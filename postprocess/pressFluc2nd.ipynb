{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parsing configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "confParser = configparser.ConfigParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf. file sections: ['parameters', 'flags', 'neigh list', 'dislocation analysis', 'irradiation', 'input files', 'py library path', 'Atomic Radius']\n"
     ]
    }
   ],
   "source": [
    "#--- parse conf. file\n",
    "confParser.read('configuration.ini')\n",
    "print('conf. file sections:',confParser.sections())\n",
    "#--- set dynamic parameters\n",
    "temp=confParser['parameters']['temperature']\n",
    "load=confParser['parameters']['load']\n",
    "confParser.set('input files','fileName',''.join([\n",
    "               'Swapped_%s.dump '%temp, #0\n",
    "               'equilibrium_%s.dump '%temp, #1\n",
    "               'dump.shearedge5k_Sheng5_anealed_%sload '%load, #2\n",
    "               'dump.shearedge5k_Sheng-non3_%sload '%load, #3\n",
    "               'quench_%s.dump '%temp, #4\n",
    "               'quench_NotAnnealed_%s.dump '%temp, #5\n",
    "               'Swapped_600_edge.dump ', #6\n",
    "               'equilib_600_edge.dump ', #7\n",
    "               'dumpSheared.xyz ', #8\n",
    "               'indented.dump ',    #9\n",
    "               'anneled_compressed_011.dump ',    #10\n",
    "               'Annealed_tension_011.dump ',    #11\n",
    "               'Annealed_before_indentation.dump ',    #12\n",
    "               'anneled_before_compression.dump ',    #13\n",
    "               'RSS_before_indentation.dump ',    #14\n",
    "               'RSS_compressed.dump ',    #15\n",
    "                'swapped.dump ', #16\n",
    "                'Atoms_dyn.dump ', #17\n",
    "                'Swapped_300.dump ', #18\n",
    "                'annealing.dump ', #19\n",
    "                'Atoms_dyn.dat ', #20\n",
    "              ]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utilityy' from '/Users/Home/Desktop/Tmp/txt/git/HeaDef/postprocess/utilityy.py'>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--- system libraries\n",
    "import sys\n",
    "sys.path.append(confParser['py library path']['py_lib'])\n",
    "import pdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib as mpl\n",
    "import traceback\n",
    "import os\n",
    "import scipy.interpolate as scp_int\n",
    "import warnings\n",
    "import matplotlib\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "from matplotlib import patches\n",
    "import sys\n",
    "import sklearn\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "import patsy\n",
    "from sklearn import linear_model, mixture\n",
    "import sklearn.mixture as skm\n",
    "from scipy import optimize\n",
    "import scipy\n",
    "import re\n",
    "from functools import reduce\n",
    "import time\n",
    "#from backports \n",
    "import fnmatch\n",
    "import json\n",
    "from json import JSONEncoder\n",
    "import functools as ftl\n",
    "\n",
    "class NumpyArrayEncoder(JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return JSONEncoder.default(self, obj)\n",
    "    \n",
    "#\n",
    "warnings.filterwarnings('ignore')\n",
    "#--- user modules\n",
    "import LammpsPostProcess as lp\n",
    "import LammpsPostProcess2nd as lpp\n",
    "import utilityy as utll\n",
    "import utility as utl\n",
    "# from utility import *\n",
    "import imp\n",
    "imp.reload(lp)\n",
    "imp.reload(lpp)\n",
    "imp.reload(utl)\n",
    "imp.reload(utll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Symbols:\n",
    "    def __init__(self):\n",
    "        self.colors = ['black','red','green','blue','cyan','brown','grey','magenta','orange','yellow']\n",
    "        self.fillstyles=['white',None,'white',None,'white',None,'white',None,'white',None,'white',None,'white',None,'white',None]\n",
    "        self.markers=['o','s','D','^','<','>','v']\n",
    "        self.markersizes=[10,10,10,12,12,12,10]\n",
    "        self.nmax=7\n",
    "        \n",
    "    def GetAttrs(self,count=0,label='',nevery=1,fmt='.-',zorder=1,**kwargs):\n",
    "        if count > self.nmax:\n",
    "            print('index out of list bound!')\n",
    "            return \n",
    "        attrs={ 'color':self.colors[count],\n",
    "            'markersize':self.markersizes[count],\n",
    "            'marker':self.markers[count],\n",
    "            'markerfacecolor':self.colors[count],\n",
    "            'markeredgecolor':'white', #'black' if not self.fillstyles[count] else None,\n",
    "            'label':label,\n",
    "           'markevery':nevery,\n",
    "           'errorevery':nevery,\n",
    "           'markeredgewidth':1.75,\n",
    "            'linewidth':1, \n",
    "           'barsabove':None,\n",
    "           'capsize':5 if not 'capsize' in kwargs else kwargs['capsize'],\n",
    "           'capthick':1,\n",
    "           'elinewidth':1,\n",
    "           'fmt':fmt,\n",
    "             'zorder':zorder,\n",
    "         }\n",
    "        return attrs\n",
    "    \n",
    "    def GetAttrs2nd(self,count=0,label='',nevery=1,fmt='.-',zorder=1):\n",
    "        if count > self.nmax:\n",
    "            print('index out of list bound!')\n",
    "            return \n",
    "        attrs={ 'color':self.colors[count],\n",
    "            'markersize':self.markersizes[count],\n",
    "            'marker':self.markers[count],\n",
    "            'markerfacecolor':'white',\n",
    "#            'markeredgecolor':'black' if not self.fillstyles[count] else None,\n",
    "            'label':label,\n",
    "           'markevery':nevery,\n",
    "           'errorevery':nevery,\n",
    "           'markeredgewidth':1.75,\n",
    "            'linewidth':1, \n",
    "           'barsabove':None,\n",
    "           'capsize':5,\n",
    "           'capthick':1,\n",
    "           'elinewidth':1,\n",
    "           'fmt':fmt,\n",
    "            'zorder':zorder,\n",
    "          }\n",
    "        return attrs\n",
    "\n",
    "class Legends:\n",
    "    def __init__(self\n",
    "                ):\n",
    "        pass\n",
    "    def Set(self,fontsize=20,\n",
    "                 labelspacing=0,\n",
    "                 **kwargs\n",
    "#                 bbox_to_anchor=(0.5,0.48,0.5,0.5),\n",
    "           ):\n",
    "        self.attrs = {'frameon':False,'fontsize':fontsize,\n",
    "                   'labelspacing':labelspacing,\n",
    "                      'handletextpad':.2,\n",
    "                   'handlelength':1,\n",
    "                    **kwargs,\n",
    "                     }\n",
    "    def Get(self):\n",
    "        return self.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "DRAW_FRAME=(0.23,0.08,0.12,0.07,0.1)\n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    matplotlib.rcParams['text.usetex'] = True #--- comment tex stuff!\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Dump File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list dir: ['swapped.dump']\n",
      "parsing ../lammpsRuns/nicocrNatom100KMultipleTempIrradiatedAnneal/dpa2/temp0/Run0/swapped.dump\n",
      "reached end of file!\n",
      "time steps: [0, 20000]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>fx</th>\n",
       "      <th>fy</th>\n",
       "      <th>fz</th>\n",
       "      <th>c_1[1]</th>\n",
       "      <th>c_1[2]</th>\n",
       "      <th>c_1[3]</th>\n",
       "      <th>c_1[4]</th>\n",
       "      <th>c_1[5]</th>\n",
       "      <th>c_1[6]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76957</td>\n",
       "      <td>2</td>\n",
       "      <td>2.9824</td>\n",
       "      <td>1.06340</td>\n",
       "      <td>3.628700</td>\n",
       "      <td>0.04343</td>\n",
       "      <td>-0.4000</td>\n",
       "      <td>-0.4306</td>\n",
       "      <td>803900.0</td>\n",
       "      <td>344400.0</td>\n",
       "      <td>325300.0</td>\n",
       "      <td>-325700.0</td>\n",
       "      <td>-937700.0</td>\n",
       "      <td>-353100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86483</td>\n",
       "      <td>3</td>\n",
       "      <td>1.1895</td>\n",
       "      <td>2.80170</td>\n",
       "      <td>0.062046</td>\n",
       "      <td>0.16330</td>\n",
       "      <td>-0.8390</td>\n",
       "      <td>-0.1444</td>\n",
       "      <td>580400.0</td>\n",
       "      <td>1236000.0</td>\n",
       "      <td>1147000.0</td>\n",
       "      <td>-213600.0</td>\n",
       "      <td>399200.0</td>\n",
       "      <td>-120200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91961</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2917</td>\n",
       "      <td>0.98025</td>\n",
       "      <td>1.951600</td>\n",
       "      <td>-1.25700</td>\n",
       "      <td>0.7459</td>\n",
       "      <td>-0.3905</td>\n",
       "      <td>-621100.0</td>\n",
       "      <td>-815700.0</td>\n",
       "      <td>-843600.0</td>\n",
       "      <td>405300.0</td>\n",
       "      <td>308600.0</td>\n",
       "      <td>-333700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97289</td>\n",
       "      <td>2</td>\n",
       "      <td>2.8802</td>\n",
       "      <td>0.91751</td>\n",
       "      <td>0.102710</td>\n",
       "      <td>0.33780</td>\n",
       "      <td>0.5731</td>\n",
       "      <td>-0.3598</td>\n",
       "      <td>178600.0</td>\n",
       "      <td>-160900.0</td>\n",
       "      <td>-265400.0</td>\n",
       "      <td>-275000.0</td>\n",
       "      <td>238400.0</td>\n",
       "      <td>209300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97291</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0543</td>\n",
       "      <td>2.93050</td>\n",
       "      <td>3.575000</td>\n",
       "      <td>1.02500</td>\n",
       "      <td>-0.7331</td>\n",
       "      <td>0.6281</td>\n",
       "      <td>-327100.0</td>\n",
       "      <td>-737700.0</td>\n",
       "      <td>-912400.0</td>\n",
       "      <td>-174500.0</td>\n",
       "      <td>-63660.0</td>\n",
       "      <td>38110.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  type       x        y         z       fx      fy      fz    c_1[1]  \\\n",
       "0  76957     2  2.9824  1.06340  3.628700  0.04343 -0.4000 -0.4306  803900.0   \n",
       "1  86483     3  1.1895  2.80170  0.062046  0.16330 -0.8390 -0.1444  580400.0   \n",
       "2  91961     1  1.2917  0.98025  1.951600 -1.25700  0.7459 -0.3905 -621100.0   \n",
       "3  97289     2  2.8802  0.91751  0.102710  0.33780  0.5731 -0.3598  178600.0   \n",
       "4  97291     1  1.0543  2.93050  3.575000  1.02500 -0.7331  0.6281 -327100.0   \n",
       "\n",
       "      c_1[2]     c_1[3]    c_1[4]    c_1[5]    c_1[6]  \n",
       "0   344400.0   325300.0 -325700.0 -937700.0 -353100.0  \n",
       "1  1236000.0  1147000.0 -213600.0  399200.0 -120200.0  \n",
       "2  -815700.0  -843600.0  405300.0  308600.0 -333700.0  \n",
       "3  -160900.0  -265400.0 -275000.0  238400.0  209300.0  \n",
       "4  -737700.0  -912400.0 -174500.0  -63660.0   38110.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = confParser['input files']['path']\n",
    "print('list dir:',os.listdir(path))\n",
    "indx = confParser['input files']['fileIndex']\n",
    "fileName = confParser['input files']['filename'].split()[int(indx)]\n",
    "#--- dump files\n",
    "print('parsing %s/%s'%(path,fileName))\n",
    "lmpData = lp.ReadDumpFile( '%s/%s'%(path,fileName) ) \n",
    "lmpData.GetCords( ncount = sys.maxsize, sort = False,\n",
    "#                 columns = {'c_1[1]':'sxx','c_1[2]':'syy','c_1[3]':'szz',\n",
    "#                                                   'c_1[4]':'sxy','c_1[5]':'sxz','c_1[6]':'syz'} \n",
    "                  columns = {'c_spatom[1]':'sxx','c_spatom[2]':'syy','c_spatom[3]':'szz',\n",
    "                             'c_spatom[4]':'sxy','c_spatom[5]':'sxz','c_spatom[6]':'syz'}\n",
    "                )\n",
    "keys = list(lmpData.coord_atoms_broken.keys())\n",
    "keys.sort()\n",
    "print('time steps:',keys)\n",
    "itime0 = keys[0]\n",
    "display(lmpData.coord_atoms_broken[itime0].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddRndStrs(df):\n",
    "    df['sxx']=np.random.normal(size=len(df))\n",
    "    df['syy']=np.random.normal(size=len(df))\n",
    "    df['szz']=np.random.normal(size=len(df))\n",
    "\n",
    "#--- add random stress\n",
    "#list( map(lambda x:AddRndStrs(lmpData.coord_atoms_broken[x]),lmpData.coord_atoms_broken.keys()) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stress response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetStrsStrain( lmpData, col='sxy' ):\n",
    "\n",
    "#     fig = plt.figure( figsize = (4,4))\n",
    "#     ax = fig.add_subplot(111)\n",
    "#     ax.set_xlabel(r'$\\epsilon_{xy}$',fontsize=16)\n",
    "#     ax.set_ylabel(r'$%s$(Gpa)'%col,fontsize=16)\n",
    "#     ax.tick_params(labelsize=16)\n",
    "    #\n",
    "    #--- point corresponding to strain maps\n",
    "    Box = {}\n",
    "    strainDump = []\n",
    "    Virial = []\n",
    "    times = lmpData.coord_atoms_broken.keys()\n",
    "    for itimee in sorted(times):\n",
    "\n",
    "        #--- extract atom and box properties\n",
    "        atoms = lp.Atoms( **lmpData.coord_atoms_broken[itimee].to_dict(orient='list') )\n",
    "        #\n",
    "        Box[itimee] = lp.Box( BoxBounds = lmpData.BoxBounds[itimee], AddMissing = np.array([0.0,0.0,0.0] ))\n",
    "        #\n",
    "        box0 = lp.Box( BoxBounds = lmpData.BoxBounds[0], AddMissing = np.array([0.0,0.0,0.0] ) ) #--- reference state\n",
    "\n",
    "        #--- volume\n",
    "        CellVectorOrtho, VectorNorm = lp.GetOrthogonalBasis( Box[itimee].CellVector )\n",
    "        volume = np.linalg.det( CellVectorOrtho )\n",
    "\n",
    "        #--- virial stress\n",
    "        try: \n",
    "            virial = np.sum(atoms[col]) / volume\n",
    "        except: #--- dump file has no stress entry! \n",
    "            if col == 'p':\n",
    "                virial = -(np.sum(atoms['sxx'])+np.sum(atoms['syy'])+np.sum(atoms['szz'])) / 3.0 / volume\n",
    "            ReadStrsFromDump = False\n",
    "\n",
    "        #--- bulk strain\n",
    "        dx=Box[itimee].CellVector[0,1]-box0.CellVector[0,1]\n",
    "        l1=Box[itimee].CellVector[1,1]\n",
    "        ebulk = dx/l1    \n",
    "\n",
    "        #--- append\n",
    "        strainDump += [ebulk]\n",
    "        Virial += [virial*1e-4] #--- bar to gpa \n",
    "\n",
    "            #\n",
    "#     ax.set_xlim(0,0.05)\n",
    "#     ax.set_ylim(Virial[0],0.5)\n",
    "#     ax.plot(\n",
    "# #        sorted(times),\n",
    "#          0.5*np.array(strainDump),\n",
    "#         Virial, '-')\n",
    "#     #\n",
    "#     plt.savefig('stress.png',dpi=75,bbox_inches='tight',pad_inches=0.0)\n",
    "#     plt.show()\n",
    "    #\n",
    "    return np.array(strainDump), Virial\n",
    "    \n",
    "if eval(confParser['flags']['StrsCurve']):\n",
    "    strain, stress = GetStrsStrain( lmpData,\n",
    "                  col='sxy',\n",
    "                 )\n",
    "    utl.PltErr(0.5*strain,stress,\n",
    "               attrs={'fmt':'-'},\n",
    "              xlim=(0,0.05),\n",
    "#               ylim=(stress[0],0.5),\n",
    "               xstr=r'$\\epsilon_{xy}$',\n",
    "               ystr=r'$\\sigma_{xy}$',\n",
    "               title='stress.png'\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetStrsStrain( lmpData, col='sxy' ):\n",
    "\n",
    "    fig = plt.figure( figsize = (4,4))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax2=ax.twinx()\n",
    "    #\n",
    "    ax.set_xlabel(r'$\\sigma_{xy}$(Gpa)',fontsize=16)\n",
    "    ax2.set_ylabel(r'$\\dot\\gamma_{xy}$',fontsize=16)\n",
    "    ax.set_ylabel(r'$\\gamma_{xy}$',fontsize=16)\n",
    "    #\n",
    "    ax2.set_yscale('log')\n",
    "    #\n",
    "    ax.tick_params(labelsize=16)\n",
    "    ax2.tick_params(labelsize=16)\n",
    "    #\n",
    "    #--- point corresponding to strain maps\n",
    "    Box = {}\n",
    "    strainDump = []\n",
    "    Virial = []\n",
    "    times = lmpData.coord_atoms_broken.keys()\n",
    "    for itimee in sorted(times):\n",
    "\n",
    "        #--- extract atom and box properties\n",
    "        atoms = lp.Atoms( **lmpData.coord_atoms_broken[itimee].to_dict(orient='list') )\n",
    "        #\n",
    "        Box[itimee] = lp.Box( BoxBounds = lmpData.BoxBounds[itimee], AddMissing = np.array([0.0,0.0,0.0] ))\n",
    "        #\n",
    "        box0 = lp.Box( BoxBounds = lmpData.BoxBounds[0], AddMissing = np.array([0.0,0.0,0.0] ) ) #--- reference state\n",
    "\n",
    "        #--- volume\n",
    "        CellVectorOrtho, VectorNorm = lp.GetOrthogonalBasis( Box[itimee].CellVector )\n",
    "        volume = np.linalg.det( CellVectorOrtho )\n",
    "\n",
    "        #--- virial stress\n",
    "        try: \n",
    "            virial = np.sum(atoms[col]) / volume\n",
    "        except: #--- dump file has no stress entry! \n",
    "            if col == 'p':\n",
    "                virial = -(np.sum(atoms['sxx'])+np.sum(atoms['syy'])+np.sum(atoms['szz'])) / 3.0 / volume\n",
    "            ReadStrsFromDump = False\n",
    "    #        virial = -(np.sum(atoms.sxx)+np.sum(atoms.syy)+np.sum(atoms.szz)) / 3.0 / volume\n",
    "\n",
    "        #--- bulk strain\n",
    "        dx=Box[itimee].CellVector[0,1]-box0.CellVector[0,1]\n",
    "        l1=Box[itimee].CellVector[1,1]\n",
    "        ebulk = dx/l1    \n",
    "\n",
    "        #--- append\n",
    "        strainDump += [ebulk]\n",
    "        Virial += [virial*1e-4] #--- bar to gpa \n",
    "\n",
    "            #\n",
    "    ax.plot(\n",
    "            sorted(Virial),\n",
    "            strainDump, '-',label=r'$\\gamma_{xy}$')\n",
    "    ax2.plot(\n",
    "            sorted(Virial),\n",
    "            np.gradient(strainDump,sorted(times)), \n",
    "            '-',color='red',label=r'$\\dot\\gamma_{xy}$')\n",
    "    #\n",
    "    plt.legend(fontsize=16)\n",
    "    #\n",
    "    plt.savefig('stress.png',dpi=75,bbox_inches='tight',pad_inches=0.0)\n",
    "    plt.show()\n",
    "    #\n",
    "\n",
    "if eval(confParser['flags']['StrsCurve']):\n",
    "    GetStrsStrain( lmpData,\n",
    "              col='sxy',\n",
    "             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def GetStrsStrain( filee, xcol, ycol, **kwargs ):\n",
    "    fig = plt.figure( figsize = (4,4))\n",
    "    ax = fig.add_subplot(111)\n",
    "    #\n",
    "    ax.set_xlabel(r'%s(ps)'%xcol,fontsize=16)\n",
    "    ax.set_ylabel(r'%s(Gpa)'%ycol,fontsize=16)\n",
    "    #\n",
    "    ax.tick_params(labelsize=16)\n",
    "    #\n",
    "    if 'xlim' in kwargs:\n",
    "        ax.set_xlim(kwargs['xlim'])\n",
    "    #\n",
    "    if 'ylim' in kwargs:\n",
    "        ax.set_ylim(kwargs['ylim'])\n",
    "    #\n",
    "    if 'xscale' in kwargs:\n",
    "        ax.set_xscale(kwargs['xscale'])\n",
    "    if 'yscale' in kwargs:\n",
    "        ax.set_yscale(kwargs['yscale'])\n",
    "    #\n",
    "    df = pd.read_csv(filee,sep=' ')\n",
    "    try:\n",
    "        ax.plot(\n",
    "                df[xcol],\n",
    "                df[ycol], '-')\n",
    "    except:\n",
    "        if ycol == 'wxy':\n",
    "            ax.plot(\n",
    "                    df[xcol],\n",
    "                    np.gradient(df['exy'],df['time']), \n",
    "                    '-',color='red',label=r'$\\dot\\gamma_{xy}$')\n",
    "    #\n",
    "    plt.savefig('stress.png',dpi=75,bbox_inches='tight',pad_inches=0.0)\n",
    "    plt.show()\n",
    "\n",
    "if eval(confParser['flags']['StrsCurve']):\n",
    "\n",
    "    GetStrsStrain( '%s/temperature.txt'%path,\n",
    "                   xcol = 'time',\n",
    "                   ycol = 'sxy',\n",
    "\n",
    "                 )\n",
    "\n",
    "    GetStrsStrain( '%s/temperature.txt'%path,\n",
    "                   xcol = 'time',\n",
    "                   ycol = 'exy',\n",
    "                  xlim=np.array([0.0,.8])*10000,\n",
    "                  ylim=[0.0,0.04]             \n",
    "                 )\n",
    "\n",
    "    GetStrsStrain( '%s/temperature.txt'%path,\n",
    "                   xcol = 'time',\n",
    "                   ycol = 'wxy',\n",
    "                  xlim=np.array([0.0,0.8])*10000,\n",
    "                  ylim=[-1e-3,1e-2],\n",
    "                  xscale = 'linear', yscale = 'linear',\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>fx</th>\n",
       "      <th>fy</th>\n",
       "      <th>fz</th>\n",
       "      <th>c_1[1]</th>\n",
       "      <th>c_1[2]</th>\n",
       "      <th>c_1[3]</th>\n",
       "      <th>c_1[4]</th>\n",
       "      <th>c_1[5]</th>\n",
       "      <th>c_1[6]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>109.41</td>\n",
       "      <td>43.495</td>\n",
       "      <td>106.76</td>\n",
       "      <td>-0.04988</td>\n",
       "      <td>0.892200</td>\n",
       "      <td>-0.02294</td>\n",
       "      <td>-721200.0</td>\n",
       "      <td>854800.0</td>\n",
       "      <td>751100.0</td>\n",
       "      <td>244700.0</td>\n",
       "      <td>-44610.0</td>\n",
       "      <td>-481100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>116.49</td>\n",
       "      <td>38.444</td>\n",
       "      <td>108.34</td>\n",
       "      <td>0.17410</td>\n",
       "      <td>-0.217700</td>\n",
       "      <td>0.69270</td>\n",
       "      <td>66960.0</td>\n",
       "      <td>867500.0</td>\n",
       "      <td>686000.0</td>\n",
       "      <td>48530.0</td>\n",
       "      <td>-221600.0</td>\n",
       "      <td>-392000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>116.40</td>\n",
       "      <td>40.219</td>\n",
       "      <td>106.64</td>\n",
       "      <td>0.67160</td>\n",
       "      <td>0.196700</td>\n",
       "      <td>0.35370</td>\n",
       "      <td>61960.0</td>\n",
       "      <td>18900.0</td>\n",
       "      <td>-576500.0</td>\n",
       "      <td>171800.0</td>\n",
       "      <td>-243000.0</td>\n",
       "      <td>277800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>118.44</td>\n",
       "      <td>36.699</td>\n",
       "      <td>101.37</td>\n",
       "      <td>-0.53360</td>\n",
       "      <td>0.006403</td>\n",
       "      <td>-0.03366</td>\n",
       "      <td>82070.0</td>\n",
       "      <td>-357500.0</td>\n",
       "      <td>501800.0</td>\n",
       "      <td>57790.0</td>\n",
       "      <td>128600.0</td>\n",
       "      <td>200300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>114.82</td>\n",
       "      <td>29.449</td>\n",
       "      <td>101.35</td>\n",
       "      <td>-0.40290</td>\n",
       "      <td>0.365500</td>\n",
       "      <td>0.07081</td>\n",
       "      <td>-1409000.0</td>\n",
       "      <td>-1313000.0</td>\n",
       "      <td>-1639000.0</td>\n",
       "      <td>-240900.0</td>\n",
       "      <td>193100.0</td>\n",
       "      <td>-125600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  type       x       y       z       fx        fy       fz     c_1[1]  \\\n",
       "0   1     3  109.41  43.495  106.76 -0.04988  0.892200 -0.02294  -721200.0   \n",
       "1   2     3  116.49  38.444  108.34  0.17410 -0.217700  0.69270    66960.0   \n",
       "2   3     3  116.40  40.219  106.64  0.67160  0.196700  0.35370    61960.0   \n",
       "3   4     3  118.44  36.699  101.37 -0.53360  0.006403 -0.03366    82070.0   \n",
       "4   5     2  114.82  29.449  101.35 -0.40290  0.365500  0.07081 -1409000.0   \n",
       "\n",
       "      c_1[2]     c_1[3]    c_1[4]    c_1[5]    c_1[6]  \n",
       "0   854800.0   751100.0  244700.0  -44610.0 -481100.0  \n",
       "1   867500.0   686000.0   48530.0 -221600.0 -392000.0  \n",
       "2    18900.0  -576500.0  171800.0 -243000.0  277800.0  \n",
       "3  -357500.0   501800.0   57790.0  128600.0  200300.0  \n",
       "4 -1313000.0 -1639000.0 -240900.0  193100.0 -125600.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>fx</th>\n",
       "      <th>fy</th>\n",
       "      <th>fz</th>\n",
       "      <th>c_1[1]</th>\n",
       "      <th>c_1[2]</th>\n",
       "      <th>c_1[3]</th>\n",
       "      <th>c_1[4]</th>\n",
       "      <th>c_1[5]</th>\n",
       "      <th>c_1[6]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>109.42</td>\n",
       "      <td>43.800</td>\n",
       "      <td>106.42</td>\n",
       "      <td>-0.035440</td>\n",
       "      <td>-0.14010</td>\n",
       "      <td>1.41800</td>\n",
       "      <td>1842000.0</td>\n",
       "      <td>425800.0</td>\n",
       "      <td>1159000.0</td>\n",
       "      <td>-1019000.0</td>\n",
       "      <td>1223000.0</td>\n",
       "      <td>135000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>116.64</td>\n",
       "      <td>38.328</td>\n",
       "      <td>108.55</td>\n",
       "      <td>0.153900</td>\n",
       "      <td>-0.01833</td>\n",
       "      <td>-0.53990</td>\n",
       "      <td>-1232000.0</td>\n",
       "      <td>-972700.0</td>\n",
       "      <td>-799800.0</td>\n",
       "      <td>-95180.0</td>\n",
       "      <td>285500.0</td>\n",
       "      <td>-347400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>116.64</td>\n",
       "      <td>40.228</td>\n",
       "      <td>106.69</td>\n",
       "      <td>-0.001604</td>\n",
       "      <td>-0.57540</td>\n",
       "      <td>0.43860</td>\n",
       "      <td>499500.0</td>\n",
       "      <td>502800.0</td>\n",
       "      <td>193500.0</td>\n",
       "      <td>145300.0</td>\n",
       "      <td>4604.0</td>\n",
       "      <td>-49970.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>118.35</td>\n",
       "      <td>36.430</td>\n",
       "      <td>101.44</td>\n",
       "      <td>0.176000</td>\n",
       "      <td>0.67670</td>\n",
       "      <td>0.02689</td>\n",
       "      <td>1125000.0</td>\n",
       "      <td>583900.0</td>\n",
       "      <td>1065000.0</td>\n",
       "      <td>-30890.0</td>\n",
       "      <td>-329400.0</td>\n",
       "      <td>-529800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>114.87</td>\n",
       "      <td>29.402</td>\n",
       "      <td>101.43</td>\n",
       "      <td>-0.449000</td>\n",
       "      <td>0.15630</td>\n",
       "      <td>0.17610</td>\n",
       "      <td>-265400.0</td>\n",
       "      <td>-568900.0</td>\n",
       "      <td>-201100.0</td>\n",
       "      <td>92860.0</td>\n",
       "      <td>-54090.0</td>\n",
       "      <td>297900.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  type       x       y       z        fx       fy       fz     c_1[1]  \\\n",
       "0   1     3  109.42  43.800  106.42 -0.035440 -0.14010  1.41800  1842000.0   \n",
       "1   2     1  116.64  38.328  108.55  0.153900 -0.01833 -0.53990 -1232000.0   \n",
       "2   3     1  116.64  40.228  106.69 -0.001604 -0.57540  0.43860   499500.0   \n",
       "3   4     3  118.35  36.430  101.44  0.176000  0.67670  0.02689  1125000.0   \n",
       "4   5     2  114.87  29.402  101.43 -0.449000  0.15630  0.17610  -265400.0   \n",
       "\n",
       "     c_1[2]     c_1[3]     c_1[4]     c_1[5]    c_1[6]  \n",
       "0  425800.0  1159000.0 -1019000.0  1223000.0  135000.0  \n",
       "1 -972700.0  -799800.0   -95180.0   285500.0 -347400.0  \n",
       "2  502800.0   193500.0   145300.0     4604.0  -49970.0  \n",
       "3  583900.0  1065000.0   -30890.0  -329400.0 -529800.0  \n",
       "4 -568900.0  -201100.0    92860.0   -54090.0  297900.0  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#itimee=np.sum(list(lmpData.coord_atoms_broken.keys())) #--- only two timesteps:[0,ntime]\n",
    "keys=list(lmpData.coord_atoms_broken.keys())\n",
    "keys.sort()\n",
    "\n",
    "itimee=keys[-1] #--- only two timesteps:[0,ntime]\n",
    "itime0=keys[0]\n",
    "atomsRf = lp.Atoms( **lmpData.coord_atoms_broken[itime0].to_dict(orient='series') )\n",
    "atoms = lp.Atoms( **lmpData.coord_atoms_broken[itimee].to_dict(orient='series') )\n",
    "    #\n",
    "box = lp.Box( BoxBounds = lmpData.BoxBounds[itimee],AddMissing = np.array([0.0,0.0,0.0] ) )\n",
    "#box.BasisVectors( AddMissing = np.array([0.0,0.0,0.0] ))\n",
    "    \n",
    "display(pd.DataFrame(atoms.__dict__).head())\n",
    "pd.DataFrame(atomsRf.__dict__).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## removed atom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atom_id=np.sum(atomsRf.id)-np.sum(atoms.id)\n",
    "# print('atom_id=',atom_id)\n",
    "# zz=pd.DataFrame(atomsRf.__dict__)[pd.DataFrame(atomsRf.__dict__)['id']==atom_id]['z'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrintOvito( pd.DataFrame(atomsDiff.__dict__), \n",
    "#             open( 'strsDiff.xyz','w'), \n",
    "#             footer = 'ITIME=%s'%itimee,\n",
    "#             attr_list=['id','type','x','y','z','sxx' ,'syy' ,'szz' ,'sxy' ,'sxz' ,'syz'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval(confParser['flags']['Displ']):\n",
    "    !ovitos OvitosCna.py $fileName Disp.xyz $nevery 4\n",
    "    \n",
    "#--- read from d2min.xyz\n",
    "    ovtData = lp.ReadDumpFile( 'Disp.xyz' )\n",
    "    ovtData.GetCords( ncount = sys.maxsize, \n",
    "                     columns = {'DisplacementX':'ux','DisplacementY':'uy','DisplacementZ':'uz'} )\n",
    "    #\n",
    "    disp = lp.Atoms( **ovtData.coord_atoms_broken[itimee].to_dict(orient='series'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voronoi Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval(confParser['flags']['VorAnl']):\n",
    "    !mkdir voranl\n",
    "\n",
    "    path = confParser['input files']['path']\n",
    "    indx = confParser['input files']['fileIndex']\n",
    "    fileName = '%s/%s'%(path,confParser['input files']['filename'].split()[int(indx)])\n",
    "    nevery = int(confParser['parameters']['nevery'])\n",
    "    types = list(map(int,confParser['Atomic Radius']['type'].split()))\n",
    "    radius = list(map(float,confParser['Atomic Radius']['radius'].split()))\n",
    "    AtomicRadius = dict(zip(types,radius))\n",
    "        \n",
    "    rad1=AtomicRadius[1]\n",
    "    rad2=AtomicRadius[2]\n",
    "    rad3=AtomicRadius[3]\n",
    "    !ovitos OvitosCna.py $fileName voranl/Voronoi.xyz $nevery 3 $rad1 $rad2 $rad3\n",
    "    \n",
    "#--- read from d2min.xyz\n",
    "    ovtData = lp.ReadDumpFile( 'voranl/Voronoi.xyz' )\n",
    "    ovtData.GetCords( ncount = sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Press. Fluc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: PressFluc: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir PressFluc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StrsDiff(atoms,atomsRf):\n",
    "    atomsDiff = lp.Atoms( **pd.DataFrame(atoms.__dict__).copy().to_dict(orient='series'))\n",
    "    atoms0 = lp.Atoms( **pd.DataFrame(atomsRf.__dict__).copy().to_dict(orient='series'))\n",
    "    #--- virial energy to stress\n",
    "    for key in ['sxx','syy','szz']:#,'sxy','syz','sxz']:\n",
    "        atomsDiff.__dict__[key] /= atomsDiff['AtomicVolume']\n",
    "        atoms0.__dict__[key] /= atoms0['AtomicVolume']\n",
    "    df=pd.DataFrame(atoms0.__dict__).set_index('id').loc[atoms.id]\n",
    "    #--- stress change\n",
    "#    for key in ['sxx','syy','szz','sxy','syz','sxz','AtomicVolume']:\n",
    "#        atomsDiff.__dict__[key] -= np.array((df[key]).tolist())\n",
    "        \n",
    "    #--- volumetric strain\n",
    "#    atomsDiff.AtomicVolume /= atoms0.AtomicVolume\n",
    "#    display(pd.DataFrame(atomsDiff.__dict__))\n",
    "    return atomsDiff\n",
    "\n",
    "if eval(confParser['flags']['PressFluc']):\n",
    "    #--- fetch radii\n",
    "    radii=list(map(float,confParser['Atomic Radius']['radius'].split()))\n",
    "    types=list(map(int,confParser['Atomic Radius']['type'].split()))\n",
    "    AtomicRadius=dict(zip(types,radii))\n",
    "    #\n",
    "    itime = 0\n",
    "    atoms = lp.Atoms( **lmpData.coord_atoms_broken[itime].to_dict(orient='series'),\n",
    "                      rad = list(map(AtomicRadius.get,lmpData.coord_atoms_broken[itime]['type'])),\n",
    "                       AtomicVolume = ovtData.coord_atoms_broken[itime]['AtomicVolume'].tolist(),\n",
    "                    )\n",
    "    #---\n",
    "    atoms0 = lp.Atoms( **lmpData.coord_atoms_broken[0].to_dict(orient='series'),\n",
    "                      rad = list(map(AtomicRadius.get,lmpData.coord_atoms_broken[0]['type'])),\n",
    "                       AtomicVolume = ovtData.coord_atoms_broken[0]['AtomicVolume'].tolist(),\n",
    "                    )\n",
    "\n",
    "    display(pd.DataFrame(atoms.__dict__).head())\n",
    "    \n",
    "    #--- pressure change\n",
    "    atomd=StrsDiff(atoms,atoms0) #--- atomd.sxx has units of stress \n",
    "    #--- filter abs(dv)>0\n",
    "    atomd = lp.Atoms( **pd.DataFrame(atomd.__dict__)[np.abs(atomd.AtomicVolume)>1.0e-10].to_dict(orient='series'))\n",
    "    display(pd.DataFrame(atomd.__dict__).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotScatter(atomd,**kwargs):\n",
    "    \n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    ax = fig.add_subplot(111)\n",
    "    #\n",
    "    if 'xlim' in kwargs:\n",
    "        ax.axis(kwargs['xlim'])\n",
    "    if 'Logy' in kwargs and kwargs['Logy']:\n",
    "        ax.set_yscale('log')\n",
    "    if 'Logx' in kwargs and kwargs['Logx']:\n",
    "        ax.set_xscale('log')\n",
    "    #\n",
    "    ax.set_ylabel(kwargs['ylabel'] if 'ylabel' in kwargs else '',fontsize=16)\n",
    "    ax.set_xlabel(kwargs['xlabel'] if 'xlabel' in kwargs else '',fontsize=16)\n",
    "\n",
    "    #\n",
    "    ax.tick_params(labelsize=20,which='both',axis='both', top=True, right=True)\n",
    "\n",
    "    y=np.array(atomd.sxx)+np.array(atomd.syy)+np.array(atomd.szz)\n",
    "    y *= (-1.0e-4/3.0)\n",
    "    x = np.array(atomd.AtomicVolume)\n",
    "    \n",
    "    cxy=0.0\n",
    "    if 'zscore' in kwargs and kwargs['zscore']:\n",
    "        x = Zscore(x)\n",
    "        y = Zscore(y)\n",
    "        cxy = np.sum(x*y)/len(x)\n",
    "    for elm,indxx,col in zip(['Ni','Co','Cr'],[1,2,3],['black','red','green']):\n",
    "        filtr = np.array(atomd.type) == indxx\n",
    "        ax.scatter(np.abs(x[filtr]),np.abs(y[filtr]),\n",
    "                   alpha=.1,c=col,label=elm)#,marker='x')\n",
    "    #\n",
    "    ax.legend(frameon=False, fontsize=12)\n",
    "    #\n",
    "#     DrawFrame(ax, 0.2,0.09,0.15,0.06,0.04,LOG_Y=True)\n",
    "    PutMinorTicks( ax, LOGY = True, LOGX=True)\n",
    "    #\n",
    "    plt.savefig('scatter.png',dpi=2*75,bbox_inches='tight',pad_inches=0.0)\n",
    "    plt.show()\n",
    "\n",
    "    return cxy\n",
    "    \n",
    "if eval(confParser['flags']['PressFluc']) and\\\n",
    "   eval(confParser['flags']['VorAnl']) and not\\\n",
    "   eval(confParser['flags']['RemoteMachine']):\n",
    "    \n",
    "    #--- scatter plot of press and volumetric strain\n",
    "    cxy = PlotScatter(atomd,\n",
    "#               zscore = True,\n",
    "#               xlim=[1e-7,1e-3,1e-8,1e4],\n",
    "               Logx=True, Logy=True,\n",
    "               ylabel = r'$|\\Delta p|$(Gpa)',\n",
    "               xlabel = r'$|\\epsilon_v|$',\n",
    "               )\n",
    "    np.savetxt('PressFluc/PressVolCrltn.txt',[cxy],header='<p.v>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval(confParser['flags']['PressFluc']):\n",
    "    press=np.sum(np.array(atoms.sxx)+np.array(atoms.syy)+np.array(atoms.szz))\n",
    "    vol = np.linalg.det(box.CellVector)\n",
    "    press *= (-1.0e-4/3.0/vol)\n",
    "\n",
    "    press0=np.sum(np.array(atoms0.sxx)+np.array(atoms0.syy)+np.array(atoms0.szz))\n",
    "    vol = np.linalg.det(box.CellVector)\n",
    "    press0 *= (-1.0e-4/3.0/vol)\n",
    "\n",
    "    print('dp=',press-press0)\n",
    "    np.savetxt('PressFluc/PressChange.txt',[press-press0],header='DeltaPress')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiple frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    sarr = MultipleFrames2nd( path='NiCoCrNatom100KTakeOneOutRlxd', title='PressChange.txt', nrun = 16, ncols=1 ).flatten()\n",
    "\n",
    "    plt.hist(sarr,bins=16)\n",
    "    plt.show()\n",
    "    \n",
    "    print(sarr.mean(),sarr.std()/np.abs(sarr.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraci = np.logspace(np.log10(0.1),np.log10(0.9),8)\n",
    "# for ifrac, fracc in zip(range(1000),fraci):\n",
    "#     sarr  = MultipleFrames2nd(path='HeaNiCoCrNatom10KTakeOneOutFreezeFract%sRlxd'%ifrac,\n",
    "#                               nrun=32,title='PressVolCrltn.txt',ncols=1).flatten()\n",
    "#     indices = ~np.isnan( sarr )\n",
    "#     sarr = sarr[ indices ]\n",
    "#     plt.scatter([fracc]*len(sarr),-sarr,color='C0')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## distortions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### equilibrium?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval(confParser['flags']['PressFluc']):\n",
    "\n",
    "    #--- timesteps\n",
    "    times =  list(lmpData.coord_atoms_broken.keys())\n",
    "    times.sort()\n",
    "    ntime=len(times)\n",
    "\n",
    "    #--- plot\n",
    "    ax=utl.PltErr(None,None,Plot=False)\n",
    "\n",
    "\n",
    "    #--- loop over time\n",
    "    for itime in times[int(ntime/2):ntime]:\n",
    "        atoms = lp.Atoms( **lmpData.coord_atoms_broken[itime].to_dict(orient='series'),\n",
    "                          rad = list(map(AtomicRadius.get,lmpData.coord_atoms_broken[itime]['type'])),\n",
    "                           AtomicVolume = ovtData.coord_atoms_broken[itime]['AtomicVolume'].tolist(),\n",
    "                        )\n",
    "\n",
    "        hist1, edges1, error1 = GetPDF( atoms.AtomicVolume, \n",
    "                                         linscale = True, \n",
    "                                         n_per_decade=12,\n",
    "                                         density = True,\n",
    "                                                    )\n",
    "\n",
    "        utl.PltErr(edges1,hist1,\n",
    "                       yerr=error1,\n",
    "                        markevery=1,markersize=9,\n",
    "                        yscale='log',\n",
    "                        xscale='linear',\n",
    "                        marker='o',\n",
    "                       ax=ax,\n",
    "            #            xstr='r',\n",
    "            #            ystr='Std./Mean',\n",
    "                        Plot=False,\n",
    "                            ylim=(1e-4,1e1),\n",
    "                            xlim=(10,13),\n",
    "    #                        title='PressFluc/pdfNiLocalConcentration.png',\n",
    "                        DrawFrame=[0.2,0.1,0.15,0.1,0.01],\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval(confParser['flags']['PressFluc']):\n",
    "    #--- plot\n",
    "    symbols=Symbols()\n",
    "    lg = Legends()\n",
    "    lg.Set(fontsize=16,\n",
    "           bbox_to_anchor=(0.0,0.48,0.5,0.5),\n",
    "          )\n",
    "    ax=utl.PltErr(None,None,Plot=False)\n",
    "\n",
    "    #--- initialize\n",
    "    std = np.zeros(3)\n",
    "    meann = np.zeros(3)\n",
    "\n",
    "    \n",
    "    times =  list(lmpData.coord_atoms_broken.keys())\n",
    "    times.sort()\n",
    "\n",
    "    #--- loop over types\n",
    "    for atom_type, count, ll in zip([1,2,3],range(3),['Ni','Co','Cr']):    \n",
    "        #--- fetch volumes\n",
    "        itime = times[-1]\n",
    "        atoms = lp.Atoms( **lmpData.coord_atoms_broken[itime].to_dict(orient='series'),\n",
    "                          rad = list(map(AtomicRadius.get,lmpData.coord_atoms_broken[itime]['type'])),\n",
    "                           AtomicVolume = ovtData.coord_atoms_broken[itime]['AtomicVolume'].tolist(),\n",
    "                        )\n",
    "\n",
    "        #--- histograms\n",
    "        filtr = atoms.type == atom_type\n",
    "\n",
    "        hist1, edges1, error1 = GetPDF( pd.DataFrame(atoms.__dict__)[filtr].AtomicVolume, \n",
    "                                         linscale = True, \n",
    "                                         n_per_decade=12,\n",
    "                                         density = True,\n",
    "                                                    )\n",
    "\n",
    "        #--- std\n",
    "        std[count] = np.std(pd.DataFrame(atoms.__dict__)[filtr].AtomicVolume)\n",
    "        meann[count] = np.mean(pd.DataFrame(atoms.__dict__)[filtr].AtomicVolume)\n",
    "        temp = eval(confParser['parameters']['temperature'])\n",
    "\n",
    "        #--- plot\n",
    "        utl.PltErr(edges1,hist1,\n",
    "                       yerr=error1,\n",
    "                        yscale='log',\n",
    "                        xscale='linear',\n",
    "                       ax=ax,\n",
    "                        attrs=symbols.GetAttrs(count=count,label='%s'%ll,fmt='.-'),      \n",
    "                   #            xstr='r',\n",
    "            #            ystr='Std./Mean',\n",
    "                        Plot=False,\n",
    "                            ylim=(1e-3,1e1),\n",
    "                            xlim=(10.5,12),\n",
    "                        DrawFrame=[0.2,0.1,0.15,0.1,0.01],\n",
    "                      )\n",
    "    utl.PltErr(None,None,\n",
    "#               legend=lg.Get(),\n",
    "               ax=ax,\n",
    "               yscale='log',\n",
    "                title='PressFluc/hist_vorVolumeTemp%sRss.png'%confParser['parameters']['temperature'],\n",
    "                DrawFrame=[0.2,0.1,0.15,0.1,0.01],\n",
    "              )\n",
    "\n",
    "\n",
    "    #--- save\n",
    "    np.savetxt('PressFluc/voronoiFluctuationsTemp%sRss.txt'%temp,np.c_[np.concatenate(([temp],std))].T,header='Temp\\tstdNi\\tstdCo\\tstdCr')\n",
    "    np.savetxt('PressFluc/voronoiAverageTemp%sRss.txt'%temp,np.c_[np.concatenate(([temp],meann))].T,header='Temp\\tmeanNi\\tmeanCo\\tmeanCr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval(confParser['flags']['PressFluc']) and not\\\n",
    "   eval(confParser['flags']['RemoteMachine']):\n",
    "    #--- plot order parameter vs. distance\n",
    "    temperature = []\n",
    "    meann = []\n",
    "    for temp, count in zip([400,600,800,1000,1200,1400],range(100)): #--- T\n",
    "        pathh = 'NiCoCrNatom100KDistortions/Temp%s/Run0/PressFluc/voronoiAverageTemp%s.txt'%(temp,temp)\n",
    "        print('parse from %s'%pathh)\n",
    "        sdata = np.loadtxt(pathh)\n",
    "        #--- filter\n",
    "        #--- order parameter\n",
    "        temperature.append(sdata[0])\n",
    "        meann.append(sdata[1:])\n",
    "            #--- mean y\n",
    "    print(temperature)\n",
    "    #--- parse rss\n",
    "    pathh = 'PressFluc/voronoiAverageTemp5Rss.txt'\n",
    "    print('parse from %s'%pathh)\n",
    "    sdata = np.loadtxt(pathh)\n",
    "    #--- filter\n",
    "    #--- order parameter\n",
    "#        temperature.append(sdata[0])\n",
    "    mean_rss = sdata[1:]\n",
    "    print(mean_rss)\n",
    "    \n",
    "    #--- plot\n",
    "    ax = utl.PltErr(None,None,Plot=False)\n",
    "    for count in range(3):\n",
    "        utl.PltErr(temperature,np.c_[meann][:,count],\n",
    "                   attrs=symbols.GetAttrs(count=count),\n",
    "                   ax=ax,\n",
    "                   Plot=False,\n",
    "\n",
    "                  )\n",
    "        utl.PltErr([1500],mean_rss[count],\n",
    "                   attrs=symbols.GetAttrs2nd(count=count),\n",
    "                   ax=ax,\n",
    "                   Plot=False,\n",
    "                    title='PressFluc/voronoiAverageTempSro.png',\n",
    "                    DrawFrame=[0.2,0.1,0.15,0.1,0.01],\n",
    "                   xlim=(300,1600),\n",
    "                xticks=(['$500$','$1000$',''],[500,1000,1500])\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    ax = utl.PltErr(None,None,Plot=False)\n",
    "    for count in range(3):\n",
    "        utl.PltErr(temperature,np.c_[stdd][:,count]/np.c_[meann][:,count],\n",
    "                   attrs=symbols.GetAttrs(count=count),\n",
    "                   ax=ax,\n",
    "                   Plot=False,\n",
    "\n",
    "                  )\n",
    "        utl.PltErr([1500],std_rss[count]/mean_rss[count],\n",
    "                   attrs=symbols.GetAttrs2nd(count=count),\n",
    "                   ax=ax,\n",
    "                   Plot=False,\n",
    "                    title='PressFluc/voronoiStdTempSro.png',\n",
    "                    DrawFrame=[0.2,0.1,0.15,0.1,0.01],\n",
    "                   xlim=(300,1600),\n",
    "                    xticks=(['$500$','$1000$',''],[500,1000,1500])\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pressure decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Intrp( d2min, box0,times, time0, Plot = None ):\n",
    "    #--- mean dist between atoms \n",
    "    natoms = len( d2min.x ) \n",
    "    CellVectorOrtho, VectorNorm = lp.GetOrthogonalBasis( box0.CellVector )\n",
    "    volume = np.linalg.det( CellVectorOrtho )\n",
    "    dmean = 0.5*( volume / natoms ) ** (1.0/3.0) \n",
    "\n",
    "\n",
    "    #--- grid tiling mapped box with original size\n",
    "    #--- values are interpolated onto this grid\n",
    "    (xlin, ylin, zlin), (xv, yv, zv) = lp.GetCubicGrid( box0.CellOrigin, \n",
    "                                                     box0.CellVector, \n",
    "                                                     dmean,\n",
    "                                                     margin = 0.0 * dmean )\n",
    "    xi = np.array(list(zip(xv.flatten(), yv.flatten(), zv.flatten())))\n",
    "\n",
    "    #--- expand the original box\n",
    "        #--- map to square box\n",
    "    mapp = lp.Map( d2min, box0 ) \n",
    "    mapp.ChangeBasis()\n",
    "    mapp.Set( d2min ) #--- atoms: add mapped xyz\n",
    "\n",
    "    cptmp = lp.Copy(d2min, box0) #--- important: must be reference frame!!\n",
    "    cptmp.Expand( epsilon = 0.3, mode = 'isotropic' )\n",
    "    d2exp = cptmp.Get()\n",
    "\n",
    "    points = np.c_[d2exp.xm,d2exp.ym,d2exp.zm] #--- unstructured points\n",
    "    values = np.c_[-(np.array(d2exp.sxx)+np.array(d2exp.syy)+np.array(d2exp.szz))/3.0/np.array(d2exp.AtomicVolume)] #--- corresponding values\n",
    "\n",
    "    grid_z = scp_int.griddata(points, values, xi, method='linear')\n",
    "    assert not np.any(np.isnan(grid_z.flatten())), 'increase ev!'\n",
    "\n",
    "    #--- make an object\n",
    "    d2intrp = lp.Atoms(**pd.DataFrame(np.c_[xi,grid_z],columns=['x','y','z','d2min']).to_dict(orient='list'))\n",
    "\n",
    "    if Plot:\n",
    "    #--- reshape value\n",
    "        nx,ny,nz = len(xlin), len(ylin),len(zlin) \n",
    "        value = np.c_[d2intrp.d2min].reshape(((ny,nx,nz)))\n",
    "\n",
    "        CellVectorOrtho, VectorNorm = lp.GetOrthogonalBasis( box0.CellVector ) #--- box length\n",
    "        #--- xy plane\n",
    "        zz=0.5*(zlin[-1]+zlin[0])\n",
    "        dz = zlin[-1]-zlin[-2]\n",
    "        lz = zlin[-1]-zlin[0]\n",
    "        nzz=int(nz*(zz-zlin[0])/lz)\n",
    "        val = value[:,:,nzz].copy()\n",
    "#        pdb.set_trace()\n",
    "\n",
    "        np.savetxt('pressBitmap.txt',val)\n",
    "\n",
    "        PltBitmap(val, \n",
    "                  xlabel = r'$x$(\\r{A})', ylabel = r'$y$(\\r{A})',\n",
    "                  xlim=VectorNorm[0]*np.array([-0.5,0.5]),ylim=VectorNorm[1]*np.array([-0.5,0.5]),\n",
    "                  zscore = True,\n",
    "                  frac = 0.5, #--- plot a patch\n",
    "                  title = 'd2min.png',\n",
    "                  colorbar=True,\n",
    "                )\n",
    "\n",
    "    return (xlin, ylin, zlin), (xv[:,:,nzz], yv[:,:,nzz], zv[:,:,nzz]), d2intrp\n",
    "  \n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    junk, (xv, yv, zv), d2intrp = Intrp(atoms, box,\n",
    "                    times = [0], #list(lmpData.coord_atoms_broken.keys()),\n",
    "                    time0 =0,\n",
    "                    Plot = True,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### map and scatterd plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PltBitmapWithScatter( value, xyScatter,\n",
    "              xlabel = 'x', ylabel = 'y',\n",
    "              xlim = (-0.5,0.5), ylim = (-0.5,0.5),\n",
    "              frac = 1.0, #--- plot a patch\n",
    "              zscore = True,\n",
    "              title = 'cxy.png',\n",
    "              colorbar=False,\n",
    "              ticklabels=True,\n",
    "              color='black',\n",
    "              **kwargs\n",
    "             ):\n",
    "        \n",
    "    val = value.copy()\n",
    "    #--- z-score\n",
    "    if zscore:\n",
    "        val -= np.mean(val)\n",
    "        val /= np.std(val)\n",
    "        val[val>2.0]=1.0\n",
    "        val[val<-2.0]=-1.0\n",
    "    #--- plot\n",
    "    (mgrid,ngrid) = val.shape\n",
    "    center = (ngrid/2,mgrid/2)\n",
    "    #\n",
    "    aspect = (ylim[1]-ylim[0])/(xlim[1]-xlim[0])\n",
    "    fig = plt.figure(figsize=(4,4*aspect))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xlabel(xlabel,fontsize=16)\n",
    "    ax.set_ylabel(ylabel,fontsize=16)\n",
    "    ax.tick_params(labelsize=16,which='both',axis='both', top=True, right=True)\n",
    "    if not ticklabels:\n",
    "        ax.axes.xaxis.set_visible(False)\n",
    "        ax.axes.yaxis.set_visible(False)\n",
    "    #\n",
    "    pos = ax.imshow(val.real,cmap='bwr',\n",
    "                     extent=(xlim[0],xlim[1],ylim[0],ylim[1]),origin='lower')# ,vmin=-.6, vmax=.6)\n",
    "    \n",
    "    ax.scatter(xyScatter[:,0],xyScatter[:,1],\n",
    "           alpha=1,color=color,marker='x',s=10)\n",
    "        \n",
    "        \n",
    "    if colorbar:\n",
    "        ax.colorbar( pos, fraction = 0.04)\n",
    "    if 'DrawFrame' in kwargs: \n",
    "        DrawFrame(ax, *kwargs['DrawFrame'])\n",
    "    plt.savefig(title,dpi=2*75,bbox_inches='tight',pad_inches=0.0)\n",
    "    plt.show()\n",
    "    \n",
    "def Intrp( d2min, box0,times, time0, title = 'bitmap', Plot = None ):\n",
    "    d2intrp = {}\n",
    "    for itime in times:\n",
    "        #--- mean dist between atoms \n",
    "        natoms = len( d2min.x ) \n",
    "        CellVectorOrtho, VectorNorm = lp.GetOrthogonalBasis( box0.CellVector )\n",
    "        volume = np.linalg.det( CellVectorOrtho )\n",
    "        dmean = 0.5*( volume / natoms ) ** (1.0/3.0) \n",
    "\n",
    "\n",
    "        #--- grid tiling mapped box with original size\n",
    "        #--- values are interpolated onto this grid\n",
    "        (xlin, ylin, zlin), (xv, yv, zv) = lp.GetCubicGrid( box0.CellOrigin, \n",
    "                                                         box0.CellVector, \n",
    "                                                         dmean,\n",
    "                                                         margin = 0.0 * dmean )\n",
    "        xi = np.array(list(zip(xv.flatten(), yv.flatten(), zv.flatten())))\n",
    "\n",
    "        #--- expand the original box\n",
    "            #--- map to square box\n",
    "        mapp = lp.Map( d2min, box0 ) \n",
    "        mapp.ChangeBasis()\n",
    "        mapp.Set( d2min ) #--- atoms: add mapped xyz\n",
    "\n",
    "        cptmp = lp.Copy(d2min, box0) #--- important: must be reference frame!!\n",
    "        cptmp.Expand( epsilon = 0.2, mode = 'isotropic' )\n",
    "        d2exp = cptmp.Get()\n",
    "\n",
    "        points = np.c_[d2exp.xm,d2exp.ym,d2exp.zm] #--- unstructured points\n",
    "        values = np.c_[-(np.array(d2exp.sxx)+np.array(d2exp.syy)+np.array(d2exp.szz))/3.0] #--- corresponding values\n",
    "\n",
    "        grid_z = scp_int.griddata(points, values, xi, method='linear')\n",
    "        assert not np.any(np.isnan(grid_z.flatten())), 'increase ev!'\n",
    "\n",
    "        #--- make an object\n",
    "        d2intrp[ itime ] = lp.Atoms(**pd.DataFrame(np.c_[xi,grid_z],columns=['x','y','z','d2min']).to_dict(orient='list'))\n",
    "\n",
    "        if Plot:\n",
    "        #--- reshape value\n",
    "            nx,ny,nz = len(xlin), len(ylin),len(zlin) \n",
    "            value = np.c_[d2intrp[ itime ].d2min].reshape(((ny,nx,nz)))\n",
    "\n",
    "            CellVectorOrtho, VectorNorm = lp.GetOrthogonalBasis( box0.CellVector ) #--- box length\n",
    "            #--- xy plane\n",
    "#            zz=0.0\n",
    "            zc=0.5*(zlin[0]+zlin[-1])\n",
    "            dz = zlin[-1]-zlin[-2]\n",
    "            lz = zlin[-1]-zlin[0]\n",
    "            #\n",
    "            zz = [zc,zlin[-1]][1]\n",
    "            nzz=int(nz*(zz-zlin[0])/lz)\n",
    "            if nzz == nz: nzz -= 1\n",
    "            val = value[:,:,nzz].copy()\n",
    "#            pdb.set_trace()\n",
    "        \n",
    "#            np.savetxt('pressBitmap.txt',val)\n",
    "\n",
    "#             PltBitmap(val, \n",
    "#                       xlabel = 'x', ylabel = 'y',\n",
    "#                       xlim=VectorNorm[0]*np.array([0.0,1.0]),ylim=VectorNorm[1]*np.array([0.0,1.0]),\n",
    "#                       zscore = True,\n",
    "#                       frac = 1.0, #--- plot a patch\n",
    "#                  title = '%s%s.png'%(title,itime),\n",
    "#                       colorbar=True,\n",
    "#                     )\n",
    "            \n",
    "            #--- filter\n",
    "            zlo=(zz-dz-zlin[0]) % lz + zlin[0]\n",
    "            zhi=(zz+dz-zlin[0]) % lz + zlin[0]\n",
    "\n",
    "            indxx= np.all([d2min.z > zlo, \n",
    "                           d2min.z < zhi\n",
    "                          ],\n",
    "                            axis=0)\n",
    "            \n",
    "            if zhi < zlo: #--- periodicity\n",
    "                indxx= np.any([d2min.z > zlo, \n",
    "                               d2min.z < zhi\n",
    "                              ],\n",
    "                                axis=0)\n",
    "\n",
    "\n",
    "            indices = d2min.type == 1 #--- Ni 3\n",
    "            indxx = np.all([indxx,indices],axis=0)\n",
    "\n",
    "            PltBitmapWithScatter(val, \n",
    "                  np.c_[np.array(d2min.x)[indxx],np.array(d2min.y)[indxx]],\n",
    "                  xlabel = '', ylabel = '',\n",
    "    #                  xlim=VectorNorm[0]*np.array([0.0,1.0]),ylim=VectorNorm[1]*np.array([0.0,1.0]),\n",
    "                  xlim=np.array([xlin[0],xlin[-1]]),ylim=np.array([ylin[0],ylin[-1]]),\n",
    "                  zscore = True,\n",
    "                  frac = 1.0, #--- plot a patch\n",
    "                  title = '%s%s.png'%(title,itime),\n",
    "                  colorbar=None,\n",
    "                  ticklabels = None,\n",
    "                  color='black',\n",
    "    #                     DrawFrame=[0.2,0.09,0.15,0.06,0.04],\n",
    "                  )\n",
    "                \n",
    "                \n",
    "\n",
    "    return (xlin, ylin, zlin), (xv[:,:,:], yv[:,:,:], zv[:,:,:]), d2intrp\n",
    "  \n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    #--- local pressure and Ni atoms\n",
    "    junk, (xv, yv, zv), d2intrp = Intrp(atoms0, box,\n",
    "                    times = [0], #list(lmpData.coord_atoms_broken.keys()),\n",
    "                    time0 =0,\n",
    "                    Plot = True,\n",
    "                    title = 'cr',\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### average map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    nruns=16\n",
    "    for irun in range(nruns):\n",
    "        val=np.loadtxt('NiCoCrNatom100KTakeOneOutRlxd/Run%s/pressBitmap.txt'%irun)\n",
    "        if irun == 0:\n",
    "            valm = val.copy()\n",
    "        else:\n",
    "            valm += val\n",
    "    valm /= nruns\n",
    "\n",
    "    PltBitmap(valm, \n",
    "              xlabel = '', ylabel = '',\n",
    "    #          xlim=VectorNorm[0]*np.array([0.0,1.0]),ylim=VectorNorm[1]*np.array([0.0,1.0]),\n",
    "              zscore = True,\n",
    "              frac = 1.0, #--- plot a patch\n",
    "              title = 'd2min.png',\n",
    "              colorbar=True,\n",
    "    #          DrawFrame=[0.3,0.3,0.3,0.1,0.1],\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def GetCR( X, Y, Z, zfield, DIR, tol=1e-3, title='decay.png',**kwargs ):\n",
    "    if 'xc' in kwargs:\n",
    "        X = X.copy()\n",
    "        Y = Y.copy()\n",
    "        Z = Z.copy()\n",
    "        xc = kwargs['xc']\n",
    "        X -= xc[0]\n",
    "        Y -= xc[1]\n",
    "        Z -= xc[2]\n",
    "    xyz = np.c_[X,Y,Z]\n",
    "    xyzNorm = np.array(list(map(lambda x: np.sum(x)**.5,xyz*xyz)))\n",
    "    #\n",
    "    #--- plot\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.tick_params(labelsize=18)\n",
    "    if 'Logy' in kwargs and kwargs['Logy']:\n",
    "        ax.set_yscale('log')\n",
    "    if 'Logx' in kwargs and kwargs['Logx']:\n",
    "        ax.set_xscale('log')\n",
    "    if 'xlim' in kwargs:\n",
    "        ax.axis(kwargs['xlim'])\n",
    "    ax.set_ylabel(kwargs['ylabel'] if 'ylabel' in kwargs else '',fontsize=16)\n",
    "    ax.set_xlabel(kwargs['xlabel'] if 'xlabel' in kwargs else '',fontsize=16)\n",
    "    #\n",
    "    for ndir in DIR:\n",
    "        dot = np.sum(xyz * ndir,axis=1) / np.sum(ndir*ndir)**0.5 / xyzNorm\n",
    "        assert np.all([-1.0<=dot,dot<=1.0])\n",
    "        #\n",
    "        indices= np.abs(1.0-dot) < tol\n",
    "        #\n",
    "        xx=X[indices]\n",
    "        yy=Y[indices]\n",
    "        zz=Z[indices]\n",
    "    #    print(np.c_[xx,yy,zz])\n",
    "        #\n",
    "        rr=np.sqrt(xx*xx+yy*yy+zz*zz)\n",
    "        rho = zfield[indices]\n",
    "        assert len( rr ) > 0 \n",
    "        assert len(rho[np.isnan(rho)]) == 0\n",
    "        #\n",
    "        slist=list(zip(rr,rho))\n",
    "        slist.sort()\n",
    "        rr = [i[0] for i in slist]\n",
    "        rho = [i[1] for i in slist]\n",
    "        ax.plot(rr,rho,'-o',label=r'%s'%ndir)\n",
    "#        print(np.c_[rr,rho])\n",
    "    #\n",
    "    #--- draw power law\n",
    "    if 'alpha' in kwargs:\n",
    "        alpha = kwargs['alpha']\n",
    "        xx=ax.lines[0].get_data()[0]\n",
    "        xx.sort()\n",
    "        xx = np.array(xx)\n",
    "        ax.plot(ax.axis()[0]*(xx/xx[0]),ax.axis()[3]*(xx[0]/xx)**alpha,'-.r',label='$r^{-%s}$'%alpha)\n",
    "        #\n",
    "        ax.legend(frameon=False, fontsize=16)\n",
    "    #--- save\n",
    "    if 'Logy' in kwargs and kwargs['Logy']:\n",
    "        PutMinorTicks(ax, LOGY=True)\n",
    "    if 'Logx' in kwargs and kwargs['Logx']:\n",
    "        PutMinorTicks(ax, LOGX=True)\n",
    "    #DrawFrame(ax, 0.3,0.3,0.3,0.1,0.1)\n",
    "    plt.savefig(title,dpi=2*75,bbox_inches='tight',pad_inches=0.0)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "\n",
    "    #--- decay of local pressure\n",
    "    valm = -1.0e-4*(atoms.sxx+atoms.syy+atoms.szz)/atoms.AtomicVolume/3.0 #--- corresponding values\n",
    "    GetCR( atoms.x, atoms.y, atoms.z, valm, \n",
    "    #      np.array([[1.0,1.0,0.0],[-1.0,1.0,0.0],[-1.0,-1.0,0.0],[1.0,-1.0,0.0]] ),\n",
    "    #      np.array([[1.0,0.0,0.0],[0.0,1.0,0.0],[-1.0,0.0,0.0],[0.0,-1.0,0.0]] ),\n",
    "          np.array([[0.0,1.0,0.0]]),#,[1.0,1.0,0.0]] ),\n",
    "          xc=np.array([28.6,0.0,0.0]), #--- origin\n",
    "          xlabel=r'$r$(\\r{A})',\n",
    "          ylabel =r'$\\Delta p$(Gpa)',\n",
    "          xlim=(1e1,1e2,1e-1,2),\n",
    "           Logy = True,\n",
    "           Logx = True,\n",
    "          alpha=1,\n",
    "         )\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "\n",
    "    #--- decay of local pressure\n",
    "    GetCR( disp.x, disp.y, disp.z, -disp.ux, \n",
    "          np.array([[1.0,0.0,0.0]]),\n",
    "          xlabel=r'$r$(\\r{A})',\n",
    "          ylabel =r'$-u_x$(\\r{A})',\n",
    "          xlim=(1e0,1e5,1e-6,1e-1),\n",
    "           Logy = True,\n",
    "           Logx = True,\n",
    "          alpha=4,\n",
    "          title='udecay.png'\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    #--- decay of local pressure\n",
    "    valm=list(map(lambda x: x[0]+x[1],np.c_[disp.ux,disp.uy,disp.uz]* np.array([[1.0,1.0,0.0]])/2**.5))\n",
    "    GetCR( disp.x, disp.y, disp.z, np.array(valm), \n",
    "          np.array([[1.0,1.0,0.0]]),\n",
    "          xlabel=r'$r$(\\r{A})',\n",
    "          ylabel =r'$u$(\\r{A})',\n",
    "          xlim=(1e0,1e3,1e-6,1e-3),\n",
    "           Logy = True,\n",
    "           Logx = True,\n",
    "          alpha=4,\n",
    "          title='udecay.png'\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composition Fluctuations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plott(sarr,nx,ny,nz,box,zlin, title):\n",
    "    value = np.c_[sarr].reshape(((ny,nx,nz)))\n",
    "    CellVectorOrtho, VectorNorm = lp.GetOrthogonalBasis( box.CellVector ) #--- box length\n",
    "    #--- xy plane\n",
    "    zz=0.5*(zlin[-1]+zlin[0])\n",
    "    dz = zlin[-1]-zlin[-2]\n",
    "    lz = zlin[-1]-zlin[0]\n",
    "    nzz=int(nz*(zz-zlin[0])/lz)\n",
    "    val = value[:,:,nzz].copy()\n",
    "    #        pdb.set_trace()\n",
    "    PltBitmap(val, \n",
    "              xlabel = r'$x$(\\r{A})', ylabel = r'$y$(\\r{A})',\n",
    "              xlim=VectorNorm[0]*np.array([-0.5,0.5]),ylim=VectorNorm[1]*np.array([-0.5,0.5]),\n",
    "              zscore = True,\n",
    "              frac = 1.0, #--- plot a patch\n",
    "              title = title,\n",
    "              colorbar=True,\n",
    "            )\n",
    "    \n",
    "    \n",
    "def GetComp( atoms, atomf ):\n",
    "    #--- different types\n",
    "    types = set(atomf.type)\n",
    "    c={}\n",
    "    n = len(atoms.x)\n",
    "    \n",
    "    return dict(zip(types,list(map(lambda x:1.0*np.sum(atoms.type == x)/n,types))))\n",
    "#    for typei in types:\n",
    "#        c[typei] = 1.0*np.sum(atoms.type == typei)/n\n",
    "#\n",
    "#    return c\n",
    "\n",
    "\n",
    "def GetPressComp( atoms,box, dmean, **kwargs ):\n",
    "    #--- grid: tiling mapped box with original size\n",
    "    (xlin, ylin, zlin), (xv, yv, zv) = lp.GetCubicGrid( box.CellOrigin, \n",
    "                                                     box.CellVector, \n",
    "                                                     dmean,\n",
    "                                                     margin = 0.0 * dmean, odd = False )\n",
    "    xi = np.array(list(zip(xv.flatten(), yv.flatten(), zv.flatten())))\n",
    "    dvol = (xlin[1]-xlin[0])*(ylin[1]-ylin[0])*(zlin[1]-zlin[0])\n",
    "    (ny,nx,nz) = xv.shape\n",
    "    print(xv.shape)\n",
    "#     nx -= 1\n",
    "#     ny -= 1\n",
    "#     nz -= 1\n",
    "    assert nx*ny*nz >= 8, 'decrease division length!'\n",
    "    #--- indices\n",
    "    (xvi, yvi, zvi) = np.meshgrid(np.arange(0,nx),np.arange(0,ny),np.arange(0,nz))\n",
    "    indices = np.array(list(zip(xvi.flatten(), yvi.flatten(), zvi.flatten()))) #--- shape:(ncel,3)\n",
    "    indices = list(map(lambda x: tuple(x),indices))\n",
    "\n",
    "    #--- partition box & assign index to each atom\n",
    "    wrap = lp.Wrap(atoms,box)\n",
    "    wrap.WrapCoord() #--- wrap inside\n",
    "    wrap.Set(atoms)\n",
    "    assert np.sum(wrap.isInside()) == len(atoms.x)\n",
    "    wrap.GetDimensionlessCords()\n",
    "    AtomCellId = (wrap.beta * np.array([nx,ny,nz])).astype(int)\n",
    "    #--- store in a df\n",
    "    df = pd.DataFrame(np.c_[pd.DataFrame(atoms.__dict__),AtomCellId],\n",
    "                         columns=list(pd.DataFrame(atoms.__dict__).keys())+['ix','iy','iz'])\n",
    "    df['ix']=df['ix'].astype(int)\n",
    "    df['iy']=df['iy'].astype(int)\n",
    "    df['iz']=df['iz'].astype(int)\n",
    "#    display(df.head())\n",
    "\n",
    "    #--- group & compute p and c\n",
    "    d = df.groupby(by=['ix','iy','iz']).groups\n",
    "#     print(len(d))\n",
    "    if 'MODU' in kwargs and kwargs['MODU']:\n",
    "        assert len(d) == nx*ny*nz, 'empty boxes!'\n",
    "    #--- lambda function: compute p \n",
    "    f = lambda x: np.sum(np.sum(np.array(x.sxx)+np.array(x.syy)+np.array(x.szz)))*(-1.0e-4/3.0/dvol)\n",
    "    vol=np.linalg.det(box.CellVector)\n",
    "    #\n",
    "    \n",
    "    keys = indices if 'MODU' in kwargs and kwargs['MODU'] else d.keys()\n",
    "#    pdb.set_trace()\n",
    "\n",
    "    #--- subset of cells\n",
    "    if 'ncmax' in kwargs:\n",
    "        ncell = len(keys)\n",
    "#        assert ncell == nx * ny * nz, '%s != %s'%(ncell,nx * ny * nz)\n",
    "        keys = list(keys)[0:np.min([ncell,kwargs['ncmax']])]\n",
    "    print('dmean=',dmean,len(keys))\n",
    "\n",
    "    plist = np.zeros(len(keys)) #list(map(lambda x:f(df.iloc[d[x]]),keys)) #--- len(plist) = ncell\n",
    "    clist = list(map(lambda x:GetComp(df.iloc[d[x]],atoms),keys)) #--- clist[icell]={1:c1,2:c2, ...}\n",
    "    \n",
    "    #---\n",
    "    if 'PLOT' in kwargs and kwargs['PLOT']:\n",
    "        plott(plist,nx,ny,nz,box,zlin, 'pCG.png')\n",
    "    \n",
    "    \n",
    "    #--- read file: elastic constants\n",
    "    if 'MODU' in kwargs and kwargs['MODU']:\n",
    "        fileName = kwargs['PATH']\n",
    "        modu = pd.read_csv(fileName, sep=' ',header=0)\n",
    "#        display(modu.head())\n",
    "        if 'PLOT' in kwargs and kwargs['PLOT']:\n",
    "            plott(modu['C66'],nx,ny,nz,box,zlin, 'muCG.png')\n",
    "\n",
    "    #--- plot\n",
    "    #--- reshape value\n",
    "\n",
    "\n",
    "        \n",
    "#        display(modu.head())\n",
    "    if 'MODU' in kwargs and kwargs['MODU']:\n",
    "        mlist = modu['C66'].to_list()\n",
    "        return clist, plist, mlist\n",
    "    else:\n",
    "        return clist, plist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if eval(confParser['flags']['PressFluc']):\n",
    "    #--- length scales\n",
    "    nn=[list(set(np.logspace(5,1,8,base=2,dtype=int))),\n",
    "        list(set(np.logspace(6,1,32,base=2,dtype=int))),\n",
    "        list(set(np.logspace(6,1,16,base=2,dtype=int)))\n",
    "       ][ 1 ]\n",
    "    nn.sort()\n",
    "\n",
    "    #clist, plist = GetPressComp( atoms,box, 20.0 )\n",
    "    #--- partition\n",
    "    box = lp.Box( BoxBounds = lmpData.BoxBounds[itime],AddMissing = np.array([0.0,0.0,0.0] ) )\n",
    "\n",
    "    rsub = np.array([\n",
    "            [53.7],\n",
    "            list(map(lambda x: box.CellVector[0,0]/x,nn))\n",
    "           ][1])\n",
    "    rsub = rsub[rsub>3.0] #--- r>r_nearest \n",
    "    rsub=[10]\n",
    "    print('rsub=',rsub)\n",
    "    \n",
    "    # #--- composition and pressure fluctuations\n",
    "#    t0 = time.time()\n",
    "    ncmax=1000\n",
    "#    cplist = list(map(lambda x: GetPressComp( atoms,box, x, ncmax=ncmax ), rsub))\n",
    "#    print('partitioning %s'%(time.time()-t0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multiple realizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if eval(confParser['flags']['PressFluc']):\n",
    "    nevery = int(confParser['parameters']['nevery'])\n",
    "    times = np.array(list(lmpData.coord_atoms_broken.keys()))\n",
    "    times = times[ times > 0 ][::nevery] #--- equilibration\n",
    "    #\n",
    "    atoml = list(map( lambda x:lp.Atoms( **lmpData.coord_atoms_broken[x].to_dict(orient='series')), times))\n",
    "    atomd = dict(zip(times,atoml)) #--- dict: key=time val=atom object\n",
    "    #\n",
    "    boxl = list(map(lambda x:lp.Box( BoxBounds = lmpData.BoxBounds[x], AddMissing = np.array([0.0,0.0,0.0] )), times ))\n",
    "    boxd = dict(zip(times,boxl))\n",
    "    #--- attributes for modulus calculatiuons\n",
    "    args = {\n",
    "             'PLOT': False,\n",
    "    #          'MODU':True, \n",
    "    #          'PATH':'%s/ElasticConst.txt'%path\n",
    "           }\n",
    "    cplist = [list(map(lambda x: \n",
    "              GetPressComp(atomd[x],\n",
    "                           boxd[x], \n",
    "                           y,\n",
    "                           ncmax=ncmax,\n",
    "                           PATH = '%s/git/HeaDef/lammpsRuns/NiCoCrNatom100KAnnealedT600Elastic%s/Run0/ElasticConst.txt'%(path,2), **args  ), \n",
    "                       times)) \n",
    "              for y, indxx in zip(rsub,range(len(rsub)))]\n",
    "    t0 = time.time()\n",
    "    cplist = dict(zip(rsub,cplist)) #--- dict: key=length val=cp list\n",
    "    print('partitioning all timesteps: %s'%(time.time()-t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Concat(cplist):\n",
    "    cp={}\n",
    "    for key in cplist:\n",
    "#         pdb.set_trace()\n",
    "        value = reduce(lambda x, y: x+y, list(map(lambda x:list(x[1]),cplist[key]))) #--- concat press.\n",
    "        valc  = reduce(lambda x, y: x+y, list(map(lambda x:list(x[0]),cplist[key]))) #--- concat press.\n",
    "        try:\n",
    "            val2 = reduce(lambda x, y: x+y, list(map(lambda x:list(x[2]),cplist[key]))) #--- concat mu.\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            cp[key]=[valc,value,val2]\n",
    "        except:    \n",
    "            cp[key]=[valc,value]\n",
    "    return cp\n",
    "\n",
    "if eval(confParser['flags']['PressFluc']):\n",
    "    cpdic = Concat(cplist) #--- cpdic[key] = [c,p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval(confParser['flags']['PressFluc']):\n",
    "    \n",
    "    symbols=Symbols()\n",
    "    #--- plots\n",
    "    ax1=utl.PltErr(None,None,Plot=False)\n",
    "    ax2=utl.PltErr(None,None,Plot=False)\n",
    "    ax3=utl.PltErr(None,None,Plot=False)\n",
    "\n",
    "    #--- cf length\n",
    "    rs=list(cpdic.keys())\n",
    "    nr=len(rs)\n",
    "\n",
    "    #--- types\n",
    "    ni_id=1\n",
    "    co_id=2\n",
    "    cr_id=3\n",
    "\n",
    "    std1 = {}\n",
    "    std2 = {}\n",
    "    std3 = {}\n",
    "    for r, indxx in zip(rs,range(0,nr,4)):\n",
    "        std1[indxx] = list(map(lambda x:x[ni_id],cpdic[r][0])) #--- local ni concentrations\n",
    "        std2[indxx] = list(map(lambda x:x[co_id],cpdic[r][0]))\n",
    "        std3[indxx] = list(map(lambda x:x[cr_id],cpdic[r][0]))\n",
    "\n",
    "        #--- histograms\n",
    "        zdata=std1[indxx] #(std1[indxx]-np.mean(std1[indxx]))/np.std(std1[indxx])\n",
    "        hist1, edges1, error1 = GetPDF( zdata, \n",
    "                                     linscale = True, \n",
    "                                     n_per_decade=24,\n",
    "                                     density = True,\n",
    "                                                )\n",
    "        hist2, edges2, error2 = GetPDF( (std2[indxx]-np.mean(std2[indxx]))/np.std(std2[indxx]), \n",
    "                                     linscale = True, \n",
    "                                     n_per_decade=24,\n",
    "                                     density = True,\n",
    "                                                )\n",
    "        hist3, edges3, error3 = GetPDF( (std3[indxx]-np.mean(std3[indxx]))/np.std(std3[indxx]), \n",
    "                                     linscale = True, \n",
    "                                     n_per_decade=24,\n",
    "                                     density = True,\n",
    "                                                )\n",
    "        ax1=utl.PltErr(edges1,hist1,\n",
    "                       yerr=error1,\n",
    "                       attrs=symbols.GetAttrs(count=0,nevery=2),\n",
    "                        yscale='log',\n",
    "                        xscale='linear',\n",
    "                        Plot=False,\n",
    "                        ax=ax1,\n",
    "#                         ylim=(1e-2,1e0),\n",
    "#                         xlim=(-3,3),\n",
    "                        title='PressFluc/pdfNiLocalConcentration.png',\n",
    "                        DrawFrame=[0.2,0.1,0.15,0.1,0.01],\n",
    "\n",
    "              )\n",
    "        np.savetxt('PressFluc/pdf_pNi_T%s.txt'%confParser['parameters']['temperature'],np.c_[hist1, edges1, error1],\n",
    "                   header='hist\\tedges\\terror')\n",
    "\n",
    "        \n",
    "        ax2=utl.PltErr(edges2,hist2,\n",
    "                       yerr=error2,\n",
    "                        markevery=2,markersize=9,\n",
    "                        yscale='log',\n",
    "                        xscale='linear',\n",
    "            #            xstr='r',\n",
    "            #            ystr='Std./Mean',\n",
    "                        Plot=False,\n",
    "                        ax=ax2,\n",
    "                        ylim=(1e-2,1e0),\n",
    "                        xlim=(-3,3),\n",
    "                        title='PressFluc/pdfCoLocalConcentration.png',\n",
    "                        DrawFrame=[0.2,0.1,0.15,0.1,0.01],\n",
    "\n",
    "              )\n",
    "        ax3=utl.PltErr(edges3,hist3,\n",
    "                       yerr=error3,\n",
    "                        markevery=2,markersize=9,\n",
    "                        yscale='log',\n",
    "                        xscale='linear',\n",
    "            #            xstr='r',\n",
    "            #            ystr='Std./Mean',\n",
    "                        Plot=False,\n",
    "                        ax=ax3,\n",
    "                        ylim=(1e-2,1e0),\n",
    "                        xlim=(-3,3),\n",
    "                        title='PressFluc/pdfCrLocalConcentration.png',\n",
    "                        DrawFrame=[0.2,0.1,0.15,0.1,0.01],\n",
    "\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### multiple temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval(confParser['flags']['PressFluc']) and not\\\n",
    "   eval(confParser['flags']['RemoteMachine']):\n",
    "    temps = [400,600,800,1000,1200,1400]\n",
    "    ax = utl.PltErr(None,None,Plot=False)\n",
    "    symbols=Symbols()\n",
    "    legend = Legends()\n",
    "    legend.Set(fontsize=16,\n",
    "           bbox_to_anchor=(0.54,0.39,0.5,0.5),\n",
    "                     labelspacing=0.2,\n",
    "          )\n",
    "    for temp,count in zip(temps,range(100)):\n",
    "        slist = np.loadtxt('NiCoCrNatom100KTemp%sRhoFluc/Run0/PressFluc/pdf_pNi_T%s.txt'%(temp,temp))\n",
    "        hist, edges, error=slist[:,0],slist[:,1],slist[:,2]\n",
    "        utl.PltErr(edges,hist,\n",
    "                       yerr=error,\n",
    "                       attrs=symbols.GetAttrs(count=count,nevery=2,label=r'$%s$'%temp),\n",
    "                        Plot=False,\n",
    "                       ax=ax,\n",
    "                  )\n",
    "    ax=utl.PltErr(None,None,attrs={'fmt':'.'},\n",
    "              legend=legend.Get(),\n",
    "               ax=ax,\n",
    "               xlim=(0,1),ylim=(4e-3,1e1),\n",
    "                        yscale='log',\n",
    "                        xscale='linear',\n",
    "                DrawFrame=[0.2,0.2,0.15,0.1,0.1],\n",
    "                     title='PressFluc/pdf_pNi_T.png',\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval(confParser['flags']['PressFluc']):\n",
    "    rs=list(cpdic.keys())\n",
    "    nr=len(rs)\n",
    "\n",
    "    ni_id=1\n",
    "    co_id=2\n",
    "    cr_id=3\n",
    "\n",
    "    std1 = np.zeros(nr)\n",
    "    std2 = np.zeros(nr)\n",
    "    std3 = np.zeros(nr)\n",
    "    for r, indxx in zip(rs,range(nr)):\n",
    "        std1[indxx] = np.std(list(map(lambda x:x[ni_id],cpdic[r][0])))\n",
    "        std2[indxx] = np.std(list(map(lambda x:x[co_id],cpdic[r][0])))\n",
    "        std3[indxx] = np.std(list(map(lambda x:x[cr_id],cpdic[r][0])))\n",
    "\n",
    "    np.savetxt('PressFluc/concentration_r.txt',np.c_[rs,std1,std2,std3],header='r\\tstdNi\\tstdCo\\tstdCr')\n",
    "    PltErr(rs,std1,\n",
    "        yscale='log',\n",
    "        xscale='log',\n",
    "        xstr='r',\n",
    "        ystr='Std./Mean',\n",
    "        title='PressFluc/var.png'\n",
    "\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval(confParser['flags']['PressFluc']) and not\\\n",
    "   eval(confParser['flags']['RemoteMachine']):\n",
    "    \n",
    "    #--- plot\n",
    "    symbols=Symbols()\n",
    "    lg = Legends()\n",
    "    lg.Set(fontsize=16,\n",
    "#           bbox_to_anchor=(0.5,0.4,0.5,0.5),\n",
    "          )\n",
    "\n",
    "    \n",
    "    pathh = {1:'NiCoCrNatom100KTemp800RhoFlucRss/Run0',\n",
    "             2:'NiCoCrNatom100KTemp400RhoFluc/Run0'\n",
    "            }[2]\n",
    "    rs,std1,std2,std3 = np.loadtxt('%s/PressFluc/concentration_r.txt'%pathh).T\n",
    "    #\n",
    "    ax=PltErr(rs,2*std1,\n",
    "        Plot=False,\n",
    "        attrs=symbols.GetAttrs(count=0,label='Ni')\n",
    "          )\n",
    "    PltErr(rs,1.2*std2,\n",
    "        Plot=False,\n",
    "        ax=ax,\n",
    "        attrs=symbols.GetAttrs(count=1,label='Co')\n",
    "          )\n",
    "    PltErr(rs,0.5*std3,\n",
    "        Plot=False,\n",
    "        ax=ax,\n",
    "        attrs=symbols.GetAttrs(count=2,label='Cr')\n",
    "          )\n",
    "    PltErr(rs,0.4/rs**1.5,\n",
    "          ax=ax,\n",
    "           attrs={'fmt':'-.r'},\n",
    "           xlim=(3,100),\n",
    "           ylim=(2e-3,1),\n",
    "        yscale='log',\n",
    "        xscale='log',\n",
    "#        xstr='$r$',\n",
    "#        ystr=r'$\\sigma$',\n",
    "        title='PressFluc/varSro.png',\n",
    "           Plot=True,\n",
    "        DrawFrame=[0.2,0.1,0.15,0.1,0.01],\n",
    "           legend=lg.Get(),\n",
    "          )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval(confParser['flags']['PressFluc']) and not\\\n",
    "   eval(confParser['flags']['RemoteMachine']):\n",
    "    \n",
    "    #--- plot\n",
    "    symbols=Symbols()\n",
    "    lg = Legends()\n",
    "    lg.Set(fontsize=16,\n",
    "#           bbox_to_anchor=(0.5,0.4,0.5,0.5),\n",
    "          )\n",
    "\n",
    "    \n",
    "    pathh = {1:'NiCoCrNatom100KTemp800RhoFlucRss/Run0',\n",
    "             2:'NiCoCrNatom100KTemp400RhoFluc/Run0'\n",
    "            }[1]\n",
    "    rs,std1,std2,std3 = np.loadtxt('%s/PressFluc/concentration_r.txt'%pathh).T\n",
    "    #\n",
    "    ax=PltErr(rs,2.2*std1*rs**1.5,\n",
    "        Plot=False,\n",
    "        attrs=symbols.GetAttrs(count=0)#,label='Ni')\n",
    "          )\n",
    "    PltErr(rs,1.5*std2*rs**1.5,\n",
    "        Plot=False,\n",
    "        ax=ax,\n",
    "        attrs=symbols.GetAttrs(count=1)#,label='Co')\n",
    "          )\n",
    "    PltErr(rs,std3*rs**1.5,\n",
    "        Plot=False,\n",
    "        ax=ax,\n",
    "        attrs=symbols.GetAttrs(count=2)#,label='Cr')\n",
    "          )\n",
    "    PltErr(None,None,\n",
    "          ax=ax,\n",
    "           attrs={'fmt':'-.r'},\n",
    "           xlim=(3,100),\n",
    "           ylim=(1e0,10),\n",
    "        yscale='log',\n",
    "        xscale='log',\n",
    "#        xstr='$r$',\n",
    "#        ystr=r'$\\sigma$',\n",
    "        title='PressFluc/varRssRescaled.png',\n",
    "           Plot=True,\n",
    "        DrawFrame=[0.2,0.1,0.15,0.1,0.01],\n",
    "#           legend=lg.Get(),\n",
    "          )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot\n",
    "#### Separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def ScatterPlt3d( clist, plist, \n",
    "                 Plot = True,\n",
    "                 **kwargs ):\n",
    "    xx = np.array(list(map(lambda x: x[1.0],clist)))\n",
    "    #\n",
    "    yy = np.array(list(map(lambda x: x[2.0],clist)))\n",
    "    #\n",
    "    zz = np.array(list(map(lambda x: x[3.0],clist))) #plist\n",
    "    #--- linear fit\n",
    "    reg = LinearRegression().fit(np.c_[xx,yy], zz)\n",
    "#     pdb.set_trace()\n",
    "\n",
    "    if 'zscore' in kwargs and kwargs['zscore']:\n",
    "        xx = Zscore(xx)\n",
    "        yy = Zscore(yy)\n",
    "        zz = Zscore(zz) #plist)\n",
    "\n",
    "    #--- plot\n",
    "    if Plot:\n",
    "        fig = plt.figure(figsize=(6,6))\n",
    "        ax = fig.add_subplot(111,projection='3d')\n",
    "        #\n",
    "        ax.set_xlabel(r'$p_{\\textrm{Ni}}$',fontsize=20)\n",
    "        ax.set_ylabel(r'$p_{\\textrm{Co}}$',fontsize=20)\n",
    "        ax.set_zlabel(r'$p_{\\textrm{Cr}}$',fontsize=20)\n",
    "        #\n",
    "        ax.tick_params(labelsize=18)\n",
    "        if 'zscore' in kwargs and kwargs['zscore']:\n",
    "            sigma=3\n",
    "            ax.set_xlim(-sigma,sigma)    \n",
    "            ax.set_ylim(sigma,-sigma)\n",
    "            ax.set_zlim(-sigma,sigma)\n",
    "            ax.scatter(0,0,0,c='red')\n",
    "        elif 'xlim' in kwargs:\n",
    "            ax.axis(kwargs['xlim'][0:4])    \n",
    "            ax.set_zlim(kwargs['xlim'][4:])\n",
    "            ax.scatter(0.33,1-0.33,0.33,c='red',s=100,zorder=5)\n",
    "            ax.set_yticks([0.2,0.4,0.6,0.8,1.0])\n",
    "            ax.set_yticklabels([r'$0.8$',r'$0.6$',r'$0.4$',r'$0.2$',r'$0.0$'])\n",
    "\n",
    "\n",
    "            \n",
    "        alpha=0.3\n",
    "        #\n",
    "        yy=1-yy\n",
    "        ax.scatter(xx,yy,zz,\n",
    "                    alpha=alpha,\n",
    "                   zorder=4,\n",
    "\n",
    "                  )\n",
    "#         ax.xaxis._axinfo['juggled']=(0,0,0)\n",
    "#         ax.yaxis._axinfo['juggled']=(1,1,1)\n",
    "#         ax.zaxis._axinfo['juggled']=(2,2,2)\n",
    "        \n",
    "        #--- projection\n",
    "        xflat = np.full_like(xx, min(ax.get_xlim()))\n",
    "        yflat = np.full_like(yy, max(ax.get_ylim()))\n",
    "        zflat = np.full_like(zz, min(ax.get_zlim()))\n",
    "        #\n",
    "        ax.scatter(xflat, yy, zz,c='black',alpha=alpha/8,zorder=3)\n",
    "        ax.scatter(xx, yflat, zz,c='black',alpha=alpha/8,zorder=2)\n",
    "        ax.scatter(xx, yy, zflat,c='black',alpha=alpha/8,zorder=1)\n",
    "        #\n",
    "        ax.scatter(0.33,1-0.33,0.33,c='red',s=100)\n",
    "\n",
    "        plt.savefig(kwargs['title'] if 'title' in kwargs else 'scatter.png',\n",
    "                    dpi=150*2,bbox_inches='tight',pad_inches=0.0)\n",
    "        plt.show()\n",
    "    #\n",
    "    return reg.coef_\n",
    "\n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "\n",
    "    # ScatterPlt3d( clist, plist, \n",
    "    # #               zscore = True, \n",
    "    #              xlim=[0.2,0.4,0.4,0.2],\n",
    "    #                 Plot = True,\n",
    "    #             )\n",
    "\n",
    "    d=0.32\n",
    "    index_r=8\n",
    "    coeffs = list(map(lambda x:\n",
    "                                ScatterPlt3d( cpdic[x[0]][0], cpdic[x[0]][1], \n",
    "                                                zscore = False, \n",
    "                                              #xlim=[0.33-d,.33+d,.33+d,.33-d,0.33-d,.33+d],\n",
    "                                              xlim=[1e-3,1,1e-3,1,1e-3,1],\n",
    "                                              Plot = True,\n",
    "                                              title='PressFluc/scatter3d_%s.png'%(x[1]),\n",
    "                                            ),    \n",
    "                                zip([rsub[2],rsub[1],rsub[0]],range(3))\n",
    "                                ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def ScatterPlt2d( clist, plist,\n",
    "                 ax,\n",
    "                 color,\n",
    "                 zorder,\n",
    "                 rsub=1.0,\n",
    "                 typee=1.0,\n",
    "                 Plot = True,\n",
    "                 **kwargs ):\n",
    "    xx = np.array(list(map(lambda x: x[typee],clist)))\n",
    "    #\n",
    "    zz = plist\n",
    "    #--- linear fit\n",
    "\n",
    "    if 'zscore' in kwargs and kwargs['zscore']:\n",
    "        xx = Zscore(xx)\n",
    "        zz = Zscore(plist)\n",
    "\n",
    "    #--- plot\n",
    "    if Plot:\n",
    "\n",
    "        if 'zscore' in kwargs and kwargs['zscore']:\n",
    "            sigma=3\n",
    "            ax.set_xlim(-sigma,sigma)    \n",
    "            ax.set_ylim(-sigma,sigma)\n",
    "        elif 'xlim' in kwargs:\n",
    "            ax.axis(kwargs['xlim'])    \n",
    "        alpha=.5\n",
    "        ax.scatter(xx, zz,c=color,alpha=alpha,marker='o',\n",
    "                   zorder=zorder, label='$%2.1f$'%rsub,\n",
    "                  )\n",
    "\n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    ax = fig.add_subplot(111)\n",
    "    #\n",
    "    ax.set_xlabel(r'Ni',fontsize=18)\n",
    "    ax.set_ylabel(r'$p$(Gpa)',fontsize=18)\n",
    "    #\n",
    "    ax.tick_params(labelsize=18)\n",
    "    #\n",
    "    d=0.3\n",
    "    dp=1.8\n",
    "    list(map(lambda x:\n",
    "            ScatterPlt2d( cpdic[x[0]][0],cpdic[x[0]][1],\n",
    "    #                    x[0][0], x[0][1],\n",
    "                         ax,\n",
    "                         x[1],\n",
    "                         x[2],\n",
    "                         rsub=x[0],\n",
    "                         typee=1.0,\n",
    "    #                     zscore = True, \n",
    "    #                     xlim=[0.33-d,.33+d,1.8-dp,1.8+dp],\n",
    "                          Plot = True,\n",
    "                        ),    \n",
    "    #        zip(cplist,['black','red','green','blue'],[4,3,2,1],[3600, 3800, 4000, 4200])\n",
    "            zip(rsub,['black','red','green','blue','C0','orange'],[6,5,4,3,2,1])\n",
    "            ))\n",
    "\n",
    "    ax.legend(fontsize=14)\n",
    "    plt.savefig('scatterNi.png',dpi=2*75,bbox_inches='tight')#,pad_inches=0.0)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    ax = fig.add_subplot(111)\n",
    "    #\n",
    "    ax.set_xlabel(r'Co',fontsize=18)\n",
    "    ax.set_ylabel(r'$p$(Gpa)',fontsize=18)\n",
    "    #\n",
    "    ax.tick_params(labelsize=18)\n",
    "    coeffs = list(map(lambda x:\n",
    "            ScatterPlt2d( cpdic[x[0]][0],cpdic[x[0]][1],\n",
    "    #                    x[0][0], x[0][1],\n",
    "                         ax,\n",
    "                         x[1],\n",
    "                         x[2],\n",
    "                         rsub=x[0],\n",
    "                         typee=2.0,\n",
    "                         zscore = True, \n",
    "    #                     xlim=[0.33-d,.33+d,1.8-dp,1.8+dp],\n",
    "                          Plot = True,\n",
    "                        ),    \n",
    "    #        zip(cplist,['black','red','green','blue'],[4,3,2,1],[3600, 3800, 4000, 4200])\n",
    "            zip(rsub,['black','red','green','blue','C0','orange'],[6,5,4,3,2,1])\n",
    "                                ))\n",
    "    ax.legend(fontsize=14)\n",
    "    plt.savefig('scatterCo.png',dpi=2*75,bbox_inches='tight')#,pad_inches=0.0)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### altogether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def ScatterPlt3d( clist, plist,\n",
    "                 ax,\n",
    "                 color,\n",
    "                 zorder,\n",
    "                 Plot = True,\n",
    "                 **kwargs ):\n",
    "    xx = np.array(list(map(lambda x: x[1.0],clist)))\n",
    "    #\n",
    "    yy = np.array(list(map(lambda x: x[2.0],clist)))\n",
    "    #\n",
    "    zz = plist\n",
    "    #--- linear fit\n",
    "    reg = LinearRegression().fit(np.c_[xx,yy], zz)\n",
    "#     pdb.set_trace()\n",
    "\n",
    "    if 'zscore' in kwargs and kwargs['zscore']:\n",
    "        xx = Zscore(xx)\n",
    "        yy = Zscore(yy)\n",
    "        zz = Zscore(plist)\n",
    "\n",
    "    #--- plot\n",
    "    if Plot:\n",
    "\n",
    "        if 'zscore' in kwargs and kwargs['zscore']:\n",
    "            sigma=3\n",
    "            ax.set_xlim(-sigma,sigma)    \n",
    "            ax.set_ylim(sigma,-sigma)\n",
    "            ax.set_zlim(-sigma,sigma)\n",
    "            ax.scatter(0,0,0,c='red')\n",
    "        elif 'xlim' in kwargs:\n",
    "            ax.axis(kwargs['xlim'])    \n",
    "    #         ax.set_ylim(ax.axis()[3],ax.axis()[2])\n",
    "\n",
    "        alpha=kwargs['alpha'] if 'alpha' in kwargs else .1\n",
    "        #\n",
    "        ax.scatter(xx,yy,zz,\n",
    "                    alpha=alpha,\n",
    "                   color='C0'\n",
    "\n",
    "                  )\n",
    "\n",
    "        #--- projection\n",
    "        xflat = np.full_like(xx, min(ax.get_xlim()))\n",
    "        yflat = np.full_like(yy, min(ax.get_ylim()))\n",
    "        zflat = np.full_like(zz, min(ax.get_zlim()))\n",
    "        \n",
    "        ax.scatter(xflat, yy, zz,c=color,alpha=alpha,zorder=zorder)\n",
    "        ax.scatter(xx, yflat, zz,c=color,alpha=alpha,zorder=zorder)\n",
    "        #\n",
    "    #\n",
    "    return reg.coef_\n",
    "\n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    ax = fig.add_subplot(111,projection='3d')\n",
    "    #\n",
    "    ax.set_xlabel(r'Ni',fontsize=18)\n",
    "    ax.set_ylabel(r'Co',fontsize=18)\n",
    "    ax.set_zlabel(r'$p$',fontsize=18)\n",
    "    #\n",
    "    ax.tick_params(labelsize=18)\n",
    "    #\n",
    "    #ax.set_title(r'$r=%s$ \\r{A}, $T=%s^\\circ K$'%(17,300),fontsize=18)\n",
    "    #\n",
    "    coeffs = list(map(lambda x:\n",
    "                                ScatterPlt3d( cpdic[x[0]][0], cpdic[x[0]][1],\n",
    "                                             ax,\n",
    "                                             'black',#x[1],\n",
    "                                             1,#x[2],\n",
    "                                                zscore = True, \n",
    "    #                                          xlim=[0.2,0.4,0.4,0.2],\n",
    "                                              Plot = True,\n",
    "                                             alpha=0.04,\n",
    "                                            ),    \n",
    "                                zip(rsub,range(len(rsub)))\n",
    "                                ))\n",
    "\n",
    "    plt.savefig('scatter.png',dpi=2*75,bbox_inches='tight',pad_inches=0.0)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlim(1e0,1e2)\n",
    "    ax.tick_params(labelsize=18)\n",
    "    ax.set_xlabel('$r$(\\r{A})',fontsize=18)\n",
    "    ax.set_ylabel('Coeffs',fontsize=18)\n",
    "    #\n",
    "    ax.plot(rsub,np.array(coeffs)[:,0],'-o',label='Ni')\n",
    "    ax.plot(rsub,np.array(coeffs)[:,1],'-s',label='Co')\n",
    "\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neighbor list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAtomsUnderIndenter():\n",
    "    keys = list(lmpData.coord_atoms_broken.keys())\n",
    "    keys.sort()\n",
    "    itime = keys[-1]\n",
    "    #\n",
    "    df_xyz = lmpData.coord_atoms_broken[itime]\n",
    "    #\n",
    "    box = lp.Box( BoxBounds = lmpData.BoxBounds[itime], AddMissing = np.array([0.0,0.0,0.0] ))\n",
    "    rc=box.CellOrigin+ np.matmul(box.CellVector,np.array([0.5,0.5,0.5]))\n",
    "    ly = 30.0;lx=30.0;lz=30.0\n",
    "    box0 = lp.Box( BoxBounds = np.c_[rc-np.array([lx,ly,lz]),rc+np.array([lx,ly,lz])], \n",
    "                 AddMissing = np.array([0.0,0.0,0.0] ))\n",
    "    #\n",
    "    atoms = lp.Atoms(**df_xyz.to_dict(orient='series'))\n",
    "    #\n",
    "    wrap = lp.Wrap(atoms,box0)\n",
    "    filtr = wrap.isInside()\n",
    "    atom_ids = list(df_xyz[filtr].index)\n",
    "    sfile = open('junk.xyz','w')\n",
    "    utl.PrintOvito(df_xyz[filtr], sfile, 0, attr_list=['id','type','x', 'y', 'z'])\n",
    "    sfile.close()\n",
    "    print(len(atom_ids))\n",
    "    return atom_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval(confParser['flags']['NeighList']):\n",
    "    natoms = min(lmpData.coord_atoms_broken[itime0].shape[0],\\\n",
    "                 eval(confParser['neigh list']['natom'])) #--- subset of atoms\n",
    "    atom_indices = GetAtomsUnderIndenter() #range(natoms) #--- under the indenter\n",
    "    np.savetxt('atom_indices.txt',atom_indices,fmt='%d')\n",
    "    #\n",
    "    cutoff = eval(confParser['neigh list']['cutoff'])\n",
    "    if eval(confParser['neigh list']['WritDisc']) and not eval(confParser['neigh list']['ReadDisc']):\n",
    "        try:\n",
    "            !rm neighList.xyz\n",
    "        except:\n",
    "            pass\n",
    "        path = confParser['input files']['path']\n",
    "        indx = confParser['input files']['fileIndex']\n",
    "        py_path=confParser['py library path']['py_lib']\n",
    "        fileName = '%s/%s'%(path,confParser['input files']['filename'].split()[int(indx)])\n",
    "        nevery = int(confParser['parameters']['nevery'])\n",
    "        t0=time.time()\n",
    "        !ovitos $py_path/OvitosCna.py $fileName neighList.xyz $nevery 4 $cutoff atom_indices.txt\n",
    "        print('output neighbor list=%s s'%(time.time()-t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval(confParser['flags']['NeighList']):\n",
    "    t0=time.time()\n",
    "    lmpNeigh = lp.ReadDumpFile( 'neighList.xyz' )\n",
    "    lmpNeigh.GetCords( ncount = sys.maxsize)\n",
    "    print('load neighbor list=%s s'%(time.time()-t0))\n",
    "    keys = list(lmpNeigh.coord_atoms_broken.keys())\n",
    "    keys.sort()\n",
    "    print('times=',keys)\n",
    "    display(lmpNeigh.coord_atoms_broken[keys[0]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order parameter\n",
    "## 2d map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: orderParameter: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir orderParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridSize(box0, cutoff, dr,verbose=False):\n",
    "    lx=2*cutoff #box0.CellVector[0,0]\n",
    "    ly=2*cutoff #box0.CellVector[1,1]\n",
    "    lz=2*cutoff #box0.CellVector[2,2]\n",
    "    nx = int(lx/dr)\n",
    "    ny = int(ly/dr)\n",
    "    nz = int(lz/dr)\n",
    "    if nx % 2 == 0:\n",
    "        nx+=1\n",
    "    if ny % 2 == 0:\n",
    "        ny+=1\n",
    "    if nz % 2 == 0:\n",
    "        nz+=1\n",
    "    if verbose:\n",
    "        print('grid size=',nx,ny,nz)\n",
    "    return (ny,nx,nz), [(-0.5*ly,0.5*ly),(-0.5*lx,0.5*lx),(-0.5*lz,0.5*lz)]\n",
    "\n",
    "\n",
    "def GetHistd(lmpNeigh, nxyz, rangee, pair, verbose=True):\n",
    "    (typei,typej) = pair\n",
    "    if verbose:\n",
    "        print('pair=',pair)\n",
    "    #--- filter\n",
    "    keys = list(lmpNeigh.coord_atoms_broken.keys())\n",
    "    keys.sort()\n",
    "    count = 0\n",
    "    for itime in keys[1:]:\n",
    "        df = lmpNeigh.coord_atoms_broken[itime]\n",
    "        indx = np.all([df.type==typei,df.Jtype==float(typej)], axis=0)\n",
    "#    display(df[indx])\n",
    "    #--- binning\n",
    "        r = np.concatenate([df[indx][['DY','DX','DZ']],-df[indx][['DY','DX','DZ']]],axis=0) if count == 0 \\\n",
    "        else np.concatenate([r, df[indx][['DY','DX','DZ']],-df[indx][['DY','DX','DZ']]],axis=0)\n",
    "        count += 1\n",
    "    H, edges = np.histogramdd(r, bins = nxyz, range=rangee)\n",
    "    if verbose:\n",
    "        print('r.shape=',r.shape) #, edges[0].size, edges[1].size, edges[2].size\n",
    "#    assert not np.any(H == 0.0), 'increase bin size!'\n",
    "    return H, edges\n",
    "\n",
    "\n",
    "def GetPairProb(lmpNeigh, lmpData, types, cutoff, dr ):\n",
    "#     pair=(2,2)\n",
    "#     H = GetHistd(\n",
    "#                     lmpNeigh.coord_atoms_broken[0],\n",
    "#                     rangee,\n",
    "#                     pair\n",
    "#                 )\n",
    "    keys = list(lmpNeigh.coord_atoms_broken.keys())\n",
    "    keys.sort()\n",
    "    itime = keys[0]\n",
    "    box = lp.Box( BoxBounds = lmpData.BoxBounds[itime], AddMissing = np.array([0.0,0.0,0.0] ))\n",
    "    nxyz, xlohi = GridSize(box, cutoff, dr)\n",
    "    \n",
    "#    pair_i,pair_j = np.meshgrid(types,types)\n",
    "#    Pairs = list(zip(pair_j.flatten(),pair_i.flatten()))\n",
    "\n",
    "#    pdb.set_trace()\n",
    "    ncut=10\n",
    "    prob={}\n",
    "    for itype in types:\n",
    "        pairs = []\n",
    "        for jtype in types:\n",
    "            pairs.append((itype,jtype))\n",
    "        H = list(map(lambda x: GetHistd( lmpNeigh, nxyz, xlohi, x)[0],pairs))\n",
    "        probt = reduce(lambda x, y: x+y, H ) #--- sum\n",
    "        filtr=probt<ncut\n",
    "#        plt.hist(probt[filtr])\n",
    "        probt[filtr]=np.nan\n",
    "        print('min=',probt[probt>0].min())\n",
    "        prob[itype] = list(map(lambda x:H[x]/probt,range(len(pairs))))\n",
    "\n",
    "    return prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if eval(confParser['flags']['SroParameter']):\n",
    "    keys = list(lmpNeigh.coord_atoms_broken.keys())\n",
    "    keys.sort()\n",
    "    types=[1,2] #--- type_i + all type_j's\n",
    "    dr=0.3 #--- discretization\n",
    "    \n",
    "    \n",
    "    sdict = GetPairProb(lmpNeigh, lmpData, types,cutoff,dr)\n",
    "    \n",
    "    #--- get bin_edges\n",
    "    itime = keys[-1]\n",
    "    box = lp.Box( BoxBounds = lmpData.BoxBounds[itime], AddMissing = np.array([0.0,0.0,0.0] ))\n",
    "    nxyz, xlohi = GridSize(box, cutoff, dr)\n",
    "    _, edges = np.histogramdd(np.array([[0,0,0]]), bins = nxyz, range=xlohi)\n",
    "\n",
    "    #--- print H\n",
    "    for itype in types:\n",
    "        for jtype, indx in zip(types,range(len(types))):\n",
    "            H = sdict[itype][indx]\n",
    "            np.savetxt('orderParameter/wc3d_itype%s_jtype%s.txt'%(itype,jtype),H.flatten())\n",
    "    np.savetxt('orderParameter/reshape.txt',nxyz,fmt='%d')\n",
    "    np.savetxt('orderParameter/edges.txt',np.c_[edges].T)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bitmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval(confParser['flags']['SroParameter']) and not\\\n",
    "  eval(confParser['flags']['RemoteMachine']): #--- uncomment!!!1\n",
    "    \n",
    "    path='AmirData/NiAl/Swapped_300/Run0'\n",
    "    \n",
    "    plane=[(0,'y'),(1,'x'),(2,'z')][1] #--- 2d plane\n",
    "\n",
    "    H     = np.loadtxt('%s/orderParameter/wc3d_itype2_jtype2.txt'%path)\n",
    "    plt.hist(H)\n",
    "    print('rcc=',H[~np.isnan(H)].mean())\n",
    "    H[np.isnan(H)]=0.0\n",
    "\n",
    "    #\n",
    "    nxyz  = np.loadtxt('%s/orderParameter/reshape.txt'%path,dtype=int)\n",
    "    edges = np.loadtxt('%s/orderParameter/edges.txt'%path).T\n",
    "    \n",
    "    H = H.reshape(nxyz)\n",
    "\n",
    "    #--- plot\n",
    "    n_center = int(nxyz[plane[0]]/2)\n",
    "    if plane[1] == 'y':\n",
    "        map2d=H[n_center,:,:]\n",
    "        ylabel='$x$'\n",
    "        xlabel='$z$'\n",
    "        xlim=(edges[2].min(),edges[2].max())\n",
    "        ylim=(edges[0].min(),edges[0].max())\n",
    "\n",
    "    elif plane[1] == 'x':\n",
    "        map2d=H[:,n_center,:]\n",
    "        ylabel='$y$'\n",
    "        xlabel='$z$'\n",
    "        xlim=(edges[2].min(),edges[2].max())\n",
    "        ylim=(edges[1].min(),edges[1].max())\n",
    "    else:\n",
    "        map2d=H[:,:,n_center]\n",
    "        ylabel='$y$'\n",
    "        xlabel='$x$'\n",
    "        xlim=(edges[1].min(),edges[1].max())\n",
    "        ylim=(edges[0].min(),edges[0].max())\n",
    "\n",
    "#    map2d -= rss\n",
    "#     for k in range(nxyz[2]):\n",
    "#         map2d[:,k]=range(nxyz[1])\n",
    "#    map2d[np.isnan(map2d)]=0.0\n",
    "    utl.PltBitmap(map2d,\n",
    "                  zscore=False,\n",
    "                  colorbar=True,\n",
    "                  xlim=xlim,\n",
    "                  ylim=ylim,\n",
    "#                  vminmax=(0,1),\n",
    "#                  cmap='seismic',\n",
    "                  ylabel=ylabel,xlabel=xlabel,\n",
    "                  title='orderParameter/wc_2dmap_pnini_sro.png',\n",
    "                 interpolation='bicubic',\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### projected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if eval(confParser['flags']['SroParameter']) and not\\\n",
    "   eval(confParser['flags']['RemoteMachine']): #--- uncomment!!!1\n",
    "    \n",
    "    rss = 0.1 #0.333\n",
    "\n",
    "\n",
    "    center = np.array(nxyz)/2\n",
    "    legend = Legends()\n",
    "    legend.Set(bbox_to_anchor=(0.5,0.48,0.5,0.5))\n",
    "\n",
    "    ax=utl.PltErr([0,cutoff],[rss,rss],yerr=None,\n",
    "              attrs={'fmt':'-.','color':'red','label':r'$\\mathrm{rss}$'},\n",
    "                Plot=False,\n",
    "              )\n",
    "    #--- along y=z\n",
    "    val = [map2d[i,i] for i in range(map2d.shape[0])]\n",
    "    r = np.sqrt(edges[0]**2+edges[2]**2 )\n",
    "    #\n",
    "    utl.PltErr(r[:-1],val,yerr=None,\n",
    "              attrs={'fmt':'-','label':'$y=z$'},\n",
    "                ax=ax,\n",
    "               Plot=False,\n",
    "              )\n",
    "    \n",
    "    #--- along z at center y\n",
    "    indx = 0 #--- y\n",
    "    val = map2d[int(center[indx]),:]\n",
    "    #\n",
    "    utl.PltErr(edges[indx][:-1],val,yerr=None,\n",
    "              attrs={'fmt':'-','label':'$z$'},\n",
    "                ax=ax,\n",
    "               Plot=False,\n",
    "              )\n",
    "\n",
    "    #--- along y at center z\n",
    "    indx = 2 #--- z\n",
    "    val = map2d[:,int(center[indx])]\n",
    "    utl.PltErr(edges[indx][:-1],val,yerr=None,\n",
    "              attrs={'fmt':'-','marker':'s','label':'$y$'},\n",
    "               ax=ax,\n",
    "               xlim=(2.5,cutoff),\n",
    "    #           ylim=(0,1),\n",
    "#               xstr=r'$r(\\r{A})$',ystr=r'$p_\\mathrm{NiNi}$',\n",
    "               legend=legend.Get(),\n",
    "                title='orderParameter/wc_pnini_sro.png'\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## radial part\n",
    "### RDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Wrapper(lmpNeigh,lmpData,itime):\n",
    "    box = lp.Box( BoxBounds = lmpData.BoxBounds[itime], AddMissing = np.array([0.0,0.0,0.0] ))\n",
    "    atoms = lp.Atoms( **lmpData.coord_atoms_broken[itime].to_dict(orient='series') )\n",
    "    neigh = lmpNeigh.coord_atoms_broken[itime]\n",
    "\n",
    "\n",
    "    rdf = lp.ComputeRdf(  atoms, box )\n",
    "    rdf.PairCrltn(  \n",
    "                  bins=np.arange(0.99*neigh.DIST.min(),cutoff,0.1), \n",
    "                  rlist=neigh.DIST,\n",
    "                  regular_r = True,\n",
    "                  )\n",
    "    return rdf.Get()\n",
    "\n",
    "\n",
    "if eval(confParser['flags']['SroParameter']):\n",
    "    keys = list(lmpNeigh.coord_atoms_broken.keys())\n",
    "    keys.sort()\n",
    "\n",
    "    itime=keys[-1]\n",
    "    itime0=keys[0]\n",
    "    bin_edges1, hist1, err1 = Wrapper(lmpNeigh,lmpData,itime)\n",
    "    bin_edges0, hist0, err0 = Wrapper(lmpNeigh,lmpData,itime0)\n",
    "    \n",
    "#     filtr=~np.isnan(bin_edges1)\n",
    "#     bin_edges1 = bin_edges1[filtr]\n",
    "#     hist1 = hist1[filtr]\n",
    "#     err1 = err1[filtr]\n",
    "\n",
    "#     filtr=~np.isnan(bin_edges0)\n",
    "#     bin_edges0 = bin_edges0[filtr]\n",
    "#     hist0 = hist0[filtr]\n",
    "#     err0 = err0[filtr]\n",
    "\n",
    "    #--- plot\n",
    "    symbols=Symbols()\n",
    "    ax = utl.PltErr(bin_edges1,hist1,err1,\n",
    "#          xlim=[2,5],\n",
    "                        attrs=symbols.GetAttrs(count=0,zorder=2),      \n",
    "\n",
    "                Plot=False,\n",
    "#                xscale='log',\n",
    "          )\n",
    "\n",
    "    utl.PltErr(bin_edges0,hist0,err0,\n",
    "          xlim=[0,4],#cutoff],\n",
    "    #       ystr='$g(r)$',\n",
    "    #       xstr='$r$',\n",
    "           title='orderParameter/gr_sheng.png',\n",
    "                        attrs=symbols.GetAttrs(count=1,zorder=1),      \n",
    "                Plot=True,\n",
    "           ax=ax,\n",
    "    #        DrawFrame=[0.2,0.1,0.15,0.1,0.1],\n",
    "           fontsize=24,\n",
    "#                xscale='log',\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fit a spline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReturnShapeFunc(x,df):\n",
    "    transformed_x = patsy.bs(x, df=df,degree =3, include_intercept=False)\n",
    "    return transformed_x \n",
    "\n",
    "def TrainModel(x,y):\n",
    "    reg = LinearRegression().fit(x, y )\n",
    "    return reg\n",
    "def Validate(reg, x,y,\n",
    "             deg_f=np.arange(0,90,5), #np.logspace(0.0,8.0,9,base=2).astype(int),\n",
    "             cv_samples=10):\n",
    "    mse={}\n",
    "    for df in deg_f:\n",
    "#    for df in map(int,np.logspace(0,12,20,base=2,endpoint=True)):\n",
    "        try:\n",
    "            transfrm = ReturnShapeFunc(x,df)\n",
    "            #--- vadidate    \n",
    "            scores = cross_validate(reg,  transfrm, y, cv=cv_samples,\n",
    "                                         scoring=('r2', 'neg_mean_squared_error'),\n",
    "                                         return_train_score=True)\n",
    "            mse[df] = np.mean(scores['train_neg_mean_squared_error'])\n",
    "        except:\n",
    "            continue\n",
    "    return mse\n",
    "\n",
    "\n",
    "# #--- training points\n",
    "# transfrm = ReturnShapeFunc(bin_edges1,50)\n",
    "    \n",
    "# #--- train\n",
    "# reg = TrainModel(transfrm,np.c_[hist1])\n",
    "\n",
    "# #--- prediction\n",
    "# y_pred = reg.predict( transfrm )\n",
    "\n",
    "\n",
    "# #--- plot\n",
    "# ax = PltErr(bin_edges1,hist1,err1,\n",
    "#       xlim=[2,cutoff],\n",
    "#         attrs={\n",
    "#                'fmt':'o',\n",
    "#                'color':'black',\n",
    "#                'markerfacecolor':'white',\n",
    "#                'zorder':1,\n",
    "#               },\n",
    "#             Plot=False\n",
    "#       )\n",
    "\n",
    "# PltErr(bin_edges1,y_pred,\n",
    "#       xlim=[2,cutoff],\n",
    "# #       ystr='$g(r)$',\n",
    "# #       xstr='$r$',\n",
    "# #       title='orderParameter/gr_sheng.png',\n",
    "#                 attrs={#'label':r'$\\mathrm{without~annealing}$',\n",
    "#                        'fmt':'-',\n",
    "#                        'markersize':9,\n",
    "#                        'markevery':1,\n",
    "#                        'color':'red',\n",
    "#                'zorder':2,\n",
    "#                       },\n",
    "#             Plot=True,\n",
    "#        ax=ax,\n",
    "# #        DrawFrame=[0.2,0.1,0.15,0.1,0.1],\n",
    "#        fontsize=24,\n",
    "#       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse = Validate(reg, bin_edges1,np.c_[hist1])\n",
    "# try:\n",
    "#     keys=mse.keys()\n",
    "#     plt.scatter(keys, [-mse[key] for key in keys],marker='x')\n",
    "#     plt.yscale('log')\n",
    "# #    plt.xscale('log')\n",
    "# #    plt.ylim(1e-5,1e-2)\n",
    "# #    plt.savefig('cv.png',dpi=75,bbox_inches='tight')\n",
    "#     plt.show()\n",
    "# except:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2nd method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_spline_roots(spl):\n",
    "    roots = []\n",
    "    knots = spl.get_knots()\n",
    "    for a, b in zip(knots[:-1], knots[1:]):\n",
    "        u, v, w = spl(a), spl((a+b)/2), spl(b)\n",
    "        t = np.roots([u+w-2*v, w-u, 2*v])\n",
    "        t = t[np.isreal(t) & (np.abs(t) <= 1)]\n",
    "        roots.extend(t*(b-a)/2 + (b+a)/2)\n",
    "    return np.array(roots)\n",
    "\n",
    "def GetExtrema(bin_edges1,hist1,r0,verbose=True):\n",
    "    y_axis=hist1\n",
    "    x_axis=bin_edges1\n",
    "    f = InterpolatedUnivariateSpline(x_axis, y_axis, k=4)\n",
    "    \n",
    "    ext=f.derivative().roots() #--- roots\n",
    "    spl_dd=f.derivative().derivative()\n",
    "    valleys=ext[np.all([spl_dd(ext)>0,ext>r0],axis=0)]\n",
    "    peaks=ext[np.all([spl_dd(ext)<0,ext>r0],axis=0)]\n",
    "\n",
    "\n",
    "#     cr_pts = quadratic_spline_roots(f.derivative())\n",
    "#     cr_pts = np.append(cr_pts, (x_axis[0], x_axis[-1]))  # also check the endpoints of the interval\n",
    "#     cr_pts = cr_pts[cr_pts>r0]\n",
    "#     ddf=f.derivative().derivative()\n",
    "#     peaks = np.sort(cr_pts[ddf(cr_pts)<0.0])\n",
    "#     valleys = np.sort(cr_pts[ddf(cr_pts)>0.0])\n",
    "    \n",
    "    if len(valleys) == 0:\n",
    "        cutoff = eval(confParser['neigh list']['cutoff'])\n",
    "        valleys = [cutoff]\n",
    "        \n",
    "    rpeak   = peaks[0]\n",
    "    rvalley = valleys[0]\n",
    "    if rvalley > rpeak:\n",
    "        valleys = np.concatenate([np.array([0]),valleys])\n",
    "    if verbose:\n",
    "        print('peaks of g(r) at:r=',peaks)\n",
    "        print('valleys of g(r) at:r=',valleys)\n",
    "    \n",
    "    return x_axis, f, valleys\n",
    "\n",
    "\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline\n",
    "\n",
    "if eval(confParser['flags']['SroParameter']):\n",
    "    \n",
    "    \n",
    "    x_axis, f, valleys = GetExtrema(bin_edges1,hist1,2.3)\n",
    "    \n",
    "    #--- plot\n",
    "    ax = utl.PltErr(bin_edges1,hist1,err1,\n",
    "            attrs={\n",
    "                   'fmt':'o',\n",
    "                   'color':'black',\n",
    "                   'markerfacecolor':'white',\n",
    "                   'markersize':4,\n",
    "                   'zorder':1,\n",
    "                  },\n",
    "                Plot=False\n",
    "          )\n",
    "\n",
    "    utl.PltErr(x_axis,f(x_axis),\n",
    "          xlim=[0,cutoff],\n",
    "    #       ystr='$g(r)$',\n",
    "    #       xstr='$r$',\n",
    "    #       title='gr_sheng_T800K.png',\n",
    "                    attrs={#'label':r'$\\mathrm{without~annealing}$',\n",
    "                           'fmt':'-',\n",
    "                           'markersize':9,\n",
    "                           'markevery':1,\n",
    "                           'color':'red',\n",
    "                   'zorder':2,\n",
    "                          },\n",
    "                Plot=False,\n",
    "           ax=ax,\n",
    "    #        DrawFrame=[0.2,0.1,0.15,0.1,0.1],\n",
    "           fontsize=24,\n",
    "          )\n",
    "\n",
    "    #--- remove valleys that are too close!\n",
    "    filtr = np.diff(valleys,prepend=valleys[-1]) >0.25\n",
    "    valleys = np.append(0,valleys[filtr])\n",
    "    utl.PltErr(valleys,np.ones(len(valleys)),\n",
    "           ax=ax,\n",
    "           attrs={'fmt':'x','markersize':10}\n",
    "          )\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WC order parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Wrapper(itime,pairi,pairj,**kwargs):\n",
    "    box = lp.Box( BoxBounds = lmpData.BoxBounds[itime], AddMissing = np.array([0.0,0.0,0.0] ))\n",
    "    atoms = lp.Atoms( **lmpData.coord_atoms_broken[itime].to_dict(orient='series') )\n",
    "    neigh = lmpNeigh.coord_atoms_broken[itime]\n",
    "\n",
    "    \n",
    "    rdf = lp.ComputeRdf(  atoms, box )\n",
    "    bins = np.arange(0.99*neigh.DIST.min(),cutoff,0.1) if 'bins' not in kwargs else kwargs['bins']\n",
    "    rdf.PairCrltn(  \n",
    "                  bins=bins, \n",
    "                  rlist=neigh.DIST )\n",
    "    return rdf.Sro(neigh,pairi,pairj,bins=bins)\n",
    "\n",
    "    \n",
    "\n",
    "if eval(confParser['flags']['SroParameter']):\n",
    "    keys = list(lmpNeigh.coord_atoms_broken.keys())\n",
    "    keys.sort()\n",
    "    itime=keys[-1]\n",
    "    itime0=keys[0]\n",
    "    #---\n",
    "    p0={}\n",
    "    p1={}\n",
    "    dp0={}\n",
    "    dp1={}\n",
    "    count = 0\n",
    "#    for pairi, pairj in [(1,1),(1,2),(1,3),(2,2),(2,3),(3,3)]: #--- different elemental pairs\n",
    "    for pairi, pairj in [(1,1),(1,2),(2,1),(2,2)]: #--- different elemental pairs\n",
    "        bin_edges0, p0[count], dp0[count] = Wrapper(itime0,pairi,pairj,bins=valleys) #--- rss\n",
    "        bin_edges1, p1[count], dp1[count] = Wrapper(itime,pairi,pairj,bins=valleys) #--- sro\n",
    "        count += 1\n",
    "        \n",
    "    count = 3\n",
    "    ax=    utl.PltErr(bin_edges1,p1[count],yerr=dp1[count],\n",
    "                Plot=False,\n",
    "                attrs={#'label':r'$\\mathrm{with~annealing}$',\n",
    "                       'fmt':'-o',\n",
    "                       'markersize':9,\n",
    "                       'markevery':1,\n",
    "                       'color':'black',\n",
    "                       'markerfacecolor':'white',\n",
    "                       'zorder':2,\n",
    "                      },\n",
    "              )\n",
    "    \n",
    "    ax = utl.PltErr(bin_edges0,p0[count],yerr=dp0[count],\n",
    "               ax=ax,\n",
    "                Plot=False,\n",
    "                attrs={#'label':r'$\\mathrm{without~annealing}$',\n",
    "                       'fmt':'-s',\n",
    "                       'markersize':9,\n",
    "                       'markevery':1,\n",
    "                       'color':'red',\n",
    "                       'zorder':1,\n",
    "                      }\n",
    "              )\n",
    "\n",
    "    utl.PltErr([0,cutoff],[0.33,0.33],\n",
    "              xlim=[2,cutoff],\n",
    "              ylim=[0,1],\n",
    "               ax=ax,\n",
    "               attrs={'fmt':'-.r'},\n",
    "#               title='wc_%s%s_farkas_T800K.png'%(pairi,pairj),\n",
    "#               ystr='$p_{%s%s}(r)$'%(pairi,pairj),\n",
    "#               xstr='$r$',\n",
    "#               legend=True,\n",
    "#               fontsize=18,\n",
    "           DrawFrame=[0.2,0.1,0.15,0.1,0.1],\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### temporal fluctuations and mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval(confParser['flags']['SroParameter']):\n",
    "    times = list(lmpNeigh.coord_atoms_broken.keys()) #[itime] # #--- list of timesteps\n",
    "    times.sort()\n",
    "    itime0=times[0]\n",
    "    if len(times) > 1:\n",
    "        times.remove(itime0) #--- exclude 0\n",
    "    #--- loop over pairs\n",
    "    count = 0\n",
    "    data = {}\n",
    "    p1_mean = {}\n",
    "    err_p1 = {}\n",
    "    for pairi, pairj in [(1,1),(1,2),(2,1),(2,2)]: #(1,3),(2,2),(2,3),(3,3)]:\n",
    "        data[count] = np.c_[list(map(lambda x:Wrapper(x,pairi,pairj,bins=valleys)[1],times))].T #--- data corresponding to different times\n",
    "        p1_mean[count] = np.mean(data[count],axis=1) #--- mean\n",
    "        err_p1[count] = ((np.mean(data[count]*data[count],axis=1) - p1_mean[count]*p1_mean[count])/len(times))**0.5\n",
    "\n",
    "        #--- print\n",
    "        np.savetxt('orderParameter/pr_annealed_ij_index%s.txt'%count,\n",
    "                   np.c_[bin_edges1,p1_mean[count],err_p1[count]],\n",
    "                   header='r\\tp\\terr_p')\n",
    "        np.savetxt('orderParameter/pr_non_annealed_ij_index%s.txt'%count,\n",
    "                   np.c_[bin_edges0,p0[count],dp0[count]],\n",
    "                   header='r\\tp\\terr_p')\n",
    "        count += 1\n",
    "    #--- plot\n",
    "    count = 0\n",
    "    for indxx in range(data[count].shape[1]):\n",
    "        kwargs={} if indxx == 0 else {'ax':ax}\n",
    "        ax = utl.PltErr(bin_edges1, data[count][:,indxx],\n",
    "                    Plot=False,\n",
    "                    xstr='r',\n",
    "                    ystr='p11',\n",
    "                    ylim=[0,1],\n",
    "                    attrs={'fmt':'-o'},\n",
    "                   **kwargs,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if eval(confParser['flags']['SroParameter']) and not\\\n",
    "   eval(confParser['flags']['RemoteMachine']):\n",
    "    \n",
    "    cutoff = eval(confParser['neigh list']['cutoff'])\n",
    "\n",
    "    #--- plot\n",
    "    symbols=Symbols()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "    p0={}\n",
    "    p1={}\n",
    "    dp0={}\n",
    "    dp1={}\n",
    "    temp = 400\n",
    "    pathh = 'AmirData/NiAl/annealing/Run0'\n",
    "    p1_mean = {}\n",
    "    err_p1 = {}\n",
    "    rcc={1:0.9,2:0.1}\n",
    "    for pairi, pairj in [(1,1),(1,2),(2,1),(2,2)]: #[(1,1),(1,2),(1,3),(2,2),(2,3),(3,3)]:\n",
    "        print('pair', pairi, pairj )\n",
    "#         data[count] = np.c_[list(map(lambda x:Wrapper(x,pairi,pairj)[1],times))].T #--- data corresponding to different times\n",
    "#         p1_mean[count] = np.mean(data[count],axis=1) #--- mean\n",
    "#         err_p1[count] = ((np.mean(data[count]*data[count],axis=1) - p1_mean[count]*p1_mean[count])/len(times))**0.5\n",
    "\n",
    "        #--- print\n",
    "        bin_edges1,p1_mean[count],err_p1[count] = np.loadtxt('%s/orderParameter/pr_annealed_ij_index%s.txt'%(pathh,count)).T\n",
    "        bin_edges0,p0[count],dp0[count] = np.loadtxt('%s/orderParameter/pr_non_annealed_ij_index%s.txt'%(pathh,count)).T\n",
    "        \n",
    "        \n",
    "        #--- plot\n",
    "        ax=    utl.PltErr(bin_edges1,p1_mean[count],yerr=2*err_p1[count],\n",
    "                    Plot=False,\n",
    "                        attrs=symbols.GetAttrs(count=0,zorder=2),      \n",
    "                  )\n",
    "\n",
    "#         ax = utl.PltErr(bin_edges0,p0[count],yerr=2*dp0[count],\n",
    "#                    ax=ax,\n",
    "#                     Plot=False,\n",
    "#                         attrs=symbols.GetAttrs(count=1,zorder=1),      \n",
    "#                   )\n",
    "\n",
    "        utl.PltErr([0,cutoff],[rcc[pairj],rcc[pairj]],\n",
    "                  xlim=[2.5,cutoff],\n",
    "#                  ylim=[0,1],#[0.1,.7],\n",
    "                   ax=ax,\n",
    "                   attrs={'fmt':'-.r'},\n",
    "#                   title='orderParameter/wc_%s%s_farkas_T%sK.png'%(pairi,pairj,temp),\n",
    "                   title='orderParameter/wc_%s%s.png'%(pairi,pairj),\n",
    "                       ystr='$p_{%s%s}(r)$'%(pairi,pairj),\n",
    "                       xstr='$r$',\n",
    "                       dpi=70,\n",
    "        #               legend=True,\n",
    "        #               fontsize=18,\n",
    "               DrawFrame=[0.2,0.1,0.15,0.1,0.1],\n",
    "                  )\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if eval(confParser['flags']['SroParameter']) and not\\\n",
    "   eval(confParser['flags']['RemoteMachine']):\n",
    "    \n",
    "    #--- loop over elemental pairs\n",
    "    count = 0\n",
    "    rpeak = 2.5\n",
    "    for pairi, pairj in [(1,1),(1,2),(1,3),(2,2),(2,3),(3,3)]:\n",
    "        print('pair',pairi,pairj)\n",
    "        \n",
    "        p0[count] = 0.33 #--- equi-molar \n",
    "        \n",
    "        #--- plot difference\n",
    "        ax=utl.PltErr(bin_edges1,p1_mean[count]-p0[count],\n",
    "                        Plot=False,\n",
    "                        attrs={#'label':r'$\\mathrm{with~annealing}$',\n",
    "                               'fmt':'-o',\n",
    "                               'markersize':9,\n",
    "                               'markevery':1,\n",
    "                               'color':'black',\n",
    "                               'markerfacecolor':'white',\n",
    "                               'zorder':2,\n",
    "                              },\n",
    "                      )\n",
    "        \n",
    "        #--- plot base line\n",
    "        utl.PltErr([0,cutoff],[0.0,0.0],\n",
    " #         xlim=[0,cutoff],\n",
    " #         ylim=[0.1,.7],\n",
    "           ax=ax,\n",
    "           attrs={'fmt':'-.r'},\n",
    "#           title='orderParameter/wc_%s%s_sheng.png'%(pairi,pairj),\n",
    "#               ystr='$p_{%s%s}(r)$'%(pairi,pairj),\n",
    "#               xstr='$r$',\n",
    "#               legend=True,\n",
    "#               fontsize=18,\n",
    "#       DrawFrame=[0.2,0.1,0.15,0.1,0.1],\n",
    "          )\n",
    "        \n",
    "        \n",
    "        #--- save delta_p\n",
    "#        filtr = np.all([~np.isnan(p1_mean[count]-p0[count]),bin_edges1>rpeak],axis=0)\n",
    "#        val=(p1_mean[count]-p0[count]) #[filtr]\n",
    "#        r_sro = bin_edges1[filtr][val<0.0][0]\n",
    "#        print('sro size=',r_sro)\n",
    "#        np.savetxt('%s/orderParameter/sroSize_ij_index%s.txt'%(pathh,count),np.c_[temp,r_sro],header='temp\\tsize')\n",
    "        np.savetxt('%s/orderParameter/deltap_r_ij_index%s.txt'%(pathh,count),np.c_[bin_edges1,p1_mean[count]-p0[count]],header='r\\tdp')\n",
    "        count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multiple Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if eval(confParser['flags']['SroParameter']) and not\\\n",
    "   eval(confParser['flags']['RemoteMachine']):\n",
    "    \n",
    "    indxx = 0 #--- NiNi\n",
    "    #--- plot order parameter vs. distance\n",
    "    symbols=Symbols()\n",
    "    lg = Legends()\n",
    "    lg.Set(fontsize=16,\n",
    "           bbox_to_anchor=(0.5,0.4,0.5,0.5),\n",
    "          )\n",
    "    ax = utl.PltErr(None,None,Plot=False)\n",
    "                \n",
    "\n",
    "    #--- loop over temp\n",
    "    Temps  = {\n",
    "#            0:300,\n",
    "            1:400,\n",
    "            2:500,\n",
    "            3:600,\n",
    "            4:700,\n",
    "            5:800,\n",
    "            6:900,\n",
    "             7:1000,\n",
    "        }\n",
    "    keys = list(Temps.keys())\n",
    "    keys.sort()\n",
    "    ppath = 'nicocrNatom100KMultipleTempIrradiatedAnneal/dpa2'\n",
    "    stdd = np.zeros(len(Temps))\n",
    "    for key, count in zip(keys,range(len(keys))): #--- T\n",
    "        temp = Temps[key]\n",
    "        pathh = '%s/temp%s/Run0/orderParameter/pr_annealed_ij_index%s.txt'%(ppath,key,indxx)\n",
    "        print('parse from %s'%pathh)\n",
    "        try:\n",
    "            sarray = np.loadtxt(pathh)\n",
    "            #--- filter\n",
    "            filtr = ~np.isnan(sarray[:,1])\n",
    "            #--- order parameter\n",
    "            sdata = sarray[filtr]\n",
    "            xdata = sdata[:,0]\n",
    "            ydata = sdata[:,1]\n",
    "            #--- std y\n",
    "#            stdd[count] = np.std( ydata )\n",
    "            #--- plot\n",
    "            utl.PltErr(xdata,ydata,#/stdd[count],\n",
    "                        Plot=False,\n",
    "                        attrs=symbols.GetAttrs(count=count%7),#,label=r'%s'%temp),      \n",
    "                        ax=ax,\n",
    "                        )\n",
    "        \n",
    "    \n",
    "            #--- first dip\n",
    "#            x_axis, f, valleys = GetExtrema(xdata,ydata,2.3,verbose=False)\n",
    "#            ksi[count] = valleys[1]\n",
    "#            print('minimum at ',valleys[1])\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "            \n",
    "    #--- plot\n",
    "    utl.PltErr([0,cutoff],[0.33,0.33],\n",
    "                attrs={'fmt':'-.r'},\n",
    "                ax=ax,\n",
    "                Plot=False,\n",
    "                title='orderParameter/wc_diff_sheng_index%s_dpa.png'%indxx,\n",
    "#               legend=lg.Get(),\n",
    "#               xlim=[2.0,20.0],\n",
    "#                  ylim=[0.1-0.33,.7-0.33],\n",
    "            DrawFrame=[0.2,0.2,0.15,0.1,0.1],\n",
    "            )\n",
    "\n",
    "\n",
    "    #--- plot rms\n",
    "#     utl.PltErr(temps,stdd,\n",
    "#             Plot=False,\n",
    "#             attrs=symbols.GetAttrs(),      \n",
    "#             DrawFrame=[0.2,0.2,0.15,0.1,0.1],\n",
    "#             yscale='log',\n",
    "# #            ylim=(0.01,0.1),\n",
    "#                  title='orderParameter/rms_sro_temperature_pair%s.png'%indxx,\n",
    "#             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multiple Temperature: rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval(confParser['flags']['SroParameter']) and not\\\n",
    "   eval(confParser['flags']['RemoteMachine']):\n",
    "    \n",
    "    #--- plot order parameter vs. distance\n",
    "    symbols=Symbols()\n",
    "    lg = Legends()\n",
    "    lg.Set(fontsize=16,\n",
    "           bbox_to_anchor=(0.5,0.4,0.5,0.5),\n",
    "          )\n",
    "    ax = utl.PltErr(None,None,Plot=False)\n",
    "                \n",
    "    for indxx in range(6):\n",
    "\n",
    "    #--- loop over temp\n",
    "        temps = [400,600,800,1000,1200,1400]\n",
    "        stdd = np.zeros(len(temps))\n",
    "        for temp, count in zip(temps,range(10)): #--- T\n",
    "            pathh = './NiCoCrNatom100KTemp%ssro/Run0/orderParameter/deltap_r_ij_index%s.txt'%(temp,indxx)\n",
    "            print('parse from %s'%pathh)\n",
    "            try:\n",
    "                sarray = np.loadtxt(pathh)\n",
    "                #--- filter\n",
    "                filtr = ~np.isnan(sarray[:,1])\n",
    "                #--- order parameter\n",
    "                sdata = sarray[filtr]\n",
    "                xdata = sdata[:,0]\n",
    "                ydata = sdata[:,1]\n",
    "                #--- std y\n",
    "                stdd[count] = np.std( ydata )\n",
    "#                 #--- plot\n",
    "#                 utl.PltErr(xdata,ydata,\n",
    "#                             Plot=False,\n",
    "#                             attrs=symbols.GetAttrs(count=count,label=r'$%s$'%temp),      \n",
    "#                             ax=ax,\n",
    "#                             )\n",
    "\n",
    "\n",
    "                #--- first dip\n",
    "    #            x_axis, f, valleys = GetExtrema(xdata,ydata,2.3,verbose=False)\n",
    "    #            ksi[count] = valleys[1]\n",
    "    #            print('minimum at ',valleys[1])\n",
    "            except:\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "\n",
    "        #--- plot\n",
    "#         utl.PltErr([0,cutoff],[0,0],\n",
    "#                     attrs={'fmt':'-.r'},\n",
    "#                     ax=ax,\n",
    "#                     Plot=False,\n",
    "#                     title='orderParameter/wc_diff_sheng_index%s.png'%indxx,\n",
    "#                    legend=lg.Get(),\n",
    "#     #               xlim=[2.0,20.0],\n",
    "#     #                  ylim=[0.1-0.33,.7-0.33],\n",
    "#                 DrawFrame=[0.2,0.2,0.15,0.1,0.1],\n",
    "#                 )\n",
    "\n",
    "\n",
    "    #--- plot rms\n",
    "        utl.PltErr(temps,stdd,\n",
    "                Plot=False,\n",
    "                attrs=symbols.GetAttrs(count=indxx),      \n",
    "#                 DrawFrame=[0.2,0.2,0.15,0.1,0.1],\n",
    "                yscale='log',\n",
    "                ylim=(0.01,0.1),\n",
    "                ax=ax\n",
    "#                      title='orderParameter/rms_sro_temperature_pair%s.png'%indxx,\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### atom-wise WC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Wrapper(itime,pairj,**kwargs):\n",
    "    box = lp.Box( BoxBounds = lmpData.BoxBounds[itime], AddMissing = np.array([0.0,0.0,0.0] ))\n",
    "    atoms = lp.Atoms( **lmpData.coord_atoms_broken[itime].to_dict(orient='series') )\n",
    "    neigh = lmpNeigh.coord_atoms_broken[itime]\n",
    "\n",
    "#    pdb.set_trace()\n",
    "    \n",
    "    rdf = lp.ComputeRdf(  atoms, box )\n",
    "    sro = rdf.AtomWiseSro(neigh,pairj)\n",
    "    \n",
    "    #--- add xyz\n",
    "    df = lmpData.coord_atoms_broken[itime]\n",
    "    df = utl.FilterDataFrame(df, key='id', val=list(sro.id))\n",
    "    sro_mod = pd.DataFrame(np.c_[df['id type x y z'.split()],sro['1 2 3'.split()]],\\\n",
    "                        columns='id type x y z p1 p2 p3'.split())\n",
    "#    sro_mod['id']=sro_mod['id'].astype(int)\n",
    "#    sro_mod['type']=sro_mod['type'].astype(int)\n",
    "\n",
    "    #--- print\n",
    "    if 'fout' in kwargs:\n",
    "        atoms = lp.Atoms( **sro_mod.to_dict(orient='series') )\n",
    "        wd = lp.WriteDumpFile(atoms, box)\n",
    "        wd.Write(kwargs['fout'], \n",
    "                 itime=itime, \n",
    "                 attrs='id type x y z p1 p2 p3'.split(),\n",
    "                fmt = '%i %i %4.3e %4.3e %4.3e %3.2f %3.2f %3.2f'\n",
    "                )\n",
    "\n",
    "    return sro_mod\n",
    "\n",
    "if eval(confParser['flags']['SroParameter']):\n",
    "    keys = list(lmpNeigh.coord_atoms_broken.keys())\n",
    "    keys.sort()\n",
    "    itime=keys[-1]\n",
    "    itime0=keys[0]\n",
    "    #---\n",
    "    !rm orderParameter/sroPerAtom.xyz\n",
    "    fp = open('orderParameter/sroPerAtom.xyz','a')\n",
    "    sro_per_atom0 = Wrapper(itime0,[1,2,3],fout=fp) #--- rss\n",
    "    sro_per_atom  = Wrapper(itime,[1,2,3],fout=fp) #--- sro\n",
    "    fp.close()    \n",
    "        \n",
    "    #--- output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dislocations\n",
    "## load line coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def shift(atomm,lx):\n",
    "    xc=atomm.x[0]\n",
    "    atomm.x -= xc\n",
    "    negative_shift = atomm.x >= 0.5*lx\n",
    "    positive_shift = atomm.x < -0.5*lx\n",
    "    assert not np.all([np.any(negative_shift),np.any(positive_shift)])\n",
    "    atomm.x -= negative_shift * lx\n",
    "    atomm.x += positive_shift * lx\n",
    "    atomm.x += xc\n",
    "    return np.any(negative_shift), np.any(positive_shift)\n",
    "        \n",
    "def GetVertexCoords(pathh,box,times,verbose=False):\n",
    "    atomss = {}\n",
    "    lx = box.CellVector[ 0, 0 ]\n",
    "    filtrd_list = os.listdir(pathh) #fnmatch.filter(os.listdir(pathh), 'mydislocations.???')\n",
    "    if verbose:\n",
    "        print('files:',filtrd_list)\n",
    "    for myfile in filtrd_list: #--- multiple files\n",
    "        #--- time step\n",
    "        indd=myfile.find('.')\n",
    "        timei=int(myfile[indd+1:])\n",
    "        if verbose:\n",
    "            print('file=',myfile)\n",
    "            print('timei=',times[timei])\n",
    " \n",
    "        #--- read file\n",
    "        strr=open('%s/%s'%(pathh,myfile)).readlines() #--- read as string\n",
    "        li = strr.index('DISLOCATIONS 2\\n') #--- 1st line to be read\n",
    "        if verbose:\n",
    "            print('read line %s '%li)\n",
    "        li += 1\n",
    "        \n",
    "        atomss[times[timei]] = {}\n",
    "        tmp = {}\n",
    "        for ii in range(2): #--- two dislocations\n",
    "            dislocation_id = int(strr[li])\n",
    "            if verbose:\n",
    "                print('dislocation_id=',dislocation_id)\n",
    "            #\n",
    "            li += 3\n",
    "            n_vertices = int(strr[li]) #--- # of lines\n",
    "            if verbose:\n",
    "                print('n_vertices=',n_vertices)\n",
    "            #\n",
    "            li+=1\n",
    "            vertice_xyz=np.c_[list(map(lambda x: x.rsplit(sep=' ')[:3],strr[li:li+n_vertices]))].astype(float)\n",
    "            li+=n_vertices\n",
    "            #--- wrap\n",
    "            tmp[ii]=lp.Atoms(x=vertice_xyz[:,0],\n",
    "                                             y=vertice_xyz[:,1],\n",
    "                                             z=vertice_xyz[:,2]\n",
    "            )\n",
    "            wrap = lp.Wrap(tmp[ii],box)\n",
    "            wrap.WrapCoord()\n",
    "            wrap.Set( tmp[ii] )\n",
    "            wrap = lp.Wrap(tmp[ii],box)\n",
    "            assert np.all(wrap.isInside()), 'aotms outside original box!'    \n",
    "        #--- shift      \n",
    "#        xmean0=np.mean(tmp[0].x)\n",
    "        negative_shift, positive_shift = shift(tmp[0],lx)\n",
    "#        if negative_shift or positive_shift:\n",
    "#           print('shift',np.mean(tmp[0].x),xmean0,times[timei])\n",
    "\n",
    "#        xmean1=np.mean(tmp[1].x)\n",
    "        negative_shift, positive_shift = shift(tmp[1],lx)\n",
    "#        if negative_shift or positive_shift:\n",
    "#           print('shift',np.mean(tmp[1].x),xmean1,times[timei])\n",
    "\n",
    "        #--- shift disl.0 or disl.1\n",
    "        if np.mean(tmp[1].x)-np.mean(tmp[0].x) < -0.5*lx:\n",
    "            tmp[1].x += lx\n",
    "        elif np.mean(tmp[1].x)-np.mean(tmp[0].x) > 0.5*lx:\n",
    "            tmp[1].x -= lx\n",
    "\n",
    "        #--- front:0 rear: 1\n",
    "        front = 1\n",
    "        behind = 0\n",
    "        if np.mean(tmp[0].x) - np.mean(tmp[1].x) > 0.0:\n",
    "            front = 0\n",
    "            behind = 1\n",
    "        tmp_front = tmp[front]\n",
    "        tmp_behind = tmp[behind]\n",
    "\n",
    "        tmp[0] = tmp_front\n",
    "        tmp[1] = tmp_behind\n",
    "                    \n",
    "        atomss[times[timei]][0] = tmp[0]\n",
    "        atomss[times[timei]][1] = tmp[1]\n",
    "#        counter += 1\n",
    "            \n",
    "    return atomss\n",
    "\n",
    "if eval(confParser['flags']['DislocAnl']):\n",
    "    path = confParser['input files']['path']\n",
    "    indx = confParser['input files']['fileIndex']\n",
    "    fileName = '%s/%s'%(path,confParser['input files']['filename'].split()[int(indx)])\n",
    "    nevery = int(confParser['parameters']['nevery'])\n",
    "    #--- make directory\n",
    "    if eval(confParser['dislocation analysis']['WritDisc']) and not eval(confParser['dislocation analysis']['ReadDisc']):\n",
    "        try:\n",
    "            os.system('rm -r dislocations')\n",
    "        except:\n",
    "            pass\n",
    "        !mkdir -p dislocations/mydislocations\n",
    "        #--- run ovitos\n",
    "        #\n",
    "        !ovitos OvitosCna.py $fileName mydislocations $nevery 5\n",
    "        !mv mydislocations.* dislocations/mydislocations\n",
    "\n",
    "    #--- box\n",
    "    box = lp.Box( BoxBounds = lmpData.BoxBounds[0],AddMissing = np.array([0.0,0.0,0.0] ) )\n",
    "\n",
    "    #--- load ca files: extract xyz\n",
    "    times = list(lmpData.coord_atoms_broken.keys())\n",
    "    times.sort()\n",
    "    atomss = GetVertexCoords('./dislocations/mydislocations', box, times, verbose=False) #--- dislocation segments\n",
    "    print(atomss.keys())\n",
    "    \n",
    "    #--- print\n",
    "    timei=0\n",
    "    idd=1 #--- dislocation id\n",
    "    display(pd.DataFrame(atomss[timei][idd].__dict__))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3d map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mpl_toolkits import mplot3d\n",
    "\n",
    "# for ii in atomss.keys():\n",
    "#     fig = plt.figure()\n",
    "#     ax = plt.axes(projection='3d')\n",
    "#     xyz_data=np.c_[atomss[ii].x, atomss[ii].y, atomss[ii].z ]\n",
    "    \n",
    "#     zlo=xyz_data[:,2].min()\n",
    "#     zhi=xyz_data[:,2].max()\n",
    "#     dz=zhi-zlo\n",
    "#     ymean=xyz_data[:,1].mean()\n",
    "#     xmean=xyz_data[:,0].mean()\n",
    "\n",
    "#     ax.set_zlim(zlo,zhi)\n",
    "#     ax.set_ylim(ymean-0.5*dz,ymean+0.5*dz)\n",
    "#     ax.set_xlim(xmean-0.5*dz,xmean+0.5*dz)\n",
    "\n",
    "\n",
    "#     ax.plot3D(xyz_data[:,0],xyz_data[:,1],xyz_data[:,2] , 'black')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sro within stacking fault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PltDislAtoms:\n",
    "    '''\n",
    "    Plot dislocation line on top of atoms\n",
    "    '''\n",
    "    def __init__(self, df, box, Plot=False, **kwargs ):\n",
    "        self.atoms = df\n",
    "        self.box = box\n",
    "        self.plot = Plot\n",
    "        self.ax = utl.PltErr(None,None,Plot=False,**kwargs)\n",
    "        #--- axis limits\n",
    "        self.ymean = []\n",
    "        self.xlo=[]\n",
    "        self.xhi=[]\n",
    "        self.zlo=[]\n",
    "        self.zhi=[]\n",
    "                       \n",
    "    def IntrpDisLines(self,dislc):\n",
    "        '''\n",
    "        interpolate line segments onto a grid\n",
    "        '''\n",
    "        self.zint, self.xint, junk = interp(dislc,self.box,0,Plot=False)\n",
    "\n",
    "    def Copy(self,atoms):\n",
    "        return lp.Atoms(x=np.copy(atoms.x),\n",
    "                       y=np.copy(atoms.y),\n",
    "                       z=np.copy(atoms.z))\n",
    "        \n",
    "    def Wrap(self,dislc):\n",
    "        '''\n",
    "        wrap line segments\n",
    "        '''\n",
    "        wrap = lp.Wrap(dislc,self.box)\n",
    "        wrap.WrapCoord()\n",
    "        wrap.Set( dislc )\n",
    "        wrap = lp.Wrap(dislc,self.box)\n",
    "        assert np.all(wrap.isInside()), 'aotms outside original box!'\n",
    "        \n",
    "    def PlotLines(self,df_dislc,**kwargs):\n",
    "        '''\n",
    "        plot segments (and arrows)\n",
    "        '''\n",
    "        dislc = self.Copy(df_dislc)\n",
    "        self.Wrap(dislc)\n",
    "        self.IntrpDisLines(dislc)\n",
    "        \n",
    "        if not self.plot:\n",
    "            plt.ioff()\n",
    "            \n",
    "        #--- set axis limits\n",
    "        self.ymean += [np.mean(dislc['y'])]\n",
    "        self.xlo += [np.min(self.xint)]\n",
    "        self.xhi += [np.max(self.xint)]\n",
    "        self.zlo += [np.min(self.zint)]\n",
    "        self.zhi += [np.max(self.zint)]\n",
    "        \n",
    "        #--- lines\n",
    "        self.ax=utl.PltErr(self.xint, \n",
    "                       self.zint,\n",
    "                       attrs={'fmt':'-','lw':2,'color':'black'},\n",
    "                       Plot=False,\n",
    "                       ax = self.ax\n",
    "                      )\n",
    "\n",
    "        #--- plot arrows (velocity)\n",
    "        if 'dx' in kwargs and 'dy' in kwargs: \n",
    "            dx = kwargs['dx']\n",
    "            assert len(self.xint) == len(dx), 'len(self.xint)=%s,len(dx)=%s'%(len(self.xint),len(dx))\n",
    "            dx -= np.mean(dx)\n",
    "            dx /= np.std(dx)\n",
    "            list(map(lambda x: self.ax.arrow(self.xint[x], self.zint[x],\n",
    "                                        dx=8*dx[x],dy=kwargs['dy'][x],\n",
    "                                        head_width=5,\n",
    "                                        head_length=6,\n",
    "                                        lw=0.6,\n",
    "                                        color='black',#'C0',\n",
    "                                       ),range(0,len(self.xint),6)))\n",
    "\n",
    "\n",
    "    def PlotAtoms(self,s=8,alpha=0.5,**kwargs):\n",
    "        #--- xyz\n",
    "        x=self.atoms['x']\n",
    "        y=self.atoms['y']\n",
    "        z=self.atoms['z']\n",
    "        ttype=np.array(self.atoms['type'],dtype=str)\n",
    "        ttype[ttype=='1']='#D2E3E6'\n",
    "        ttype[ttype=='2']='#404EB1'\n",
    "        ttype[ttype=='3']='#B44A43'\n",
    "        attrs={}\n",
    "        if 'stress' in kwargs:\n",
    "            ttype = kwargs['stress']\n",
    "            attrs={'cmap':'seismic'}\n",
    "#            print(ttype)\n",
    "        \n",
    "        #--- 2d stack\n",
    "        ymean = np.mean(self.ymean) if not 'ystack' in kwargs else kwargs['ystack']\n",
    "        rc = 1.0 if not 'rc' in kwargs else kwargs['rc']\n",
    "        filtr = np.all([ymean-rc<=y, y<ymean+rc],axis=0)\n",
    "\n",
    "        #--- axis limits\n",
    "        self.xlim=kwargs['xlim'] if 'xlim' in kwargs else\\\n",
    "                  (np.min(self.xlo),np.max(self.xhi) )\n",
    "        self.ylim=kwargs['ylim'] if 'ylim' in kwargs else\\\n",
    "                  (np.min(self.zlo),np.max(self.zhi) )\n",
    "\n",
    "\n",
    "        #--- plot atoms\n",
    "        self.ax.scatter( x[filtr],z[filtr], \n",
    "                   c=ttype[filtr],\n",
    "                   s=s,\n",
    "                   alpha=alpha,\n",
    "                   **attrs, #cmap=\"seismic\",\n",
    "                )\n",
    "\n",
    "    def Save(self,title,**kwargs):\n",
    "        #\n",
    "        utl.PltErr( None,None, attrs={'fmt':'.','markersize':2},\n",
    "                xlim=self.xlim,\n",
    "                ylim=self.ylim,\n",
    "               ax=self.ax,\n",
    "               title=title,\n",
    "               Plot = False,\n",
    "                   **kwargs\n",
    "                )\n",
    "        #\n",
    "        if not self.plot:\n",
    "            plt.close(self.ax.get_figure())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SroStackFault(PltDislAtoms):\n",
    "    '''\n",
    "    compute sro parameters within a stacking ault\n",
    "    '''\n",
    "    def __init__(self, df, box ):\n",
    "        PltDislAtoms.__init__(self,df,box,Plot=False)\n",
    "\n",
    "        \n",
    "    def SetLimits(self,df_dislc,**kwargs):\n",
    "        '''\n",
    "        set xyz limits\n",
    "        '''\n",
    "        dislc = self.Copy(df_dislc)\n",
    "        self.Wrap(dislc)\n",
    "        self.IntrpDisLines(dislc)\n",
    "        \n",
    "            \n",
    "        #--- set axis limits\n",
    "        self.ymean += [np.mean(dislc['y'])] if not 'ystack' in kwargs else [kwargs['ystack']]\n",
    "        self.xlo += [np.min(self.xint)]\n",
    "        self.xhi += [np.max(self.xint)]\n",
    "        self.zlo += [np.min(self.zint)]\n",
    "        self.zhi += [np.max(self.zint)]\n",
    "        \n",
    "    def SetFiltr(self, rc = 2.5):\n",
    "        #--- limits\n",
    "        xxlo = np.min(self.xlo)\n",
    "        xxhi = np.max(self.xhi)\n",
    "        zzlo = np.min(self.zlo)\n",
    "        zzhi = np.max(self.zhi)\n",
    "        yylo = np.min(self.ymean)-rc\n",
    "        yyhi = np.max(self.ymean)+rc\n",
    "\n",
    "        #--- xyz\n",
    "        x=self.atoms['x']\n",
    "        y=self.atoms['y']\n",
    "        z=self.atoms['z']\n",
    "    \n",
    "        self.filtr = np.all([y>=yylo, y<yyhi, x>=xxlo, x<xxhi, z>=zzlo, z<zzhi ],axis=0)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    def GetNeighborList(self,confParser):\n",
    "        \n",
    "        #--- set parameters\n",
    "        natoms = eval(confParser['neigh list']['natom']) #--- subset of atoms\n",
    "        self.cutoff = eval(confParser['neigh list']['cutoff'])\n",
    "        nevery = 1 #int(confParser['parameters']['nevery'])\n",
    "        \n",
    "        #--- write dump file\n",
    "        fileName = 'dislocations/dump.xyz'\n",
    "        wd = lpp.WriteDumpFile(lp.Atoms(**self.atoms.to_dict()), self.box)\n",
    "        wd.Write(fileName, itime=0,\n",
    "                 attrs=['id', 'type', 'x', 'y', 'z' ], \n",
    "                 fmt = '%i %i %5.4e %5.4e %5.4e' )\n",
    "        \n",
    "        \n",
    "        #--- filter\n",
    "        NATOM = len(self.atoms['x'])\n",
    "        atom_indices = np.arange(NATOM)[self.filtr]\n",
    "        if natoms < len(atom_indices):\n",
    "            atom_indices = atom_indices[0:natoms]\n",
    "#            print(atom_indices)\n",
    "        atom_indices = ' '.join(list(map(str,atom_indices)))\n",
    "    \n",
    "    \n",
    "        #--- call ovito\n",
    "        t0=time.time()\n",
    "        output = 'dislocations/neighList.xyz'\n",
    "        try:\n",
    "            !rm $output\n",
    "        except:\n",
    "            pass\n",
    "        #--- build full neigh list but with a list of query points\n",
    "        !ovitos OvitosCna.py $fileName $output  $nevery 6 $self.cutoff $atom_indices\n",
    "        print('output neighbor list=%s s'%(time.time()-t0))\n",
    "        \n",
    "        #--- parse\n",
    "        t0=time.time()\n",
    "        lmpNeigh = lp.ReadDumpFile( 'dislocations/neighList.xyz' )\n",
    "        lmpNeigh.GetCords( ncount = sys.maxsize)\n",
    "        print('load neighbor list=%s s'%(time.time()-t0))\n",
    "        self.neigh = lmpNeigh.coord_atoms_broken[0]\n",
    "    \n",
    "    \n",
    "    def grValleys(self,rmin=2.3):\n",
    "\n",
    "        rdf = lp.ComputeRdf(  lp.Atoms(**self.atoms.to_dict()), self.box )\n",
    "        rdf.PairCrltn(  \n",
    "                      bins=np.arange(0.0,self.cutoff,0.1), \n",
    "                      rlist=self.neigh.DIST,\n",
    "                      regular_r = True,\n",
    "                      )\n",
    "        bin_edges1, hist1, err1  = rdf.Get()\n",
    "        x_axis, f, self.valleys = GetExtrema(bin_edges1,hist1,rmin)\n",
    "    \n",
    "    \n",
    "    def SetSro(self,pairi,pairj):\n",
    "        self.grValleys() #--- valleys\n",
    "        \n",
    "        rdf = lp.ComputeRdf(  lp.Atoms(**self.atoms.to_dict()), self.box )\n",
    "        self.sro = rdf.Sro(self.neigh,pairi,pairj,bins=self.valleys)\n",
    "\n",
    "        \n",
    "if eval(confParser['flags']['DislocAnl']):\n",
    "    #--- timestep\n",
    "    times = list(atomss.keys())\n",
    "    times.sort()\n",
    "    timei = times[-1]\n",
    "\n",
    "    #--- stacking fault\n",
    "    sroStack = SroStackFault( df=lmpData.coord_atoms_broken[ timei ], \n",
    "                        box=lp.Box( BoxBounds = lmpData.BoxBounds[0],AddMissing = np.array([0.0,0.0,0.0] ) ), \n",
    "\n",
    "                      )\n",
    "\n",
    "    sroStack.SetLimits(atomss[ timei ][ 0 ])#,ystack=10 )\n",
    "    sroStack.SetLimits(atomss[ timei ][ 1 ])#,ystack=10)\n",
    "    sroStack.SetFiltr()\n",
    "    sroStack.GetNeighborList(confParser)\n",
    "    sroStack.SetSro(1,1) #--- rss\n",
    "\n",
    "    bin_edges, p0, dp0 =  sroStack.sro\n",
    "    PltErr(bin_edges,p0)    \n",
    "\n",
    "    np.savetxt('dislocations/pr_aging_ij_index%s.txt'%0,\n",
    "           np.c_[bin_edges,p0,dp0],\n",
    "           header='r\\tp\\terr_p')\n",
    "\n",
    "    \n",
    "    #--- outside\n",
    "    sroStack = SroStackFault( df=lmpData.coord_atoms_broken[ timei ], \n",
    "                        box=lp.Box( BoxBounds = lmpData.BoxBounds[0],AddMissing = np.array([0.0,0.0,0.0] ) ), \n",
    "\n",
    "                      )\n",
    "\n",
    "    sroStack.SetLimits(atomss[ timei ][ 0 ], ystack=10 )\n",
    "    sroStack.SetLimits(atomss[ timei ][ 1 ], ystack=10 )\n",
    "    sroStack.SetFiltr()\n",
    "    sroStack.GetNeighborList(confParser)\n",
    "    sroStack.SetSro(1,1) #--- rss\n",
    "\n",
    "    bin_edges, p0, dp0 =  sroStack.sro\n",
    "    PltErr(bin_edges,p0)    \n",
    "\n",
    "    np.savetxt('dislocations/pr_aging_ij_index%s_ystack10.txt'%0,\n",
    "           np.c_[bin_edges,p0,dp0],\n",
    "           header='r\\tp\\terr_p')\n",
    "\n",
    "    \n",
    "\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box=lp.Box( BoxBounds = lmpData.BoxBounds[0],AddMissing = np.array([0.0,0.0,0.0] ) )\n",
    "# box.BoxBounds[1][:2].astype(float)\n",
    "# sroStack.ymean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval(confParser['flags']['DislocAnl']) and not\\\n",
    "   eval(confParser['flags']['RemoteMachine']):\n",
    "    indxx = 0 #--- NiNi\n",
    "    #--- plot order parameter vs. distance\n",
    "    symbols=Symbols()\n",
    "    lg = Legends()\n",
    "    lg.Set(fontsize=16,\n",
    "           bbox_to_anchor=(0.5,0.4,0.5,0.5),\n",
    "          )\n",
    "    ax = utl.PltErr(None,None,Plot=False)\n",
    "    \n",
    "    #--- loop over temp\n",
    "    temp = 600\n",
    "    for count, label in zip(range(3),['Total','Sacking fault',r'$y=10 \\r{A}$']): #--- T\n",
    "        pathh = [\n",
    "#            './NiCoCrNatom100KTemp%ssro/Run0/orderParameter/pr_annealed_ij_index%s.txt'%(temp,indxx),\n",
    "#            './NiCoCrNatom100KTemp600AgingSro/Run0/dislocations/pr_aging_ij_index%s.txt'%(indxx),\n",
    "            'orderParameter/pr_annealed_ij_index%s.txt'%(indxx), #--- total\n",
    "            'dislocations/pr_aging_ij_index%s.txt'%(indxx), #--- y=y(dislocation)\n",
    "            'dislocations/pr_aging_ij_index%s_ystack10.txt'%(indxx), #--- y=10\n",
    "            \n",
    "                ][count]\n",
    "        print('parse from %s'%pathh)\n",
    "        try:\n",
    "            sarray = np.loadtxt(pathh)\n",
    "            #--- filter\n",
    "            filtr = ~np.isnan(sarray[:,1])\n",
    "            #--- order parameter\n",
    "            sdata = sarray[filtr]\n",
    "            xdata = sdata[:,0]\n",
    "            ydata = sdata[:,1]\n",
    "            #--- plot\n",
    "            utl.PltErr(xdata,ydata,\n",
    "                        Plot=False,\n",
    "                        attrs=symbols.GetAttrs(count=count,label=label),      \n",
    "                        ax=ax,\n",
    "                        )\n",
    "        \n",
    "    \n",
    "            #--- first dip\n",
    "#            x_axis, f, valleys = GetExtrema(xdata,ydata,2.3,verbose=False)\n",
    "#            ksi[count] = valleys[1]\n",
    "#            print('minimum at ',valleys[1])\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "            \n",
    "    #--- plot\n",
    "    utl.PltErr([0,20],[0.33,0.33],\n",
    "                attrs={'fmt':'-.r'},\n",
    "                ax=ax,\n",
    "                Plot=False,\n",
    "                title='orderParameter/wc_aging_dislocated_index%s.png'%indxx,\n",
    "               legend=lg.Get(),\n",
    "#               xlim=[2.0,20.0],\n",
    "#                  ylim=[0.1-0.33,.7-0.33],\n",
    "            DrawFrame=[0.2,0.2,0.15,0.1,0.1],\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## height correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp(df,box,timei,verbose=False,Plot=True,**kwargs):\n",
    "    x=df.z\n",
    "    y=df.x\n",
    "    #\n",
    "    [xlo, xhi, junk]=box.BoxBounds[2].astype(float)\n",
    "#    print(xlo,xhi)\n",
    "    dx=1.0 #2*np.ceil(np.abs(np.diff(x)).min())\n",
    "    hist, bin_edges = np.histogram(x,bins=np.arange(xlo,xhi,dx))\n",
    "    ysum, bin_edges = np.histogram(x,bins=np.arange(xlo,xhi,dx),weights=y)\n",
    "    ysum2, bin_edges = np.histogram(x,bins=np.arange(xlo,xhi,dx),weights=y*y)\n",
    "    ymean = ysum / hist\n",
    "    ysum2 /= hist\n",
    "    ysum2 -= ymean*ymean\n",
    "    ystd = (ysum2 / hist)**0.5\n",
    "    bin_edges = (bin_edges[1:]+bin_edges[:-1])*0.5\n",
    "    \n",
    "    if Plot:\n",
    "        if verbose:\n",
    "            print('itime=',timei)\n",
    "        if 'ax' in kwargs:\n",
    "            ax = kwargs['ax']\n",
    "            args = {'ax':ax}\n",
    "            kwargs.pop('ax')\n",
    "        else:\n",
    "            args={}\n",
    "        xx=0.5*(x.max()-x.min())\n",
    "        \n",
    "        ax=PltErr(y,x,\n",
    "              attrs={'fmt':'.'},\n",
    "                Plot=False,\n",
    "                **args\n",
    "              )\n",
    "        ax=PltErr(ymean,bin_edges, #yerr=ystd,\n",
    "              attrs={'fmt':'-r'},\n",
    "               ax=ax,\n",
    "#                ylim=(np.mean(y)-xx,np.mean(y)+xx),\n",
    "#                xlim=(np.min(x),np.max(x)),\n",
    "                Plot=False,\n",
    "               **kwargs\n",
    "              )\n",
    "    \n",
    "    return bin_edges, ymean, ystd\n",
    "\n",
    "\n",
    "def Crltn(x,y):\n",
    "    xq=np.fft.fft(x)\n",
    "    yq=np.fft.fft(y)\n",
    "    return np.fft.ifft(np.abs(xq*yq))/len(xq)\n",
    "\n",
    "def PltCrltnn(xint,yint, Plot = True, attrs={'fmt':'-'},**kwargs):\n",
    "#    print(yint.shape)\n",
    "    crltn = Crltn(zscore(yint),zscore(yint))\n",
    "    n = xint.shape[0]\n",
    "#    print(kwargs)\n",
    "    if Plot:\n",
    "        PltErr((xint-xint[0])[0:int(n/2+n%2)],crltn[0:int(n/2+n%2)],\n",
    "               attrs=attrs,\n",
    "               Plot = False,\n",
    "               **kwargs)\n",
    "    return (xint-xint[0])[0:int(n/2+n%2)],crltn[0:int(n/2+n%2)] #, xint[crltn<0][0]\n",
    "        \n",
    "if eval(confParser['flags']['DislocAnl']):\n",
    "\n",
    "    zscore = lambda x: (x-np.mean(x))/np.std(x) \n",
    "\n",
    "\n",
    "    #--- interpolate h(z)\n",
    "    times = list(atomss.keys())\n",
    "    times.sort()\n",
    "    timei=times[-1]\n",
    "    xint, yint, junk = interp(atomss[timei][idd],box,timei,\n",
    "                             ystr=r'$z$'    if not eval(confParser['flags']['RemoteMachine']) else 'z',\n",
    "                             xstr=r'$h(z)$' if not eval(confParser['flags']['RemoteMachine']) else 'h(z)' ,\n",
    "                             )\n",
    "\n",
    "    #--- correlation\n",
    "    junk,  junk =PltCrltnn(xint,yint,\n",
    "                                xstr=r'$|z-z^\\prime|$' if not eval(confParser['flags']['RemoteMachine']) else 'dz',\n",
    "                               ystr=r'$\\langle h(z)h(z^\\prime)\\rangle$' if not eval(confParser['flags']['RemoteMachine']) else 'c(dz)',\n",
    "\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "if eval(confParser['flags']['DislocAnl']) and not\\\n",
    "   eval(confParser['flags']['RemoteMachine']):\n",
    "\n",
    "    #--- timestep\n",
    "    times = list(atomss.keys())\n",
    "    times.sort()\n",
    "    timei = times[-1]\n",
    "    \n",
    "    #--- box\n",
    "    box=lp.Box( BoxBounds = lmpData.BoxBounds[0],AddMissing = np.array([0.0,0.0,0.0] ) )\n",
    "    aspect_ratio = box.CellVector[0,0]/box.CellVector[2,2]\n",
    "    \n",
    "    \n",
    "    #--- plot\n",
    "    pltDisl = PltDislAtoms( df=lmpData.coord_atoms_broken[ timei ], \n",
    "                           box=lp.Box( BoxBounds = lmpData.BoxBounds[0],AddMissing = np.array([0.0,0.0,0.0] ) ), \n",
    "                           Plot = True, \n",
    "                           figsize=(4*aspect_ratio,4) \n",
    "                          )\n",
    "    #--- plot lines\n",
    "    pltDisl.PlotLines(atomss[ timei ][ 0 ],\n",
    "#                     dx = vel[0], #--- velocities\n",
    "#                     dy = np.zeros(len(vel[0])),\n",
    "\n",
    "                    )\n",
    "    pltDisl.PlotLines(atomss[ timei ][ 1 ])\n",
    "    #--- plot atoms\n",
    "    pltDisl.PlotAtoms(s=10,\n",
    "                      alpha=0.5,#.8,#.4,\n",
    "#                     xlim=(np.mean(df_disc0.x)-0.5*(np.max(df_disc0.z)-np.min(df_disc0.z)),\n",
    "#                           np.mean(df_disc0.x)+0.5*(np.max(df_disc0.z)-np.min(df_disc0.z))),\n",
    "    #                 xlim = (0,760),\n",
    "                       xlim=box.BoxBounds[0][:2].astype(float),\n",
    "                       ylim=box.BoxBounds[2][:2].astype(float),\n",
    "#                       ystack = 10.0, #np.mean(box.BoxBounds[1][:2].astype(float)), #--- comment if there are dislocations\n",
    "                        rc=2.5,\n",
    "                     )\n",
    "    #--- save\n",
    "    pltDisl.Save(\n",
    "                 title='dislocations/DislAgedT600K',\n",
    "#                 title='dislocations/DislAgingT600K.png',\n",
    "#                 title='dislocations/DislRandomT600K.png',\n",
    "                 dpi=150,\n",
    "                DrawFrame=[0.035,0.035,0.15,0.1,0.1],\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('every ang is', 3.0/box.CellVector[2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalee=0.02270484123882844\n",
    "lx=100 #A\n",
    "\n",
    "if eval(confParser['flags']['DislocAnl']) and not\\\n",
    "   eval(confParser['flags']['RemoteMachine']):\n",
    "    figsize=lx*scalee\n",
    "\n",
    "    #--- timestep\n",
    "    times = list(atomss.keys())\n",
    "    times.sort()\n",
    "    timei = times[-1]\n",
    "    \n",
    "    #--- box\n",
    "    box=lp.Box( BoxBounds = lmpData.BoxBounds[0],AddMissing = np.array([0.0,0.0,0.0] ) )\n",
    "    aspect_ratio = box.CellVector[0,0]/box.CellVector[2,2]\n",
    "    \n",
    "    \n",
    "    #--- plot\n",
    "    pltDisl = PltDislAtoms( df=lmpData.coord_atoms_broken[ timei ], \n",
    "                           box=lp.Box( BoxBounds = lmpData.BoxBounds[0],AddMissing = np.array([0.0,0.0,0.0] ) ), \n",
    "                           Plot = True, \n",
    "                           figsize=(figsize,figsize) \n",
    "                          )\n",
    "\n",
    "    #--- plot atoms\n",
    "    pltDisl.PlotAtoms(s=4,\n",
    "                      alpha=0.5,#.8,#.4,\n",
    "#                     xlim=(np.mean(df_disc0.x)-0.5*(np.max(df_disc0.z)-np.min(df_disc0.z)),\n",
    "#                           np.mean(df_disc0.x)+0.5*(np.max(df_disc0.z)-np.min(df_disc0.z))),\n",
    "    #                 xlim = (0,760),\n",
    "                      xlim=(float(box.BoxBounds[0][0]),float(box.BoxBounds[0][0])+lx),\n",
    "                      ylim=(float(box.BoxBounds[2][0]),float(box.BoxBounds[2][0])+lx),\n",
    "                      ystack = np.mean(box.BoxBounds[1][:2].astype(float)), #--- comment if there are dislocations\n",
    "                        rc=2.5,\n",
    "                     )\n",
    "    #--- save\n",
    "    pltDisl.Save(\n",
    "                 title='dislocations/sroDislFree.png',\n",
    "#                 title='dislocations/DislAgingT600K.png',\n",
    "#                 title='dislocations/DislRandomT600K.png',\n",
    "                 dpi=150,\n",
    "                DrawFrame=[0.2,0.1,0.15,0.1,0.1],\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PltDislAtomsWrapperFunc(**kwargs):\n",
    "    #--- plot\n",
    "    pltDisl = PltDislAtoms( df=kwargs['df'],#lmpData.coord_atoms_broken[ timei ], \n",
    "                           box=kwargs['box'],#lp.Box( BoxBounds = lmpData.BoxBounds[0],AddMissing = np.array([0.0,0.0,0.0] ) ), \n",
    "                           Plot = kwargs['Plot'],#True, \n",
    "    #                       figsize=(18,3) \n",
    "                          )\n",
    "    #--- plot lines\n",
    "    args = {}\n",
    "    if 'dx' in kwargs and 'dy' in kwargs:\n",
    "        args={'dx':kwargs['dx'],'dy':kwargs['dy']}\n",
    "    pltDisl.PlotLines(kwargs['df_disc'],#atomss[ timei ][ 0 ],\n",
    "                      **args,\n",
    "#                      dx = vel[0], #--- velocities\n",
    "#                      dy = np.zeros(len(vel[0])),\n",
    "\n",
    "                     )\n",
    "    #pltDisl.PlotLines(df_disc1)\n",
    "    attrs = {} if not 'stress' in kwargs else {'stress':kwargs['stress']}\n",
    "    #--- plot atoms\n",
    "    pltDisl.PlotAtoms(s=10,\n",
    "                      alpha=.8,#.4,\n",
    "                     xlim=(np.mean(kwargs['df_disc'].x)-0.5*(np.max(kwargs['df_disc'].z)-np.min(kwargs['df_disc'].z)),\n",
    "                           np.mean(kwargs['df_disc'].x)+0.5*(np.max(kwargs['df_disc'].z)-np.min(kwargs['df_disc'].z))),\n",
    "    #                 xlim = (0,760),\n",
    "                      **attrs\n",
    "                     )\n",
    "    #--- save\n",
    "    pltDisl.Save(\n",
    "                 title=kwargs['title'],#'dislocations/DislVelocItime%s_id%s.png'%(timei,idd),\n",
    "                 dpi=kwargs['dpi'],#150,\n",
    "                DrawFrame=kwargs['DrawFrame'],#[0.2,0.1,0.15,0.1,0.01],\n",
    "                )\n",
    "\n",
    "if eval(confParser['flags']['DislocAnl']) and not\\\n",
    "   eval(confParser['flags']['RemoteMachine']):\n",
    "    PltDislAtomsWrapperFunc(\n",
    "        df=lmpData.coord_atoms_broken[ timei ], \n",
    "        box=lp.Box( BoxBounds = lmpData.BoxBounds[0],AddMissing = np.array([0.0,0.0,0.0] ) ), \n",
    "        Plot = True,\n",
    "        df_disc=atomss[ timei ][ 0 ],\n",
    "        title='dislocations/DislVelocItime%s_id%s.png'%(timei,idd),\n",
    "        dpi=150,\n",
    "        DrawFrame=[0.2,0.1,0.15,0.1,0.01],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiple timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if eval(confParser['flags']['DislocAnl']):\n",
    "    #--- timestep\n",
    "    times = list(atomss.keys())\n",
    "    times.sort()\n",
    "    timei = times[0]\n",
    "    \n",
    "    #--- discretized x\n",
    "    xint, junk, junk = interp(atomss[timei][idd],box,timei,Plot=False)\n",
    "\n",
    "    for idd in [0,1]:\n",
    "        #--- interpolate\n",
    "        ax = PltErr(None,None,Plot=False)\n",
    "        yint = np.c_[list(map(lambda x:interp(atomss[x][idd],box,x,Plot=True,ax=ax,                             \n",
    "                                              ystr=r'$z$' if not eval(confParser['flags']['RemoteMachine']) else 'z',\n",
    "                                              xstr=r'$h(z)$' if not eval(confParser['flags']['RemoteMachine']) else 'h(z)',\n",
    "                                              xlim=(0,761)\n",
    "                                             )[1],times))]\n",
    "        plt.show()\n",
    "        #--- print\n",
    "        header = 'r\\t'+reduce(lambda x,y:x+y,map(lambda x: 'h_%s\\t'%x ,range(yint.shape[0])))\n",
    "        np.savetxt('dislocations/h%s_profile_multiple_times.txt'%idd,np.c_[xint,yint.T],header=header)\n",
    "\n",
    "        #--- plot lines & atoms                \n",
    "        list(map(lambda x:        \n",
    "            PltDislAtomsWrapperFunc(\n",
    "            df=lmpData.coord_atoms_broken[ x ], \n",
    "            box=lp.Box( BoxBounds = lmpData.BoxBounds[0],AddMissing = np.array([0.0,0.0,0.0] ) ), \n",
    "            Plot = False,\n",
    "            df_disc=atomss[ x ][ idd ],\n",
    "            title='dislocations/DislItime%s_id%s.png'%(x,idd),\n",
    "            dpi=150,\n",
    "            DrawFrame=[0.2,0.1,0.15,0.1,0.01],\n",
    "            ),times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.std(yint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiple timesteps: plot h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "indxx=1 #--- csa, rsa\n",
    "dislocation_id = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "class parse:\n",
    "    def __init__(self,fp0,fp1):\n",
    "        self.fp0 = fp0\n",
    "        self.fp1 = fp1\n",
    "        pass\n",
    "    def ParseData(self,load, pathh,dislocation_id,**kwargs):\n",
    "        print('load=%s'%load)\n",
    "        sdata0 = np.loadtxt('%s/%s'%(pathh,self.fp0)) #--- velocity profile\n",
    "        sdata1 = np.loadtxt('%s/%s'%(pathh,self.fp1)) #--- velocity profile\n",
    "\n",
    "        #--- fetch data\n",
    "        self.r = sdata0[:,0]\n",
    "        hx0 = sdata0[:,1:]\n",
    "        hx1 = sdata1[:,1:]\n",
    "        hx=[hx0,hx1][dislocation_id]\n",
    "        if 'index' in kwargs: \n",
    "            val=hx.T[kwargs['index']]\n",
    "        else:\n",
    "            val = hx.T\n",
    "        return val\n",
    "    def Get_r(self):\n",
    "        return self.r\n",
    "\n",
    "if eval(confParser['flags']['DislocAnl']) and not\\\n",
    "   eval(confParser['flags']['RemoteMachine']):\n",
    "\n",
    "    #--- parse data\n",
    "    loads = [\n",
    "                [500,600,650,700,750], #--- csa\n",
    "                [400,500,550,600,650], #--- rsa\n",
    "              ][indxx]\n",
    "    \n",
    "    ps = parse('h0_profile_multiple_times.txt',\n",
    "               'h1_profile_multiple_times.txt'\n",
    "              )\n",
    "    hx = np.array(list(map(lambda x:ps.ParseData(\n",
    "              load=x,\n",
    "              pathh=[\n",
    "                     'NiCoCrNatom100KTemp600/dislocated/load%s/Run0/dislocations'%x,\n",
    "                     'NiCoCrNatom100KTemp600Rss/dislocated/load%s/Run0/dislocations'%x,\n",
    "                    ][indxx],\n",
    "              dislocation_id = dislocation_id,\n",
    "              index = -1,\n",
    "                ), loads))).T\n",
    "    r = ps.Get_r()\n",
    "    print('hx.shape=',hx.shape)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #--- plot\n",
    "    ax0=PltErr(None,None,Plot=False)\n",
    "    shift = lambda x:(1+x)*50 #--- shift vertically\n",
    "    attrs = {'markevery':1,'markersize':8}\n",
    "#     list(map(lambda x:PltErr(x[0]-np.mean(x[0])+shift(x[1]),r,ax=ax0,\n",
    "#                              attrs={'fmt':'-','label':load,'color':'C0'},\n",
    "#                              Plot=False,\n",
    "#                             ylim=(np.min(r),np.max(r)),\n",
    "#                             xlim=(0,0.4*761),\n",
    "#                             ),zip(hx.T,range(10))))\n",
    "    list(map(lambda x:PltErr((x[0]-np.mean(x[0]))/np.std(x[0])+5*(x[1]-2),r,ax=ax0,\n",
    "                             attrs={'fmt':'-','label':load,'color':'C0'},\n",
    "                             Plot=False,\n",
    "                            ylim=(np.min(r),np.max(r)),\n",
    "                            xlim=(-14,14),\n",
    "                            ),zip(hx.T,range(10))))\n",
    "                                 \n",
    "    utl.PltErr(None,None,ax=ax0,\n",
    "                DrawFrame=[0.2,0.1,0.15,0.1,0.01],\n",
    "                title='dislocations/h0_%s.png'%indxx,\n",
    "      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.mean(np.std(hx,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     #--- parse data\n",
    "#     load = 1200\n",
    "#     ps = parse('vx0_profile_multiple_times.txt',\n",
    "#                'vx1_profile_multiple_times.txt'\n",
    "#               )\n",
    "#     for dislocation_id in [0,1]:\n",
    "#         vx = ps.ParseData(\n",
    "#                   load=load,\n",
    "#                   pathh=[\n",
    "#                          'NiCoCrNatom100KTemp600/dislocated/load%s/Run0/dislocations'%load,\n",
    "#                          'NiCoCrNatom100KTemp600Rss/dislocated/load%s/Run0/dislocations'%load,\n",
    "#                         ][indxx],\n",
    "#                   dislocation_id = dislocation_id,\n",
    "#                     ).T\n",
    "#         r = ps.Get_r()\n",
    "#         print('vx.shape=',vx.shape)\n",
    "#         ntime=vx.shape[1]\n",
    "#         timei=0#int(ntime/2)\n",
    "#         timef=ntime\n",
    "\n",
    "\n",
    "\n",
    "#         #--- plot\n",
    "#         ax0=PltErr(None,None,Plot=False)\n",
    "#         shift = lambda x:(1+x)*50 #--- shift vertically\n",
    "#         attrs = {'markevery':1,'markersize':8}\n",
    "#         list(map(lambda x:PltErr(x,r,ax=ax0,\n",
    "#                                  attrs={'fmt':'-','label':load,'color':'C0'},\n",
    "#                                  Plot=False,\n",
    "# #                                ylim=(np.min(r),np.max(r)),\n",
    "# #                                xlim=(-14,14),\n",
    "#                                 ),vx.T[timei:timei+1]))\n",
    "                                 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval(confParser['flags']['DislocAnl']) and not\\\n",
    "   eval(confParser['flags']['RemoteMachine']):\n",
    "    \n",
    "    #--- plot\n",
    "    symbols = Symbols()\n",
    "    legends = Legends()\n",
    "    legends.Set(fontsize=16,\n",
    "                labelspacing=.2,\n",
    "                bbox_to_anchor=[(0.53,0.46,0.5,0.5),(0.3,0.42,0.5,0.5)][indxx]            \n",
    "               )\n",
    "    axc=PltErr([0,761],[0,0],attrs={'fmt':'-.r'},Plot=False)\n",
    "\n",
    "            \n",
    "\n",
    "    #--- plot correlations\n",
    "    #--- correlation\n",
    "    list(map(lambda x:PltCrltnn(r,x[0],\n",
    "                    Plot=True,\n",
    "                   ax=axc,\n",
    "                   attrs=symbols.GetAttrs(count=x[1],label=r'$%s$'%loads[x[1]],nevery=8,fmt='-'),\n",
    "                        ),\n",
    "             zip(hx.T,range(10))))\n",
    "                                             \n",
    "    utl.PltErr(None,None,ax=axc,\n",
    "               marker='o',\n",
    "               DrawFrame=[0.2,0.1,0.15,0.1,0.01],\n",
    "               ylim=(-1,1),\n",
    "               xlim=(0,(np.max(r)-np.min(r))/2),\n",
    "            title='dislocations/h0_crltn_%s.png'%indxx,\n",
    "           legend=legends.Get(),\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## velocity correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def minImage(v,box,verbose=False):\n",
    "    lx = box.CellVector[ 0, 0 ]\n",
    "    #--- minimum image\n",
    "    v -= (np.mean(v) >= 0.5*lx) * lx\n",
    "    v += (np.mean(v) < -0.5*lx) * lx\n",
    "    return v\n",
    "\n",
    "if eval(confParser['flags']['DislocAnl']):\n",
    "    times = list(atomss.keys())\n",
    "    times.sort()\n",
    "\n",
    "    for idd in [0,1]:\n",
    "        #--- interpolate\n",
    "        ax = PltErr(None,None,Plot=False)\n",
    "        #--- discretized x\n",
    "        xint, junk, junk = interp(atomss[timei][idd],box,timei,Plot=False)\n",
    "        yint = np.c_[list(map(lambda x:interp(atomss[x][idd],box,x,Plot=False,ax=ax,                             \n",
    "                                             )[1],times))]\n",
    "\n",
    "\n",
    "        #--- velocity fluctuations\n",
    "        print('h.shape=',yint.shape)\n",
    "    #    vel0=np.diff((yint0.T-np.mean(yint0,axis=1)),axis=1).T\n",
    "        vel=np.diff((yint.T),axis=1).T\n",
    "        vel=np.c_[list(map(lambda x:minImage(x,box),vel))] #--- pbc\n",
    "        dt = times[1]-times[0]\n",
    "        vel /= dt\n",
    "        #--- print\n",
    "        header = 'r\\t'+reduce(lambda x,y:x+y,map(lambda x: 'vx_%s\\t'%x ,range(vel.shape[0])))\n",
    "        np.savetxt('dislocations/vx%s_profile_multiple_times.txt'%idd,np.c_[xint,vel.T],header=header)\n",
    "        #\n",
    "    #    vel0=(vel0.T-np.mean(vel0,axis=1)).T #--- zero mean\n",
    "    #    vel0=(vel0.T/np.std(vel0,axis=1)).T  #--- unit variance\n",
    "    #    vel=np.c_[vel.T,1+vel[0,:]].T\n",
    "        print('v.shape=',vel.shape)\n",
    "\n",
    "        #--- plot\n",
    "        ntime=vel.shape[0]\n",
    "        timei=0\n",
    "        timef=ntime\n",
    "        ax=PltErr(None,None,Plot=False)\n",
    "        list(map(lambda x:PltErr(x,xint,ax=ax,\n",
    "                                 attrs={'fmt':'-'},\n",
    "                                 Plot=False,\n",
    "                                 ystr=r'$z$' if not eval(confParser['flags']['RemoteMachine']) else 'z',\n",
    "                                 xstr=r'$v_x(z)$' if not eval(confParser['flags']['RemoteMachine']) else 'vx(z)'),\n",
    "                 vel[timei:timef]))\n",
    "        plt.show()\n",
    "    \n",
    "        #--- plot lines & atoms\n",
    "#         list(map(lambda x:PltDislAtoms(xint,yint[x[1]],\n",
    "#                                   lmpData.coord_atoms_broken[ x[0] ],\n",
    "#                                   atomss[ x[0] ][ idd ],\n",
    "#                                   box,\n",
    "#                                   'dislocations/DislVelocItime%s_id%s.png'%(x[0],idd),\n",
    "#                                  dx = vel[x[1]],\n",
    "#                                  dy = np.zeros(len(yint[x[1]])),\n",
    "#                                     Plot=False,\n",
    "#                                       ),\n",
    "#                  zip(times,range(ntime))))\n",
    "\n",
    "\n",
    "        list(map(lambda x:        \n",
    "            PltDislAtomsWrapperFunc(\n",
    "            df=lmpData.coord_atoms_broken[ x[0] ], \n",
    "            box=lp.Box( BoxBounds = lmpData.BoxBounds[0],AddMissing = np.array([0.0,0.0,0.0] ) ), \n",
    "            dx = vel[x[1]],\n",
    "            dy = np.zeros(len(vel[x[1]])),\n",
    "            Plot = False,\n",
    "            df_disc=atomss[ x[0] ][ idd ],\n",
    "            title='dislocations/DislVelocItime%s_id%s.png'%(x[0],idd),\n",
    "            dpi=150,\n",
    "            DrawFrame=[0.2,0.1,0.15,0.1,0.01],\n",
    "            ),zip(times,range(ntime))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def vonMises(df):\n",
    "#     return np.array(list(np.sqrt(0.5*((df.sxx-df.syy)**2+(df.syy-df.szz)**2+(df.szz-df.sxx)**2)+3*(df.sxy**2+df.syz**2+df.sxz**2))))\n",
    "\n",
    "# #--- plot stress\n",
    "# indx=8 #7 #6 #4\n",
    "# itime=times[indx]\n",
    "# idd = 1\n",
    "# #\n",
    "# PltDislAtomsWrapperFunc(\n",
    "# df=lmpData.coord_atoms_broken[ itime ], \n",
    "# box=lp.Box( BoxBounds = lmpData.BoxBounds[0],AddMissing = np.array([0.0,0.0,0.0] ) ), \n",
    "# dx = vel[indx],\n",
    "# dy = np.zeros(len(vel[indx])),\n",
    "# Plot = True,\n",
    "# df_disc=atomss[ itime ][ idd ],\n",
    "# title='dislocations/DislStressItime%s_id%s.png'%(itime,idd),\n",
    "# dpi=150,\n",
    "# DrawFrame=[0.2,0.1,0.15,0.1,0.01],\n",
    "# stress = vonMises(lmpData.coord_atoms_broken[ itime ]),\n",
    "# )\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiple timesteps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot\n",
    "#### mean velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "indxx=0 #--- csa, rss\n",
    "dislocation_id = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if eval(confParser['flags']['DislocAnl']) and not\\\n",
    "   eval(confParser['flags']['RemoteMachine']):\n",
    "\n",
    "    loads= [\n",
    "                        [1300,1200,1100,1000,950,750,700,650,600,500], #--- csa\n",
    "                        [1200,1100,900,800,750,700,650,600,550,500,400], #--- rsa\n",
    "\n",
    "][indxx]\n",
    "\n",
    "    #--- parse\n",
    "    ps = parse('vx0_profile_multiple_times.txt',\n",
    "               'vx1_profile_multiple_times.txt'\n",
    "              )\n",
    "    vx = np.array(list(map(lambda x:ps.ParseData(\n",
    "              load=x,\n",
    "              pathh=[\n",
    "                     'NiCoCrNatom100KTemp600/dislocated/load%s/Run0/dislocations'%x,\n",
    "                     'NiCoCrNatom100KTemp600Rss/dislocated/load%s/Run0/dislocations'%x,\n",
    "                    ][indxx],\n",
    "              dislocation_id = dislocation_id,\n",
    "                ), loads))).T\n",
    "    r = ps.Get_r()\n",
    "    print('vx.shape=',vx.shape)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #--- plot\n",
    "    ax=PltErr(None,None,Plot=False)\n",
    "    list(map(lambda x:PltErr(np.arange(x.shape[1]),np.abs(np.mean(x,axis=0)),\n",
    "                   ax=ax,\n",
    "                    attrs={'fmt':'.','markersize':12},\n",
    "                    xstr=r'itime',\n",
    "                    ystr=r'$\\langle v_x \\rangle$',\n",
    "                    yscale='log',\n",
    "                    ylim=(1e-8,1e4),\n",
    "                   Plot=False,\n",
    "                    ), vx))\n",
    "        \n",
    "    #--- average\n",
    "    vx_mean=list(map(lambda x:10**np.mean(np.log10(np.abs(x))),vx)) #--- mean velocity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval(confParser['flags']['DislocAnl']) and not\\\n",
    "   eval(confParser['flags']['RemoteMachine']):\n",
    "    \n",
    "    prefact = 1e-10/(0.004*0.001*1e-9)\n",
    "    np.savetxt('dislocations/mobility_%s.txt'%indxx,np.c_[loads,prefact*np.array(vx_mean)])\n",
    "    PltErr(loads,prefact*np.array(vx_mean),\n",
    "#           yscale='log',\n",
    "       DrawFrame=[0.2,0.1,0.15,0.1,0.01],\n",
    "        title='dislocations/mobility_%s.png'%indxx,\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval(confParser['flags']['DislocAnl']) and not\\\n",
    "   eval(confParser['flags']['RemoteMachine']):\n",
    "    data0 = np.loadtxt('dislocations/mobility_%s.txt'%0)\n",
    "    data1 = np.loadtxt('dislocations/mobility_%s.txt'%1)\n",
    "    symbols=Symbols()\n",
    "    legends = Legends()\n",
    "    legends.Set(fontsize=16,labelspacing=.2,\n",
    "#                bbox_to_anchor=(0.5,0.44,0.5,0.5),\n",
    "#                bbox_to_anchor=(0.65,0.3,0.5,0.5),\n",
    "               )\n",
    "\n",
    "    ax=utl.PltErr(data1[:,0],data1[:,1],Plot=False,\n",
    "            attrs=symbols.GetAttrs(count=0,label='RSA',fmt='-'),\n",
    "              )\n",
    "\n",
    "    utl.PltErr(data0[:,0],data0[:,1],\n",
    "            attrs=symbols.GetAttrs(count=1,label='annealed',fmt='-'),\n",
    "              ax=ax,\n",
    "    #           yscale='log',\n",
    "           DrawFrame=[0.2,0.1,0.15,0.1,0.01],\n",
    "            title='dislocations/mobility.png',\n",
    "        legend=legends.Get(),          \n",
    "              )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  velocity profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval(confParser['flags']['DislocAnl']) and not\\\n",
    "   eval(confParser['flags']['RemoteMachine']):\n",
    "    \n",
    "    #--- parse data\n",
    "    load = 1200\n",
    "    ps = parse('vx0_profile_multiple_times.txt',\n",
    "               'vx1_profile_multiple_times.txt'\n",
    "              )\n",
    "    vx = ps.ParseData(\n",
    "              load=load,\n",
    "              pathh=[\n",
    "                     'NiCoCrNatom100KTemp600/dislocated/load%s/Run0/dislocations'%load,\n",
    "                     'NiCoCrNatom100KTemp600Rss/dislocated/load%s/Run0/dislocations'%load,\n",
    "                    ][indxx],\n",
    "              dislocation_id = dislocation_id,\n",
    "#              index = range(10,20),\n",
    "                ).T\n",
    "    r = ps.Get_r()\n",
    "    print('vx.shape=',vx.shape)\n",
    "    ntime=vx.shape[1]\n",
    "    timei=int(ntime/2)\n",
    "    timef=ntime\n",
    "    \n",
    "    \n",
    "    \n",
    "    #--- plot\n",
    "    ax0=PltErr(None,None,Plot=False)\n",
    "    shift = lambda x:(1+x)*50 #--- shift vertically\n",
    "    attrs = {'markevery':1,'markersize':8}\n",
    "    list(map(lambda x:PltErr((x[0]-np.mean(x[0]))/np.std(x[0])+5*(x[1]-2),r,ax=ax0,\n",
    "                             attrs={'fmt':'-','label':load,'color':'C0'},\n",
    "                             Plot=False,\n",
    "                            ylim=(np.min(r),np.max(r)),\n",
    "                            xlim=(-14,14),\n",
    "                            ),zip(vx.T[timei:timef:3],range(5))))\n",
    "    list(map(lambda x:PltErr([5*(x-2),5*(x-2)],[np.min(r),np.max(r)],ax=ax0,\n",
    "                             attrs={'fmt':'-.','color':'C0'},\n",
    "                             Plot=False,\n",
    "                            ),range(5)))\n",
    "                                 \n",
    "    utl.PltErr(None,None,ax=ax0,\n",
    "               marker='o',\n",
    "                DrawFrame=[0.2,0.1,0.15,0.1,0.01],\n",
    "                title='dislocations/v0_%s.png'%indxx,\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  velocity correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval(confParser['flags']['DislocAnl']) and not\\\n",
    "   eval(confParser['flags']['RemoteMachine']):\n",
    "    xint = r\n",
    "    \n",
    "    #--- plot\n",
    "    legends = Legends()\n",
    "    legends.Set(fontsize=16,labelspacing=.2)\n",
    "    \n",
    "    ax=utl.PltErr([0,(np.max(r)-np.min(r))/2],[0,0],attrs={'fmt':'-.r'},Plot=False)\n",
    "    \n",
    "    #--- correlation\n",
    "    cvx = np.c_[list(map(lambda x:PltCrltnn(xint,x[0],ax=ax,\n",
    "                           attrs=symbols.GetAttrs(count=x[1],label=r'$(%s)$'%(x[1]+1),nevery=8,fmt='-'),\n",
    "                                           )[1].real,\n",
    "             zip(vx.T[timei:timef:3],range(5))))]\n",
    "    #---save\n",
    "    utl.PltErr(None,None,ax=ax,\n",
    "           marker='o',\n",
    "       DrawFrame=[0.2,0.1,0.15,0.1,0.01],\n",
    "        title='dislocations/v0_crltn_%s.png'%indxx,\n",
    "        ylim=(-1,1),\n",
    "        xlim=(0,(np.max(r)-np.min(r))/2),\n",
    "        legend=legends.Get(),          \n",
    "          )\n",
    "    plt.show()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multiple loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if eval(confParser['flags']['DislocAnl']) and not\\\n",
    "   eval(confParser['flags']['RemoteMachine']):\n",
    "    count=0\n",
    "    #--- initialize plot object\n",
    "    ax=PltErr([0,(np.max(r)-np.min(r))/2],[0,0],attrs={'fmt':'-.r'},Plot=False)\n",
    "    legends = Legends()\n",
    "    legends.Set(fontsize=16,labelspacing=.2,\n",
    "                bbox_to_anchor=(0.5,0.44,0.5,0.5),\n",
    "#                bbox_to_anchor=(0.65,0.3,0.5,0.5),\n",
    "               )\n",
    "\n",
    "        \n",
    "    for load in [\n",
    "                        [1300,1200,1100,1000], #--- csa\n",
    "                        [1200,1100,900,800,750,700], #--- rsa\n",
    "][indxx]:\n",
    "\n",
    "        print('load=%s'%load)\n",
    "        pathh = [\n",
    "                 'NiCoCrNatom100KTemp600/dislocated/load%s/Run0/dislocations'%load, #--- csa\n",
    "                 'NiCoCrNatom100KTemp600Rss/dislocated/load%s/Run0/dislocations'%load, #--- rsa\n",
    "                'dislocations'\n",
    "        ][indxx]\n",
    "        try:\n",
    "            sdata0 = np.loadtxt('%s/vx0_profile_multiple_times.txt'%pathh) #--- velocity profile\n",
    "            sdata1 = np.loadtxt('%s/vx1_profile_multiple_times.txt'%pathh) #--- velocity profile\n",
    "\n",
    "            #--- fetch data\n",
    "            r = sdata0[:,0]\n",
    "            vx0 = sdata0[:,1:]\n",
    "            vx1 = sdata1[:,1:]\n",
    "\n",
    "            #--- plot\n",
    "            ntime=vx1.shape[1]\n",
    "            timei=int(ntime/2)\n",
    "            timef=ntime\n",
    "            \n",
    "            #--- correlations\n",
    "            xint = r\n",
    "\n",
    "            #--- plot\n",
    "\n",
    "            #--- correlation\n",
    "            vx = [vx0,vx1][dislocation_id]\n",
    "            cvx = np.c_[list(map(lambda x:PltCrltnn(xint,x,Plot=False,#ax=ax,\n",
    "        #                            xstr=r'$|z-z^\\prime|$' if not eval(confParser['flags']['RemoteMachine']) else 'dz',\n",
    "        #                               ystr=r'$\\langle v_x(z)v_x(z^\\prime)\\rangle$' if not eval(confParser['flags']['RemoteMachine']) else 'c(dz)',\n",
    "                                                   )[1].real,\n",
    "                     vx.T[timei:timef:1]))]\n",
    "\n",
    "            #--- plot correlations\n",
    "            z = PltCrltnn(xint,cvx[0],Plot=False)[0]\n",
    "#            print('z.shape=',z.shape)\n",
    "#            print('cvv.shape=',cvx.shape)\n",
    "            cmean = np.mean(cvx,axis=0)\n",
    "#            print('cmean.shape=',cmean.shape)\n",
    "            erry = np.std(cvx,axis=0)/len(cvx)**0.5\n",
    "\n",
    "            utl.PltErr(z,cmean,yerr=None, Plot=False,\n",
    "                   ax=ax, #markevery=8,Plot=False,label=r'$%s$'%load,\n",
    "                           attrs=symbols.GetAttrs(count=count,label=r'$%s$'%load,nevery=8,fmt='-')\n",
    "                  )\n",
    "\n",
    "        \n",
    "            count += 1\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "            \n",
    "# utl.PltErr(None,None,ax=ax,\n",
    "#        DrawFrame=[0.2,0.1,0.15,0.1,0.01],\n",
    "#        attrs={'markevery':8},\n",
    "#         title='dislocations/v0_crltn_%s_multipleLoads.png'%indxx,\n",
    "#         legend=legends.Get(),          \n",
    "#                ylim=(-0.5,1),\n",
    "#         xlim=(0,(np.max(r)-np.min(r))/2),\n",
    "\n",
    "#       )\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     z = PltCrltn(xint,cvx[0],Plot=False)[0]\n",
    "#     print('z.shape=',z.shape)\n",
    "#     print('cvv.shape=',cvx.shape)\n",
    "#     cmean = np.mean(cvx,axis=0)\n",
    "#     print('cmean.shape=',cmean.shape)\n",
    "#     erry = np.std(cvx,axis=0)/len(cvx)**0.5\n",
    "\n",
    "#     PltErr(z,cmean,yerr=erry,\n",
    "#  #            xstr=r'$|z-z^\\prime|$' if not RemoteMachine else 'dz',\n",
    "#  #            ystr=r'$\\langle v_x(z).v_x(z^\\prime)\\rangle$' if not RemoteMachine else 'c(dz)'\n",
    "#           )\n",
    "#     print('ksi_mean=',z[cmean<0][0])\n",
    "# #     np.savetxt('dislocations/vxcrltn.txt',np.c_[z,cmean.real,erry.real],header='z\\tv_x(z)\\terr')\n",
    "# #     np.savetxt('dislocations/vxlength.txt',np.c_[temperature,z[cmean.real<0][0]],header='temp\\tksi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     z = PltCrltn(xint,cvx[0],Plot=False)[0]\n",
    "#     print('z.shape=',z.shape)\n",
    "#     print('cvv.shape=',cvx.shape)\n",
    "#     cmean = np.mean(cvx,axis=0)\n",
    "#     print('cmean.shape=',cmean.shape)\n",
    "#     erry = np.std(cvx,axis=0)/len(cvx)**0.5\n",
    "\n",
    "#     PltErr(z,cmean,yerr=erry,\n",
    "#  #            xstr=r'$|z-z^\\prime|$' if not RemoteMachine else 'dz',\n",
    "#  #            ystr=r'$\\langle v_x(z).v_x(z^\\prime)\\rangle$' if not RemoteMachine else 'c(dz)'\n",
    "#           )\n",
    "#     print('ksi_mean=',z[cmean<0][0])\n",
    "# #     np.savetxt('dislocations/vxcrltn.txt',np.c_[z,cmean.real,erry.real],header='z\\tv_x(z)\\terr')\n",
    "# #     np.savetxt('dislocations/vxlength.txt',np.c_[temperature,z[cmean.real<0][0]],header='temp\\tksi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if eval(confParser['flags']['DislocAnl']) and not\\\n",
    "#    eval(confParser['flags']['RemoteMachine']):\n",
    "#     for load in ['500','600','700','800']: #--- different loads\n",
    "#         print('load=%s'%load)\n",
    "#         pathh = 'NiCoCrNatom100KTemp600/dislocated/load%s/Run0/dislocations'%load\n",
    "#         sdata = np.loadtxt('%s/vxcrltn_multiple_times.txt'%pathh)\n",
    "#         r = sdata[:,0]\n",
    "#         cvx = sdata[:,1:]\n",
    "\n",
    "#         #--- correlation\n",
    "#         ax=PltErr(None,None,Plot=False)\n",
    "#         list(map(lambda x:PltErr(r,x,ax=ax,\n",
    "#                                 attrs={'fmt':'-'},\n",
    "#                                 Plot=False,\n",
    "#                                 ),\n",
    "#                  cvx.T))\n",
    "#         PltErr(ax.axis()[:2],[0,0],ax=ax,\n",
    "#                Plot=False,\n",
    "#                 xstr=r'$|z-z^\\prime|$',\n",
    "#                 ystr=r'$\\langle v_x(z)v_x(z^\\prime)\\rangle$',\n",
    "#                attrs={'fmt':'-.','color':'black','lw':2},\n",
    "#                title='dislocations/vxcrltn_%s.png'%load\n",
    "#               )\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lengthscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if eval(confParser['flags']['DislocAnl']) and not\\\n",
    "#    eval(confParser['flags']['RemoteMachine']):\n",
    "#     ksii = {}\n",
    "#     for load in [500,600,700,800]:\n",
    "#         print('load=%s'%load)\n",
    "#         pathh = 'NiCoCrNatom100KTemp600/dislocated/load%s/Run0/dislocations'%load\n",
    "#         sdata = np.loadtxt('%s/vxlength_multiple_times.txt'%pathh)\n",
    "#         n=len(sdata)\n",
    "\n",
    "#         ax=PltErr(sdata[:,0],sdata[:,1],\n",
    "#            attrs={'fmt':'o'},\n",
    "#            xstr=r'$t$',\n",
    "#            ystr=r'$\\xi$',\n",
    "#             Plot=False,\n",
    "#           )\n",
    "\n",
    "#         ksii[load]=utll.GetQuantile(pd.Series(sdata[:,1]),0.95)\n",
    "\n",
    "#         PltErr(ax.axis()[:2],[ksii[load],ksii[load]],\n",
    "#                 attrs={'fmt':'-.r'},\n",
    "#                Plot=False,\n",
    "#                ax=ax\n",
    "#               )\n",
    "        \n",
    "#     PltErr(ksii.keys(),list(map(lambda x:ksii[x],ksii.keys())),\n",
    "# #            attrs={'fmt':'-.r'},\n",
    "#            marker='o',\n",
    "#            fmt='.',\n",
    "#            Plot=True,\n",
    "#            xstr=r'$\\sigma$',\n",
    "#            ystr=r'$\\xi$',\n",
    "#            title='dislocations/xi.png',\n",
    "#           )\n",
    "    \n",
    "# #RemoteMachine=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# max shear plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "\n",
    "def GetEig(svect):\n",
    "    smat=np.array([[svect[0],svect[3],svect[4]],\n",
    "                   [svect[3],svect[1],svect[5]],\n",
    "                   [svect[4],svect[5],svect[2]]])\n",
    "    w, v = LA.eigh(smat)\n",
    "    smax = 0.5*(w[2]-w[0])\n",
    "    nvec = v[1]\n",
    "    return smax\n",
    "\n",
    "if eval(confParser['flags']['maxshear']):\n",
    "    pref = 1e-6 #--- pa to gpa\n",
    "    keys = list(lmpData.coord_atoms_broken.keys())\n",
    "    keys.sort()\n",
    "\n",
    "\n",
    "    for itime in keys:\n",
    "        print('itime=',itime)\n",
    "        df = lmpData.coord_atoms_broken[itime]\n",
    "        stress = np.c_[df[['sxx', 'syy', 'szz','sxy', 'sxz', 'syz']]]\n",
    "        smax = np.array(list(map(lambda x:GetEig(x),stress)))*pref\n",
    "\n",
    "        df_new = pd.DataFrame(np.c_[df['id type x y z'.split()],smax],columns='id type x y z val'.split())\n",
    "\n",
    "        atom = lp.Atoms(**df_new.to_dict(orient='series'))\n",
    "        box  = lp.Box( BoxBounds = lmpData.BoxBounds[itime], AddMissing = np.array([0.0,0.0,0.0] ))\n",
    "        wd = lp.WriteDumpFile(atom, box)\n",
    "        output = open('dump.xyz','a')\n",
    "        wd.Write(output,itime=itime,\n",
    "                 attrs=['id', 'type', 'x', 'y', 'z','val'], \n",
    "                 fmt='%i %i %4.3e %4.3e %4.3e %4.3e')\n",
    "        output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# irradiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Statistics:\n",
    "    pref = 1e-4 #--- bar to GPA\n",
    "    def __init__(self,path,verbose=False):\n",
    "\n",
    "        self.path = path\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        #--- list of files\n",
    "        self.inputFiles = os.listdir('%s'%(path))\n",
    "        if self.verbose:\n",
    "            print('class Statistics constructor call: inputFiles=',np.array(self.inputFiles))\n",
    "            \n",
    "            \n",
    "    def ParseDump(self,fp):\n",
    "        if self.verbose:\n",
    "            print('parsing %s/%s:'%(self.path,fp))\n",
    "        self.lmpData = lp.ReadDumpFile('%s/%s'%(self.path,fp)) #,verbose=self.verbose)\n",
    "        self.lmpData.GetCords(ncount=sys.maxsize)\n",
    "        #--- print\n",
    "        if self.verbose:\n",
    "            keys = list(self.lmpData.coord_atoms_broken.keys())\n",
    "            keys.sort()\n",
    "            display(self.lmpData.coord_atoms_broken[keys[0]])\n",
    "            \n",
    "    def GetStressDump(self):\n",
    "        '''\n",
    "        return stress timeseries from dump file\n",
    "        '''\n",
    "        #--- timesteps\n",
    "        keys = list(self.lmpData.coord_atoms_broken.keys())\n",
    "        keys.sort()\n",
    "\n",
    "        #--- virial\n",
    "        szz = np.array(list(map(lambda x:self.lmpData.coord_atoms_broken[x]['c_mystress[3]'].sum(),keys)))\n",
    "\n",
    "        #--- volume\n",
    "        vol = np.array(list(map(lambda x:np.linalg.det(lp.Box(BoxBounds=self.lmpData.BoxBounds[x],\n",
    "                                                     AddMissing=np.array([0,0,0])).CellVector),\n",
    "                       keys)))\n",
    "\n",
    "        ezz = Statistics.Strain(self.lmpData)\n",
    "        self.dmpStrs=pd.DataFrame(np.c_[keys,ezz,Statistics.pref*szz/vol,szz],\n",
    "                                  columns=['timestep','strain','szz','virial'])\n",
    "\n",
    "    \n",
    "    def ParseTimeSeries(self,fp,\n",
    "                        max_rows=1000000,\n",
    "                        skiprows=0,\n",
    "                        cols=['timestep']):    \n",
    "        if self.verbose:\n",
    "            print('parsing %s/%s:'%(self.path,fp))\n",
    "        self.loadTimeSeries=pd.DataFrame(np.c_[np.loadtxt('%s/%s'%(self.path,fp),max_rows=max_rows,skiprows=skiprows)],\n",
    "                        columns=cols,\n",
    "                                   )\n",
    "        self.loadTimeSeriesOriginal = self.loadTimeSeries.copy()\n",
    "        #--- add timesteps: thermo.txt must include every timestep!\n",
    "#         n=loadTimeSeries.shape[0]\n",
    "#         self.loadTimeSeries=pd.DataFrame(np.c_[range(n),loadTimeSeries],\n",
    "#                                          columns = ['timestep']+list(loadTimeSeries.keys()))\n",
    "        \n",
    "    def PltTimeSeries(self,ld, xdata='strain',ydata='szz',\n",
    "                      **kwargs):\n",
    "\n",
    "        #--- set limits\n",
    "\n",
    "        #--- time\n",
    "        tlo = ld[xdata].min() if not 'xlim' in kwargs else kwargs['xlim'][0]\n",
    "        thi = ld[xdata].max() if not 'xlim' in kwargs else kwargs['xlim'][1] #ld.Time.max()\n",
    "        filtr=np.all([ld[xdata]<thi,ld[xdata]>=tlo],axis=0)\n",
    "#         # #--- load\n",
    "        flo = 0.99*ld[ydata][filtr].min()\n",
    "        fhi = 1.01*ld[ydata][filtr].max() \n",
    "\n",
    "        #--- rate\n",
    "        rate = -np.gradient(ld[ydata],ld[xdata])\n",
    "        filtr = np.all([filtr,rate > 0],axis=0)\n",
    "        rlo = 0.99*rate[filtr].min()\n",
    "        rhi = 1.01*rate[filtr].max() \n",
    "\n",
    "\n",
    "        ax=utl.PltErr(None,None,Plot=False)\n",
    "\n",
    "        utl.PltErr(ld[xdata][filtr], rate[filtr],\n",
    "                   attrs={'fmt':'.','color':'red','ms':.4},\n",
    "                    Plot=False,\n",
    "                      ax=ax,\n",
    "        #           yscale='log',\n",
    "#                    xlim=(tlo,thi),\n",
    "                    ylim=kwargs['ylim'] if 'ylim' in kwargs else (rlo,rhi),\n",
    "\n",
    "                  )\n",
    "\n",
    "        #--- load vs. time\n",
    "        utl.PltErr(ld[xdata], ld[ydata],\n",
    "                   attrs={'fmt':'-','color':'C0'},\n",
    "        #             Plot=False,\n",
    "#                    xlim=(tlo,thi),\n",
    "                   ylim=kwargs['ylim'] if 'ylim' in kwargs else (flo,fhi),\n",
    "                   ax=ax,\n",
    "                      twinx=True,\n",
    "#                    title='png/stress_timeseries.png',\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "    @staticmethod\n",
    "    def GetAvl( t,x, y, lambdc ):\n",
    "        n = len(x)\n",
    "        i = 0\n",
    "        smat = [[],[],[],[],[]]\n",
    "        try:\n",
    "            while True:\n",
    "                while y[i] < lambdc:\n",
    "                    i += 1\n",
    "                assert y[i] >= lambdc\n",
    "                #--- avalanche starts\n",
    "                dur = 0\n",
    "    #            size = 0.0 #y[i]\n",
    "                start = x[i]\n",
    "                start_indx = i\n",
    "                start_t = t[i]\n",
    "                while y[i]>=lambdc: #-x[i] == 1:\n",
    "                    dur += 1\n",
    "    #                size += (y[i]-lambdc)\n",
    "                    i += 1\n",
    "                #--- avalanche ends\n",
    "                assert y[i] < lambdc\n",
    "                end = x[i] #x[i-1 if i-1 >= 0 else 0]\n",
    "                end_indx = i #i-1 if i-1>= 0 else 0\n",
    "                end_t = t[i] #i-1 if i-1>= 0 else 0\n",
    "                #--- size\n",
    "                sub_x = x[start_indx:end_indx+1]\n",
    "                sub_y = y[start_indx:end_indx+1]\n",
    "                size = np.sum((sub_x[1:]-sub_x[:-1])*sub_y[:-1])\n",
    "    #            print start, end, size\n",
    "                #--- find epicenter\n",
    "                smat = np.c_[smat,[start, end, start_t, end_t, size]]\n",
    "        except:\n",
    "    #        traceback.print_exc()\n",
    "            pass\n",
    "\n",
    "        assert smat.shape[1] > 0, 'Lower lambdc! lambdc='%lambdc\n",
    "        df_avl = pd.DataFrame(smat.T,columns=['ei','ef','ti','tf','size'])\n",
    "        df_avl=df_avl[df_avl['size']>0]\n",
    "        return df_avl\n",
    "    \n",
    "    @staticmethod\n",
    "    def Wrapper_GetAvl(t,x,y,tlo,thi,lambdc):\n",
    "        '''\n",
    "        return avalanche sizes given force timeseries and initial and final times\n",
    "        '''\n",
    "\n",
    "#        pdb.set_trace()\n",
    "\n",
    "        signal = -np.gradient(y,x)\n",
    "        if lambdc == 'median':\n",
    "            filtr = signal > 0\n",
    "            lambdc = np.median(signal[filtr])\n",
    "            print('threshold=',lambdc)\n",
    "        df_avl = Statistics.GetAvl( t,np.array(x), signal, lambdc)\n",
    "        df_avl.sort_values( by = 'ti',ascending = True,inplace=True)\n",
    "\n",
    "        #--- data frame storing avalanche attributes\n",
    "#         pdb.set_trace()\n",
    "        filtr = np.all([df_avl.ei>=tlo,df_avl.ef<thi],axis=0)\n",
    "\n",
    "        return df_avl[filtr]\n",
    "    \n",
    "    def Avalanche(self, ld, xdata='strain',value='szz',    \n",
    "        lambdc = 0.0, #--- threshold\n",
    "        **kwargs\n",
    "                 ):\n",
    "        tlo = ld[xdata].min() if not 'strain_lo' in kwargs else kwargs['strain_lo']\n",
    "        thi = ld[xdata].max() if not 'strain_hi' in kwargs else kwargs['strain_hi']\n",
    "                \n",
    "\n",
    "            #--- thermo.txt includes every timestep: x.index == x.timestep!\n",
    "        try:\n",
    "            self.df_avl = Statistics.Wrapper_GetAvl(list(ld.index),ld[xdata],ld[value],tlo,thi,lambdc)\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "            print('increase the threshold!!!')\n",
    "\n",
    "        print('# of avalanches:%s'%self.df_avl.shape[0])\n",
    "\n",
    "\n",
    "    def SizeDist(self,sizes, fout, **kwargs):\n",
    "#        smax = np.max(sizes)\n",
    "        hist, edge, err = utl.GetPDF(sizes, n_per_decade=6, linscale=None, **kwargs)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('write in %s'%fout)\n",
    "            \n",
    "        #--- output as json\n",
    "        if 'json' in kwargs and kwargs['json']:\n",
    "            ti = kwargs['ti']\n",
    "            tf = kwargs['tf']\n",
    "            ei = kwargs['ei']\n",
    "            ef = kwargs['ef']\n",
    "            dictionary={'hist':list(hist),'edge':list(edge),'err':list(err),\n",
    "                        'timestep_i':ti, 'timestep_f':tf, 'strain_i':ei, 'strain_f':ef\n",
    "                       }\n",
    "            with open('avlStats/json/%s.json'%fout[:-4],'w') as fp:\n",
    "                json.dump(dictionary, fp)\n",
    "                \n",
    "        else: #--- txt file\n",
    "            with open(fout,'w') as fp:\n",
    "                if not kwargs['density']: #--- output histogram and edges\n",
    "                    np.savetxt(fp,np.c_[hist, edge[:-1], edge[1:], err],header='hist edge_left edge_right err')\n",
    "                else:\n",
    "                    np.savetxt(fp,np.c_[hist, edge, err],header='hist edge err')\n",
    "\n",
    "                \n",
    "    def SizeDistMultipleTimes(self,n=1000):\n",
    "        '''\n",
    "        return pdf every n avalanches\n",
    "        '''\n",
    "        \n",
    "        ntot = self.df_avl.shape[0]\n",
    "        assert n < ntot, 'decrease n!'\n",
    "        nlist=np.arange(0,ntot,n)\n",
    "        pairs = list(zip(nlist[:-1],nlist[1:]))\n",
    "        list(map(lambda x: self.SizeDist(sizes=self.df_avl['size'].iloc[x[0]:x[1]],\n",
    "                                         fout='pdf_s_%s.txt'%(x[0]),\n",
    "                                         ti =self.df_avl['ti'].iloc[x[0]], tf =self.df_avl['tf'].iloc[x[1]],\n",
    "                                         ei =self.df_avl['ei'].iloc[x[0]], ef =self.df_avl['ef'].iloc[x[1]],\n",
    "                                         json = True\n",
    "                                        ),\n",
    "                                     pairs)\n",
    "            )\n",
    "    \n",
    "    def Scatter(self,x,y,fout,**kwargs):\n",
    "        with open(fout,'w') as fp:\n",
    "            np.savetxt(fp,np.c_[x, y],header='size duration')\n",
    "            \n",
    "    def FiltrNoiseNonPeriod(self,kernel_width=1001):\n",
    "        '''\n",
    "        filter thermal noise\n",
    "        '''\n",
    "        if self.verbose:\n",
    "            print('filtering noise ...')\n",
    "        BOX_PTS = kernel_width #1000+1 #int(sys.argv[ 3 ]) #--- kernel width\n",
    "        assert BOX_PTS % 2 == 1, 'must be odd!'\n",
    "        value = np.array(list(self.loadTimeSeries.szz))\n",
    "        #\n",
    "        n=len(value)\n",
    "        unit=np.ones(n) \n",
    "        value= np.concatenate([value,np.zeros(n)]) #--- extend\n",
    "        unit= np.concatenate([unit,np.zeros(n)]) \n",
    "        try: #--- non-periodic function\n",
    "            box_pts=BOX_PTS\n",
    "            counter = 0 #--- counter\n",
    "            while box_pts > 0: #--- bulk+end\n",
    "                box = np.ones(box_pts)/box_pts\n",
    "                value_smooth = signal.convolve(value, box, mode='same')\n",
    "                unit_smooth = signal.convolve(unit, box, mode='same')\n",
    "                value_smooth=value_smooth/unit_smooth #[i] for i in xrange( n ) ]\n",
    "                if counter == 0:\n",
    "                    value_smooth0=[i for i in value_smooth] #--- store\n",
    "\n",
    "                value_smooth0[n-1-int((box_pts-1)/2)]=value_smooth[n-1-int((box_pts-1)/2)]\n",
    "                #\n",
    "                counter+=1\n",
    "                box_pts-=2\n",
    "        except:\n",
    "    #\t\ttraceback.print_exc()\n",
    "            pass\t\n",
    "        #---\n",
    "        try: #--- start\n",
    "            center=0\n",
    "            box_pts=1\n",
    "            while box_pts<BOX_PTS:\n",
    "                box = np.ones(box_pts)/box_pts\n",
    "                value_smooth = signal.convolve(value, box, mode='same')\n",
    "                unit_smooth = signal.convolve(unit, box, mode='same')\n",
    "                value_smooth=value_smooth/unit_smooth #[i] for i in xrange( n ) ]\n",
    "                index=n-(n-1-(box_pts-1)/2)\n",
    "                value_smooth0[center]=value_smooth[center]\n",
    "                #\n",
    "                center+=1\n",
    "                box_pts+=2\n",
    "        except:\n",
    "    #\t\ttraceback.print_exc()\n",
    "            pass\t\n",
    "        n=self.loadTimeSeries.shape[0]\n",
    "        self.loadTimeSeries.szz = np.array(value_smooth0[:n])\n",
    "        \n",
    "    def FiltrNoisePeriod(self,kernel_width=1001):\n",
    "        '''\n",
    "        filter thermal noise\n",
    "        '''\n",
    "        if self.verbose:\n",
    "            print('filtering noise ...')\n",
    "        BOX_PTS = kernel_width #1000+1 #int(sys.argv[ 3 ]) #--- kernel width\n",
    "#        assert BOX_PTS % 2 == 1, 'must be odd!'\n",
    "        value = np.array(list(self.loadTimeSeriesOriginal.szz))\n",
    "        #\n",
    "        n=len(value)\n",
    "        value= np.concatenate([value,np.zeros(n)]) #--- extend\n",
    "        box_pts=BOX_PTS\n",
    "        counter = 0 #--- counter\n",
    "#        box = np.ones(box_pts)\n",
    "        box = signal.windows.hann(box_pts)\n",
    "        value_smooth = signal.convolve(value, box, mode='full')/np.sum(box)\n",
    "        n=self.loadTimeSeriesOriginal.shape[0]\n",
    "        self.loadTimeSeries.szz = np.array(value_smooth[:n])\n",
    "        \n",
    "    def Filtr(self,**kwargs):\n",
    "        '''\n",
    "        filter timeseries\n",
    "        '''\n",
    "        n=len(self.loadTimeSeries)\n",
    "        filtr = np.ones(n,dtype=bool)\n",
    "        if 'strain_lo' in kwargs:\n",
    "            strains = self.loadTimeSeries.strain\n",
    "            filtr_strain_lo = np.array(strains)>= kwargs['strain_lo']\n",
    "            filtr = np.all([filtr,filtr_strain_lo],axis=0)\n",
    "        if 'strain_hi' in kwargs:\n",
    "            strains = self.loadTimeSeries.strain\n",
    "            filtr_strain_hi = np.array(strains)<kwargs['strain_hi']\n",
    "            filtr = np.all([filtr,filtr_strain_hi],axis=0)\n",
    "        self.loadTimeSeries = self.loadTimeSeries[filtr]\n",
    "\n",
    "    def kernelWidth(self, fout,output_path):\n",
    "        n=int(np.log2(self.loadTimeSeriesOriginal.shape[0]))\n",
    "        widths=np.logspace(1,n,n,base=2,dtype=int)\n",
    "        widths += 1\n",
    "        msee=np.zeros(len(widths))\n",
    "        for width,indx in zip(widths,range(len(msee))):\n",
    "\n",
    "            #--- filter noise\n",
    "            self.FiltrNoisePeriod(kernel_width=width)\n",
    "            msee[indx] = Statistics.mse(self.loadTimeSeriesOriginal.szz,\n",
    "                self.loadTimeSeries.szz\n",
    "               )\n",
    "            \n",
    "        with open(fout,'w') as fp:\n",
    "            np.savetxt(fp,np.c_[widths, msee],header='w mse')\n",
    "                \n",
    "        utl.PltErr(widths,msee,xscale='log', #yscale='log',\n",
    "                DrawFrame=DRAW_FRAME,\n",
    "                   title='%s/png/kernelWidth.png'%output_path\n",
    "                  )\n",
    "    @staticmethod\n",
    "    def linearFit(x,y):\n",
    "        y -= y[0]\n",
    "        return np.polyfit(x, y, 1)[0]\n",
    "        \n",
    "    def PlasticStrain(self,                                \n",
    "                            xdata='ezz',ydata='szz',\n",
    "                    ):\n",
    "        '''\n",
    "            add extra column associated with plastic defromation\n",
    "        '''\n",
    "        de = self.loadTimeSeries[xdata].iloc[1]-self.loadTimeSeries[xdata].iloc[0]\n",
    "        E_thresh = np.linspace(100*de,0.1,128)\n",
    "        modulus = {}\n",
    "        for ethresh in E_thresh:\n",
    "            filtr = np.all([self.loadTimeSeries[xdata] < ethresh, self.loadTimeSeries[xdata] >= 10*de],axis=0)\n",
    "            #--- fit a line\n",
    "#            pdb.set_trace()\n",
    "            modulus[ethresh] = Statistics.linearFit(\n",
    "                                np.array(self.loadTimeSeries[xdata][filtr]),\n",
    "                                np.array(self.loadTimeSeries[ydata][filtr]),\n",
    "                               )\n",
    "        #--- plot mu vs threshold\n",
    "        utl.PltErr(E_thresh,\n",
    "                    list(map(lambda x:modulus[x],E_thresh))\n",
    "                  )\n",
    "        ,\n",
    "\n",
    "        #--- compute modulus\n",
    "        mod95 = np.quantile(list(modulus.values()),0.95)\n",
    "        \n",
    "        print('mod95=',mod95)\n",
    "        \n",
    "        #--- plastic strain\n",
    "        self.loadTimeSeries['ep'] = self.loadTimeSeries[xdata] - self.loadTimeSeries[ydata] / mod95\n",
    "        \n",
    "    @staticmethod\n",
    "    def Strain(lmpData):\n",
    "        keys = list(lmpData.coord_atoms_broken.keys())\n",
    "        keys.sort()\n",
    "        assert len(keys) > 1\n",
    "        \n",
    "        itime0 = keys[ 0 ]\n",
    "        itime  = keys[ 1 ]\n",
    "        box = lp.Box( BoxBounds = lmpData.BoxBounds[itime], \n",
    "                     AddMissing = np.array([0.0,0.0,0.0] ))\n",
    "        box0 = lp.Box( BoxBounds = lmpData.BoxBounds[itime0], \n",
    "                     AddMissing = np.array([0.0,0.0,0.0] ))\n",
    "        #\n",
    "        dl =(box.CellVector[:,2][2] - box0.CellVector[:,2][2])\n",
    "        dl /= (itime-itime0)\n",
    "        #\n",
    "        L0 = box0.CellVector[:,2][2] - itime0 * dl\n",
    "        L = L0 + dl * np.array(keys)\n",
    "        #\n",
    "#        epsilon = (box.CellVector[:,2][2] / box0.CellVector[:,2][2]) - 1.0\n",
    "#        epsilon /= (itime-itime0)\n",
    "        return L/L0-1 #epsilon*np.array(keys)\n",
    "\n",
    "    @staticmethod\n",
    "    def mse(s1,s2):\n",
    "        return np.sum((s1-s2)**2)/s1.shape[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def LogBins(xlo,xhi,nbin_per_decade):\n",
    "        return np.logspace(np.log10(xlo),\n",
    "                           np.log10(xhi),\n",
    "                           nbin_per_decade*int(np.log10(xhi/xlo))\n",
    "                          )\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class Defects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Defects(Statistics):\n",
    "    '''\n",
    "    performs dislocation and phase analysis of input crystals\n",
    "    '''\n",
    "    StructureType=[0.0,1.0,2.0,3.0,4.0,5.0] #--- hard coded based on ovito's structure types\n",
    "    \n",
    "    def __init__(self,path,verbose=False):\n",
    "        Statistics.__init__(self,path,verbose)\n",
    "        if self.verbose:\n",
    "            print('calss Defects constructor call')\n",
    "\n",
    "        \n",
    "    def CrysPhase(self,input_file,output_path,nevery):\n",
    "        '''\n",
    "        dump phase information\n",
    "        \n",
    "        '''\n",
    "        #--- make folder\n",
    "        os.system('mkdir -p %s/dislocations/mydislocations'%output_path)\n",
    "        \n",
    "#         if eval(parser['cluster analysis']['clusterAnalysis']): #--- only for cluster analysis\n",
    "        if self.verbose:\n",
    "            print('dxa analysis ...')\n",
    "\n",
    "\n",
    "        #--- run ovitos\n",
    "        os.system('ovitos %s/OvitosCna.py %s mydislocations %s 5 %d'%\\\n",
    "                  (confParser['py library path']['py_lib'],input_file,nevery,eval('False')))\n",
    "        !mv mydislocations.*  $output_path/dislocations/mydislocations\n",
    "        \n",
    "#         if self.verbose:\n",
    "#             print('cna analysis ...')\n",
    "#         #--- cna analysis (dxa gives no bcc!)\n",
    "#         os.system('ovitos %s/OvitosCna.py %s %s/dislocations/mydislocations/cna_output.xyz %s 0'%\\\n",
    "#                   (parser['py library directory']['path'],input_file,output_path,nevery))\n",
    "\n",
    "    def PeriodicImage(self,input_file,output_path):\n",
    "        '''\n",
    "        replicates all particles\n",
    "        '''\n",
    "        if self.verbose:\n",
    "            print('periodic image ...')\n",
    "\n",
    "        #--- make folder\n",
    "        os.system('mkdir -p %s/dislocations/mydislocations'%output_path)\n",
    "        \n",
    "        #--- read original set\n",
    "        self.ParseDump(input_file)\n",
    "        timesteps = list(self.lmpData.BoxBounds.keys())\n",
    "        box = list(map(lambda x:lp.Box(BoxBounds=self.lmpData.BoxBounds[x],AddMissing=np.array([0,0,0])),timesteps))\n",
    "        box_original = dict(zip(timesteps,box))\n",
    "            \n",
    "        #--- run ovitos\n",
    "#        input_file='%s/%s'%(self.path,fp)\n",
    "#        pdb.set_trace()\n",
    "#        print('output_path=',output_path)\n",
    "        #---nevery set to 1 might lead to memory issue!!! \n",
    "        nevery = int(parser['dislocation analysis']['nevery'])\n",
    "        os.system('ovitos %s/OvitosCna.py %s %s/dislocations/mydislocations/periodic_image.xyz %s 9'%\\\n",
    "                  (parser['py library directory']['path'],input_file,output_path,nevery))\n",
    "        \n",
    "        #--- add a new field: inside the main cell \n",
    "        self.ParseDump('%s/dislocations/mydislocations/periodic_image.xyz'%output_path)\n",
    "        timesteps = list(self.lmpData.BoxBounds.keys())\n",
    "        box = list(map(lambda x:lp.Box(BoxBounds=self.lmpData.BoxBounds[x],AddMissing=np.array([0,0,0])),timesteps))\n",
    "        box_new = dict(zip(timesteps,box))\n",
    "        \n",
    "        #--- call wrap & add extra field \"isInside\"\n",
    "        list(map(lambda x:self.IsInside(self.lmpData.coord_atoms_broken[x],box_original[x]), timesteps))\n",
    "        \n",
    "        #--- output\n",
    "        with open('%s/dislocations/mydislocations/periodic_image_mod.xyz'%output_path,'a') as output:\n",
    "            list(map(lambda x:Defects.WriteDumpFile(self.lmpData.coord_atoms_broken[x],\n",
    "                                                box_new[x],\n",
    "                                                output,\n",
    "                                                x\n",
    "                                               ), timesteps))\n",
    "        \n",
    "\n",
    "        \n",
    "    def IsInside(self,df,box):\n",
    "#        pdb.set_trace()\n",
    "        atoms = lp.Atoms(**df.to_dict(orient='list'))\n",
    "        wp = lp.Wrap(atoms, box)\n",
    "        wp.isInside()\n",
    "        df['isInside'] = np.copy(wp.isInside())\n",
    "        #--- add field\n",
    "        \n",
    "    @staticmethod\n",
    "    def WriteDumpFile(df,box,outpt,itime):\n",
    "        atoms = lp.Atoms(**df.to_dict(orient='list'))\n",
    "        wd = lp.WriteDumpFile(atoms, box)\n",
    "        wd.Write(outpt, itime=itime, attrs=['id', 'type', 'x', 'y', 'z','isInside'], fmt='%i %i %4.3e %4.3e %4.3e %d')\n",
    "        \n",
    "\n",
    "    def ParseDump(self,fp,ncount=sys.maxsize):\n",
    "        if self.verbose:\n",
    "            print('parsing %s:'%(fp))\n",
    "        self.lmpData = lp.ReadDumpFile('%s'%(fp)) #,verbose=self.verbose)\n",
    "        self.lmpData.GetCords(ncount=ncount)\n",
    "        #--- print\n",
    "        if self.verbose:\n",
    "            keys = list(self.lmpData.coord_atoms_broken.keys())\n",
    "            keys.sort()\n",
    "            print('times:%s'%keys)\n",
    "            display(self.lmpData.coord_atoms_broken[keys[0]])\n",
    "\n",
    "    def Density(self,fout,header):\n",
    "        if self.verbose:\n",
    "            print('write in:',fout)\n",
    "        keys = list(self.lmpData.coord_atoms_broken.keys())\n",
    "        keys.sort()\n",
    "        self.ratios = np.c_[list(map(lambda x:Defects.phaseDensity(self.lmpData.coord_atoms_broken[x]),keys))]\n",
    "        self.strains = self.strains = Defects.Strain(self.lmpData)\n",
    "        #--- write\n",
    "        with open(fout,'w') as fp:\n",
    "            np.savetxt(fp,np.c_[keys,self.strains,self.ratios],header=header)\n",
    "\n",
    "    def BinaryMatrix(self):\n",
    "        '''\n",
    "        returns a binary matrix of clusters\n",
    "        '''\n",
    "        !mkdir -p dislocations/BinaryMatrix \n",
    "        times = list(self.lmpData.coord_atoms_broken.keys())\n",
    "        times.sort()\n",
    "        #--- loop over timesteps\n",
    "        for time, indx in zip(times,range(len(times))):\n",
    "#        for time, indx in zip(times,range(3)):\n",
    "            if self.verbose:\n",
    "                print('print BinaryMatrix%s.json'%time)\n",
    "            with open(\"dislocations/BinaryMatrix/BinaryMatrix%s.json\"%indx, \"w\") as outfile:\n",
    "                xlin,ylin,zlin,mask = Defects.Mask(self.lmpData.coord_atoms_broken[time],\n",
    "                                                   self.lmpData.BoxBounds[time]\n",
    "                                                  )\n",
    "                #--- output as json\n",
    "                dictionary={'x':list(xlin),'y':list(ylin),'z':list(zlin),\n",
    "                            'val':list(mask.flatten().astype(float)),\n",
    "                            'timestep':time}\n",
    "                json.dump(dictionary, outfile)\n",
    "            \n",
    "            \n",
    "    @staticmethod\n",
    "    def Mask(lmpData,BoxBounds,Plot=False):\n",
    "        '''\n",
    "        returns binary density matrix \n",
    "        '''\n",
    "        #--- fetch data\n",
    "        dmin_log = (lmpData['StructureType'] == 2).astype(int) #--- hcp phase\n",
    "        atom = lp.Atoms(**(lmpData))\n",
    "        box  = lp.Box( BoxBounds = BoxBounds,  \n",
    "                      AddMissing = np.array([0.0,0.0,0.0] ))\n",
    "        atom.tmp = list(dmin_log)\n",
    "         #-----------------\n",
    "         #--- INTERPOLATE\n",
    "         #-----------------\n",
    "        (xlin, ylin, zlin), (xv, yv, zv), mu_intrp = utl.Intrp(atom, box, 'tmp',\n",
    "                    Plot = None, method='nearest', #dx=1.0,\n",
    "                   )\n",
    "        #--- plot\n",
    "        value = utl.PltBinary(\n",
    "                            xlin,ylin,zlin, mu_intrp.tmp,\n",
    "                            box,\n",
    "                            0.0, #--- threshold\n",
    "                            cmap='Greys',\n",
    "                            zscore=False,\n",
    "                            xlabel = 'x', ylabel = 'y',\n",
    "                            labels = True,\n",
    "                            Plot=Plot,\n",
    "                         )\n",
    "\n",
    "        mask = value > 0 #quantile(list(value.flatten()),0.95)\n",
    "        return xlin,ylin,zlin,mask\n",
    "            \n",
    "    @staticmethod\n",
    "    def phaseDensity(df):\n",
    "        return np.sum(np.c_[list(map(lambda x:df.StructureType == x, Defects.StructureType))].T,axis=0)/float(df.shape[0])\n",
    "\n",
    "    @staticmethod\n",
    "    def Strain(lmpData):\n",
    "        keys = list(lmpData.coord_atoms_broken.keys())\n",
    "        keys.sort()\n",
    "        assert len(keys) > 1\n",
    "        \n",
    "        itime0 = keys[ 0 ]\n",
    "        itime  = keys[ 1 ]\n",
    "        box = lp.Box( BoxBounds = lmpData.BoxBounds[itime], \n",
    "                     AddMissing = np.array([0.0,0.0,0.0] ))\n",
    "        box0 = lp.Box( BoxBounds = lmpData.BoxBounds[itime0], \n",
    "                     AddMissing = np.array([0.0,0.0,0.0] ))\n",
    "        #\n",
    "        dl =(box.CellVector[:,2][2] - box0.CellVector[:,2][2])\n",
    "        dl /= (itime-itime0)\n",
    "        #\n",
    "        L0 = box0.CellVector[:,2][2] - itime0 * dl\n",
    "        L = L0 + dl * np.array(keys)\n",
    "        #\n",
    "#        epsilon = (box.CellVector[:,2][2] / box0.CellVector[:,2][2]) - 1.0\n",
    "#        epsilon /= (itime-itime0)\n",
    "#        print('strain=',L0,dl,dl/L0)\n",
    "        return L/L0-1 #epsilon*np.array(keys)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list dir: ['swapped.dump']\n",
      "class Statistics constructor call: inputFiles= ['swapped.dump']\n",
      "calss Defects constructor call\n",
      "dxa analysis ...\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    if not eval(confParser['irradiation']['irradiation']):\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        !rm -r dislocations\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    path = confParser['input files']['path']\n",
    "    print('list dir:',os.listdir(path))\n",
    "    indx = confParser['input files']['fileIndex']\n",
    "    fileName = confParser['input files']['filename'].split()[int(indx)]\n",
    "\n",
    "#--- constructor call\n",
    "    defect = Defects(path = path,\n",
    "                     verbose=True)\n",
    "\n",
    "    output_path = confParser['irradiation']['outputPath']\n",
    "    \n",
    "    #--- replicate simulation cell\n",
    "    defect.CrysPhase(input_file='%s/%s'%(path,fileName),\n",
    "                    output_path=output_path,\n",
    "                    nevery = int(confParser['parameters']['nevery'])\n",
    "                    )\n",
    "\n",
    "    #--- parse dump file\n",
    "#    defect.ParseDump(fp='%s/dislocations/mydislocations/mydislocations.xyz'%\\\n",
    "#                      output_path)\n",
    "\n",
    "    #--- hcp density\n",
    "#    defect.Density(fout='%s/dislocations/structureTypeFraction.txt'%output_path,\n",
    "#                  header='itime ezz other fcc hcp bcc cubicDiamond hexDiamond')\n",
    "\n",
    "#     #--- redo for cna data\n",
    "#     Defects.StructureType = [0.0,1.0,2.0,3.0,4.0]\n",
    "#     defect.ParseDump(fp='%s/dislocations/mydislocations/cna_output.xyz'%output_path)\n",
    "#     defect.Density(fout='%s/dislocations/structureCnaTypeFraction.txt'%output_path,\n",
    "#                   header='itime ezz other fcc hcp bcc ico')\n",
    "    \n",
    "    #--- mydislocations is huge!!!\n",
    "#    os.system('rm -r %s/dislocations/mydislocations'%output_path)\n",
    "\n",
    "\n",
    "    return defect\n",
    "    #--- write binary density matrix\n",
    "#    defect.BinaryMatrix()\n",
    "        \n",
    "defect = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stats:\n",
    "    '''\n",
    "    cluster statistics\n",
    "    '''\n",
    "    def __init__( self, dataFrame,\n",
    "              verbose = False ):\n",
    "        self.df = dataFrame\n",
    "        #--- group atoms within the same cluster\n",
    "        self.groups = dataFrame.groupby(by='Cluster').groups\n",
    "        self.cluster_ids = np.array(list(self.groups.keys()))\n",
    "        self.nb_labels = self.cluster_ids.shape[0]\n",
    "\n",
    "    def CenterOfMass(self):\n",
    "        return np.c_[list(map(lambda x: np.mean(self.df.iloc[self.groups[x]][['x','y','z']],axis=0), self.cluster_ids))]\n",
    "                                 \n",
    "        \n",
    "    def GetSize(self,cut_off = 1):\n",
    "        #--- clusters: label_im\n",
    "        \n",
    "        #--- dataframe with cluster info: id, size, ...\n",
    "        size = np.c_[list(map(lambda x: self.groups[x].shape[0], self.cluster_ids))]\n",
    "                                \n",
    "        types = np.c_[list(map(lambda x: list(set(self.df.iloc[self.groups[x]]['StructureType']))[0], \n",
    "                               self.cluster_ids))]\n",
    "\n",
    "        #--- radius of gyration\n",
    "        self.covarianceMat()\n",
    "        rg = np.mean(self.covar_mat[['xx','yy','zz']],axis=1)**0.5\n",
    "        \n",
    "        #---  direction\n",
    "        self.Orientation()\n",
    "        n_xyz = np.c_[self.orientation[['nx', 'ny', 'nz']]]\n",
    "\n",
    "        \n",
    "        #--- assign\n",
    "        self.stats=pd.DataFrame(np.c_[self.cluster_ids,types,size,rg,n_xyz], \n",
    "                                columns='clusterID clusterType Size rg nx ny nz'.split())\n",
    "            \n",
    "        \n",
    "        #--- exclude replicas\n",
    "#        if eval(parser['dislocation analysis']['periodicImage']):\n",
    "#            self.stats = self.pbc()\n",
    "        \n",
    "        filtr = self.stats.Size > cut_off\n",
    "        self.stats = self.stats[ filtr ]\n",
    "        \n",
    "    def pbc(self):\n",
    "        #--- pick clusters within and/or crossing the main simulation cell\n",
    "        filtr = np.array(list(map(lambda x:Fractal.isClusterInside(x,self.df),self.cluster_ids)))\n",
    "        cluster_ids = self.cluster_ids[filtr]\n",
    "        return utl.FilterDataFrame(self.stats, key='clusterID', val=cluster_ids)\n",
    "\n",
    "        \n",
    "    def GetProbInf(self):\n",
    "#        percCount = self.stats[self.stats['percTrue']==True].shape[0]\n",
    "#        self.pinf0 = 1.0*percCount/self.stats.shape[0]\n",
    "        \n",
    "        self.pinf = (self.stats['percTrue'] * self.stats['size']).sum()/self.stats['size'].sum()\n",
    "#        print(self.pinf0,self.pinf)\n",
    "    #--- p\n",
    "    def GetProb(self):\n",
    "        (ny,nx,nz) = self.mask.shape\n",
    "        nsize = nx*ny*nz\n",
    "        self.p = 1.0*self.mask.sum()/nsize #--- occupation prob.\n",
    "\n",
    "    #--- <s^2>/<s>\n",
    "    def GetSmean(self):\n",
    "        self.smean = (self.stats['size']*self.stats['size']).sum()/self.stats['size'].sum()\n",
    "    #--- correlation length\n",
    "    def GetCrltnLenSq(self):\n",
    "        self.si_sq = 2*(self.stats['rg_sq']*self.stats['size'] * self.stats['size']).sum()/\\\n",
    "                  (self.stats['size'] * self.stats['size']).sum()       \n",
    "\n",
    "    def isPercolating(self,sliceX,sliceY,sliceZ,size):\n",
    "        (ny,nx,nz)=size\n",
    "        #\n",
    "        xlo = sliceX.start\n",
    "        xhi = sliceX.stop\n",
    "        assert xhi - xlo <= nx\n",
    "        #    \n",
    "        ylo = sliceY.start\n",
    "        yhi = sliceY.stop\n",
    "        assert yhi - ylo <= ny\n",
    "        #    \n",
    "        zlo = sliceZ.start\n",
    "        zhi = sliceZ.stop\n",
    "        assert zhi - zlo <= nz\n",
    "        #\n",
    "        return xhi - xlo == nx or yhi - ylo == ny or zhi - zlo == nz\n",
    "\n",
    "    def covarianceMat(self):\n",
    "        '''\n",
    "        returns co-variance matrix corresponding to each cluster\n",
    "        '''\n",
    "        covar_mat = np.c_[list(map(lambda x:self.GetcoVar(x),self.cluster_ids))]\n",
    "        self.covar_mat = pd.DataFrame(np.c_[self.cluster_ids,covar_mat],columns='label xx xy xz yy yz zz'.split())\n",
    "\n",
    "    def GetcoVar(self,cls_label):\n",
    "        filtr = self.df.Cluster == cls_label\n",
    "\n",
    "        count = np.sum(filtr)\n",
    "\n",
    "        xmean = np.mean(self.df[filtr].x)\n",
    "        ymean = np.mean(self.df[filtr].y)\n",
    "        zmean = np.mean(self.df[filtr].z)\n",
    "\n",
    "        varxy = np.sum((self.df[filtr].x - xmean)*(self.df[filtr].y - ymean)) / count\n",
    "        varxz = np.sum((self.df[filtr].x - xmean)*(self.df[filtr].z - zmean)) / count\n",
    "        varyz = np.sum((self.df[filtr].y - ymean)*(self.df[filtr].z - zmean)) / count\n",
    "\n",
    "        varxx = np.var(self.df[filtr].x)\n",
    "        varyy = np.var(self.df[filtr].y)\n",
    "        varzz = np.var(self.df[filtr].z)\n",
    "\n",
    "        return np.array([varxx,varxy,varxz,varyy,varyz,varzz])\n",
    "\n",
    "    def Orientation(self):\n",
    "        '''\n",
    "        returns cluster orientation\n",
    "        '''\n",
    "        ans = np.c_[list(map(lambda x:Stats.Diagonalize(self.covar_mat.iloc[x]),range(self.nb_labels)))]\n",
    "        labels = np.c_[list(map(lambda x:self.covar_mat.iloc[x]['label'],range(self.nb_labels)))] \n",
    "        self.orientation = pd.DataFrame(np.c_[labels,ans],columns='label nx ny nz'.split())\n",
    "\n",
    "    def OrientationDxa(self):\n",
    "        '''\n",
    "        read orientations from dislocation files\n",
    "        '''\n",
    "        ncluster = self.nb_labels - 1 #--- exclude zero\n",
    "        if self.verbose:\n",
    "            print('frame=%s, ncluster=%s'%(frame_number,ncluster))\n",
    "        if ncluster > 0:\n",
    "            orientation = Fractal.ReadDislocationFile('%s/dislocations/mydislocations/mydislocations.%s'%\\\n",
    "                                                      (parser['dislocation analysis']['outputPath'],frame_number),\n",
    "                                                     ncluster,\n",
    "                                                      #verbose=self.verbose\n",
    "                                                     )\n",
    "\n",
    "            orientation_reformatted = np.c_[list(map(lambda x:orientation[x][:,2],self.cluster_ids))]\n",
    "\n",
    "            \n",
    "        \n",
    "    @staticmethod\n",
    "    def Diagonalize(a):\n",
    "        amat = np.array([[a.xx,a.xy,a.xz],[a.xy,a.yy,a.yz],[a.xz,a.yz,a.zz]])\n",
    "        w, v = np.linalg.eigh(amat)\n",
    "        assert w[0] <= w[1] and w[0] <= w[2], 'not sorted!'\n",
    "        return v[:, 0]\n",
    "\n",
    "\n",
    "\n",
    "    def Print(self):\n",
    "        try:\n",
    "            !rm dislocations/ps/clusters.xyz\n",
    "        except:\n",
    "            pass\n",
    "        sfile=open('dislocations/ps/clusters.xyz','a')\n",
    "        cluster_ids = list(self.stats.clusterID)\n",
    "        for clusterID in cluster_ids: #--- loop over cls\n",
    "            filtr = np.all([self.df.Cluster == clusterID, self.df.StructureType == 2],axis=0) #--- hcp clusters\n",
    "            if not np.any(filtr): \n",
    "                continue\n",
    "            cls_props = self.stats[ self.stats.clusterID == clusterID ] #--- props\n",
    "            props = [cls_props['Size'].iloc[0], \n",
    "                     cls_props[['nx','ny','nz']].iloc[0]\n",
    "                    ]\n",
    "            utl.PrintOvito( self.df[filtr], sfile, 'size=%s, n=[%2.1f,%2.1f,%2.1f]'%(props[0],props[1][0],props[1][1],props[1][2]), attr_list=['x','y','z'] )\n",
    "        sfile.close() #'size=%s,n=%s'%(props[0],props[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class Fractal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fractal(Statistics):\n",
    "    '''\n",
    "    multi-fractal analysis of hcp clusters\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,verbose=False):\n",
    "        Statistics.__init__(self,path='.',verbose=verbose)\n",
    "        \n",
    "        self.verbose = verbose\n",
    "\n",
    "    def Parse(self,fp):\n",
    "        self.lmpData = lp.ReadDumpFile('%s'%(fp)) #,verbose=self.verbose)\n",
    "        self.lmpData.GetCords(ncount=sys.maxsize,sort=False)\n",
    "        self.timesteps = np.array(list(self.lmpData.coord_atoms_broken.keys()))\n",
    "        self.timesteps.sort()\n",
    "        \n",
    "        #--- dislocation files\n",
    "        flist=os.listdir('%s/dislocations/mydislocations'%\\\n",
    "                        confParser['irradiation']['outputPath'])\n",
    "        #--- exclude other files\n",
    "        flist.remove('mydislocations.xyz')\n",
    "#        flist.remove('cna_output.xyz')\n",
    "        try:\n",
    "            flist.remove('periodic_image.xyz')\n",
    "            flist.remove('periodic_image_mod.xyz')\n",
    "        except:\n",
    "            pass\n",
    "        #\n",
    "        self.frameNumber = np.array(list(map(lambda x:int(x[x.find('.')+1:]),flist)))\n",
    "        self.frameNumber.sort()\n",
    "\n",
    "#     def SizeDistribution(self,fout):\n",
    "#         '''\n",
    "#         cluster size distribution\n",
    "#         '''\n",
    "        \n",
    "#         #--- analysis of clusters\n",
    "#         data = list(map(lambda x:\n",
    "#                              self.ClusterAnalysis(self.lmpData.coord_atoms_broken[x[0]],\n",
    "#                                                   lp.Box(BoxBounds=self.lmpData.BoxBounds[x[0]],AddMissing=np.array([0,0,0])),\n",
    "#                                                   x[1])['ps'],\n",
    "#                              zip(self.timesteps,self.frameNumber)))\n",
    "#         strains = Defects.Strain(self.lmpData) \n",
    "#         #--- write\n",
    "#         Fractal.PrintMultipleTimeSteps(fout,self.timesteps,data,strains)        \n",
    "\n",
    "        \n",
    "    def SizeDistributionTotal(self,fout):\n",
    "        s = np.concatenate(list(map(lambda x:\n",
    "                                    self.ClusterAnalysis(self.lmpData.coord_atoms_broken[x[0]],\n",
    "                                                         lp.Box(BoxBounds=self.lmpData.BoxBounds[x[0]],AddMissing=np.array([0,0,0])),\n",
    "                                                         x[1])['s'],\n",
    "                                    zip(self.timesteps,self.frameNumber))))\n",
    "        #--- size distribution                    \n",
    "        self.SizeDist(sizes=s,\n",
    "                       fout=fout,\n",
    "                       density=False,\n",
    "                       bins=Statistics.LogBins(eval(parser['cluster analysis']['slo']),\n",
    "                                               eval(parser['cluster analysis']['shi']),\n",
    "                                               nbin_per_decade=6),\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def PrintOvito(sdict,df_xyz,fout):\n",
    "#        print(df_xyz)\n",
    "        sfile=open(fout,'a')\n",
    "        for dislocation_id in sdict['corners']:\n",
    "            #--- center\n",
    "            center_id = sdict['nearestAtom'][dislocation_id]\n",
    "#            xyz_center = sdict['center'][dislocation_id] #\n",
    "            xyz_center = list(df_xyz.iloc[ center_id ]['x y z'.split()])\n",
    "#            pdb.set_trace()\n",
    "            cordc = pd.DataFrame(np.concatenate([[xyz_center],\n",
    "                                                 sdict['corners'][dislocation_id][:,0:3]],axis=0),\n",
    "                                 columns='x y z'.split())\n",
    "            footer='dislocation_id=%s'%dislocation_id\n",
    "            utl.PrintOvito(cordc, sfile, footer, attr_list=['x', 'y', 'z'])\n",
    "        sfile.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def CenterOfMass(slist):\n",
    "        for frameIndex in range(len(slist)):\n",
    "            sdict = slist[ frameIndex ]\n",
    "            sdict['center'] = {}\n",
    "            for dislocation_id in sdict['corners']:\n",
    "                xyz = np.c_[sdict['corners'][dislocation_id][:,0:3]]\n",
    "#                 pdb.set_trace()\n",
    "                sdict['center'][dislocation_id] = np.mean(xyz,axis=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def NearestAtom(slist):\n",
    "        rc = list(map(lambda y:list(np.c_[list(map(lambda x:list(y['center'][x]),y['center']))].flatten()),slist))\n",
    "            #=--- print in json\n",
    "        with open('query.json','w') as fp:\n",
    "            #--- output as json\n",
    "            dictionary={'frameIndex':list(range(len(slist))),'query':rc}\n",
    "            json.dump(dictionary, fp)\n",
    "\n",
    "        path = confParser['input files']['path']\n",
    "        indx = confParser['input files']['fileIndex']\n",
    "        py_path=confParser['py library path']['py_lib']\n",
    "        fileName = '%s/%s'%(path,confParser['input files']['filename'].split()[int(indx)])\n",
    "        nevery = int(confParser['parameters']['nevery'])\n",
    "\n",
    "        #--- print query points\n",
    "        \n",
    "    \n",
    "        !ovitos $py_path/OvitosCna.py $fileName 'nearestAtoms.json' $nevery 10 'query.json'\n",
    "#        print('output neighbor list=%s s'%(time.time()-t0))\n",
    "\n",
    "        with open('nearestAtoms.json','r') as fp:\n",
    "            dataa =json.load(fp)\n",
    "\n",
    "        for frameIndex in range(len(slist)):\n",
    "            nearestAtoms = dataa['nearestAtoms'][frameIndex]\n",
    "            sdict = slist[ frameIndex ]\n",
    "            sdict['nearestAtom'] = {}\n",
    "            for dislocation_id in sdict['corners']:\n",
    "                sdict['nearestAtom'][dislocation_id] = nearestAtoms[dislocation_id][0]\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def NeighborList(xyz, box, atom_indices):\n",
    "#        for dislocation_id in sdict['corners']:\n",
    "        #--- center\n",
    "#        center_ids = sdict['nearestAtom'].values()\n",
    "\n",
    "#        atom_indices = center_ids\n",
    "        np.savetxt('atom_indices.txt',atom_indices,fmt='%d')\n",
    "        #--- create dump.xyz\n",
    "        atomm = lp.Atoms(**xyz.to_dict(orient='series'))\n",
    "        wd = lp.WriteDumpFile(atomm, box)\n",
    "        with open('junk.xyz','w') as outpt: \n",
    "            wd.Write(outpt, itime=0, attrs=['id', 'type', 'x', 'y', 'z'], fmt='%i %i %4.3e %4.3e %4.3e')\n",
    "        #--- call ovito\n",
    "        cutoff = eval(confParser['neigh list']['cutoff'])\n",
    "        py_path=confParser['py library path']['py_lib']\n",
    "        nevery =1\n",
    "        t0=time.time()\n",
    "        !ovitos $py_path/OvitosCna.py junk.xyz\\\n",
    "        neighList.xyz $nevery 4 $cutoff atom_indices.txt\n",
    "        print('output neighbor list=%s s'%(time.time()-t0))\n",
    "        #--- parse\n",
    "        lmpNeigh = lp.ReadDumpFile( 'neighList.xyz' )\n",
    "        lmpNeigh.GetCords( ncount = sys.maxsize)\n",
    "        print('load neighbor list=%s s'%(time.time()-t0))\n",
    "#        display(lmpNeigh.coord_atoms_broken[0].head())\n",
    "        \n",
    "        #--- clean\n",
    "        !rm junk.xyz neighList.xyz\n",
    "        \n",
    "        return lmpNeigh.coord_atoms_broken[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def PrintNeighbors(atom_indices,lmpNeigh,xyz):\n",
    "        #--- get coordinates\n",
    "        atom_id      = xyz.iloc[atom_indices].id\n",
    "        filtr        = lmpNeigh.coord_atoms_broken[0].id==atom_id\n",
    "        ids          = lmpNeigh.coord_atoms_broken[0][filtr].J\n",
    "        cordc        = utl.FilterDataFrame(xyz, key='id', val=ids)        \n",
    "        #--- print\n",
    "        with open('neighh.xyz','w') as sfile:\n",
    "            utl.PrintOvito(cordc, sfile, 'junk', attr_list=['x', 'y', 'z'])\n",
    "            \n",
    "    @staticmethod    \n",
    "    def Sro(xyz, box, neighList, pairi,pairj,**kwargs):\n",
    "        atoms = lp.Atoms( **xyz.to_dict(orient='series') )\n",
    "        rdf = lp.ComputeRdf(  atoms, box )\n",
    "        bins = np.arange(0.99*neighList.DIST.min(),1.01*neighList.DIST.max(),0.1) if 'bins' not in kwargs else kwargs['bins']\n",
    "        rdf.PairCrltn(  \n",
    "                      bins=bins, \n",
    "                      rlist=neighList.DIST )\n",
    "        return rdf.Sro(neighList,pairi,pairj,bins=bins)\n",
    "\n",
    "    \n",
    "    @staticmethod   \n",
    "    def Print( slist, timesteps, fout ):\n",
    "        keys = [ 'bin_edges', 'value', 'error' ]\n",
    "        with open(fout,'w') as fp:\n",
    "            for tmp, timestep in zip(slist,timesteps):\n",
    "        \n",
    "        #--- make a dictionary\n",
    "                sdict = dict( zip( keys, tmp ) )\n",
    "                sdict['time'] = np.array([timestep])\n",
    "                json.dump( sdict, fp, cls=NumpyArrayEncoder )\n",
    "                fp.write('\\n')\n",
    "\n",
    "            \n",
    "    def Clusters(self,fout):\n",
    "        \n",
    "        !mkdir -p $fout\n",
    "        \n",
    "        dislocationSegments=\\\n",
    "        list(map(lambda x: Fractal.ReadDislocationFile('%s/dislocations/mydislocations/mydislocations.%s'%\\\n",
    "                      (confParser['irradiation']['outputPath'],x),verbose=False,\n",
    "                                                      ),self.frameNumber\n",
    "                )\n",
    "            )\n",
    "                             \n",
    "        #--- center of segments\n",
    "        Fractal.CenterOfMass(dislocationSegments)\n",
    "            \n",
    "        #--- nearest atom\n",
    "        Fractal.NearestAtom(dislocationSegments)\n",
    "    \n",
    "    \n",
    "        #--- plot defects\n",
    "#        Fractal.PrintOvito(dislocationSegments[0],\n",
    "#                           self.lmpData.coord_atoms_broken[0],\n",
    "#                          'cords.xyz')\n",
    "\n",
    "        #--- neighbor list\n",
    "#        pdb.set_trace()\n",
    "        lmpNeigh = list(map(lambda x:Fractal.NeighborList(xyz = self.lmpData.coord_atoms_broken[x[0]],\n",
    "                             box = lp.Box( BoxBounds = self.lmpData.BoxBounds[x[0]], AddMissing = np.array([0.0,0.0,0.0] )),\n",
    "                             atom_indices = list(dislocationSegments[x[1]]['nearestAtom'].values())\n",
    "                            ),zip(self.timesteps,self.frameNumber)))\n",
    "        \n",
    "        #--- print neighbors\n",
    "#         Fractal.PrintNeighbors(list(dislocationSegments[0]['nearestAtom'].values())[0],\n",
    "#                        lmpNeigh,\n",
    "#                        self.lmpData.coord_atoms_broken[0]\n",
    "#                       )\n",
    "\n",
    "\n",
    "        #--- mean sro (averaged over defects)\n",
    "        for pairi in [1,2,3]:\n",
    "            for pairj in range(pairi,4):\n",
    "#                print(pairi,pairj)\n",
    "                sro = list(map(lambda x:Fractal.Sro(xyz = self.lmpData.coord_atoms_broken[x[0]], \n",
    "                            box = lp.Box( BoxBounds = self.lmpData.BoxBounds[x[0]], AddMissing = np.array([0.0,0.0,0.0] )),\n",
    "                            neighList = lmpNeigh[x[1]],\n",
    "                            pairi=1,pairj=1,\n",
    "                            bins = np.arange(2.0,1.01*eval(confParser['neigh list']['cutoff']),0.1)\n",
    "                                                   ),zip(self.timesteps,self.frameNumber)\n",
    "                              )\n",
    "                          )\n",
    "\n",
    "                #--- print\n",
    "                Fractal.Print( sro, self.timesteps, '%s/wc_pairi_%s_pairj_%s.txt' %(fout,pairi,pairj) )\n",
    "#        pdb.set_trace()\n",
    "#         cls_size = np.concatenate(list(map(lambda x:\n",
    "#                                     self.ClusterAnalysis(self.lmpData.coord_atoms_broken[x[0]],\n",
    "#                                                          lp.Box(BoxBounds=self.lmpData.BoxBounds[x[0]],AddMissing=np.array([0,0,0])),\n",
    "#                                                          x[1])['s'],\n",
    "#                                     zip(self.timesteps,self.frameNumber))))\n",
    "\n",
    "        \n",
    "#         s = np.concatenate(list(map(lambda x:\n",
    "#                                     self.ClusterAnalysis(self.lmpData.coord_atoms_broken[x[0]],\n",
    "#                                                          lp.Box(BoxBounds=self.lmpData.BoxBounds[x[0]],AddMissing=np.array([0,0,0])),\n",
    "#                                                          x[1])['angle'],\n",
    "#                                     zip(self.timesteps,self.frameNumber))))\n",
    "#         theta = list(map(lambda x:x.real,s))\n",
    "#         phi   = list(map(lambda x:x.imag,s))\n",
    "#         with open(fout,'w') as fp:\n",
    "#             np.savetxt(fp,np.c_[theta, phi, np.concatenate([cls_size,cls_size])],header='theta phi size')\n",
    "\n",
    "    def FractalDimension(self,fout):\n",
    "        s = np.concatenate(list(map(lambda x:\n",
    "                                    self.ClusterAnalysis(self.lmpData.coord_atoms_broken[x[0]],\n",
    "                                                         lp.Box(BoxBounds=self.lmpData.BoxBounds[x[0]],AddMissing=np.array([0,0,0])),\n",
    "                                                         x[1])['s'],\n",
    "                                    zip(self.timesteps,self.frameNumber))))\n",
    "        rg = np.concatenate(list(map(lambda x:\n",
    "                                    self.ClusterAnalysis(self.lmpData.coord_atoms_broken[x[0]],\n",
    "                                                         lp.Box(BoxBounds=self.lmpData.BoxBounds[x[0]],AddMissing=np.array([0,0,0])),\n",
    "                                                         x[1])['rg'],\n",
    "                                    zip(self.timesteps,self.frameNumber))))\n",
    "        with open(fout,'w') as fp:\n",
    "            np.savetxt(fp,np.c_[rg, s],header='rg size')\n",
    "\n",
    "    def Plot(self,mask,xlin,ylin,zlin):\n",
    "        #--- print in ovito\n",
    "        xv,yv,zv=np.meshgrid(xlin,ylin,zlin)\n",
    "        mask_tmp=mask.copy()\n",
    "        mask_tmp[:,:,:]=0\n",
    "        for idd in list(self.stats.stats['cls_id']): \n",
    "            filtr = self.stats.label_im == int(idd)\n",
    "            mask_tmp[filtr]=int(idd)        \n",
    "        cordc = pd.DataFrame(np.c_[xv.flatten(),yv.flatten(),zv.flatten(),mask_tmp.flatten()],columns='x y z mass'.split())\n",
    "        sfile=open('dislocations/map.xyz','w')\n",
    "        utl.PrintOvito( cordc, sfile, 'atoms', attr_list=['x','y','z','mass'] )\n",
    "\n",
    "    def GetAccumulatedSize(self,stats,fout):\n",
    "        '''\n",
    "        returns scatter data of stress drop and cluster size\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        \n",
    "        #--- total size per frame\n",
    "        sum_size = list(map(lambda x:\n",
    "                    self.ClusterAnalysis(self.lmpData.coord_atoms_broken[x[0]],\n",
    "                                        lp.Box(BoxBounds=self.lmpData.BoxBounds[x[0]],AddMissing=np.array([0,0,0])),\n",
    "                                         x[1])['sum_size'],\n",
    "                    zip(self.timesteps,self.frameNumber)))\n",
    "        \n",
    "        #--- energy\n",
    "        timesteps = stats.loadTimeSeries.step\n",
    "        #--- assert frames analyzed by dxa are present within the stress timeseries\n",
    "        new_timesteps = list(map(lambda x:timesteps[timesteps>=x].iloc[0],self.timesteps[:-1]))\n",
    "        new_timesteps += [timesteps.iloc[-1]]\n",
    "        EnergyDrop = utl.FilterDataFrame(stats.loadTimeSeries, key='step', val=new_timesteps)['pe']\n",
    "\n",
    "        #--- write\n",
    "        with open(fout,'w') as fp:\n",
    "            np.savetxt(fp,np.c_[sum_size,EnergyDrop],header='clusterSize EnergyDrop')\n",
    "\n",
    "\n",
    "        \n",
    "    @staticmethod\n",
    "    def isClusterInside(cls_id,df):\n",
    "        filtr = df.Cluster == cls_id\n",
    "        return np.any(df[filtr].isinside)\n",
    "    \n",
    "    def ClusterAnalysis(self,dataFrame,\n",
    "                        box,\n",
    "                        frame_number):\n",
    "        '''\n",
    "        returns fractal dimension df\n",
    "        '''\n",
    "        statistics = Stats(dataFrame)\n",
    "        statistics.GetSize(cut_off = 1)\n",
    "#        statistics.Print()\n",
    "\n",
    "        #--- store in a dictionary and return\n",
    "        sizeDist=[]\n",
    "        s = []\n",
    "        angle = []\n",
    "        sum_size = 0\n",
    "        rg = []\n",
    "        if statistics.nb_labels > 0:\n",
    "            #--- assign outputs\n",
    "            filtr = statistics.stats.clusterType == 2 #--- hcp\n",
    "            if np.sum(filtr) != 0:\n",
    "                #--- angles\n",
    "                angle = list(map(lambda x:Fractal.GetPolarAzimuthalAngles(x), \n",
    "                                        np.c_[statistics.stats[filtr][['nx','ny','nz']]]))+\\\n",
    "                        list(map(lambda x:Fractal.GetPolarAzimuthalAngles(x), \n",
    "                                                -np.c_[statistics.stats[filtr][['nx','ny','nz']]]))\n",
    "                #--- size\n",
    "                s = statistics.stats[filtr].Size\n",
    "                sum_size = s.sum()\n",
    "                sizeDist = np.c_[utl.GetPDF(s, n_per_decade=6, linscale=None )] #--- size distribution\n",
    "                \n",
    "                #--- rg\n",
    "                rg = statistics.stats[filtr].rg\n",
    "        return {'ps':sizeDist,'s':s,'angle':angle,'sum_size':sum_size, 'rg':rg}\n",
    "\n",
    "\n",
    "    def Filtr(self,**kwargs):\n",
    "        '''\n",
    "        filter dataset based on timesteps, strains ...\n",
    "        '''\n",
    "        n=len(self.data)\n",
    "        filtr = np.ones(n,dtype=bool)\n",
    "        if 'strain_lo' in kwargs:\n",
    "            strains = self.GetStrain()\n",
    "            filtr_strain_lo = np.array(strains) >= kwargs['strain_lo']\n",
    "            filtr = np.all([filtr,filtr_strain_lo],axis=0)\n",
    "        if 'strain_hi' in kwargs:\n",
    "            strains = self.GetStrain()\n",
    "            filtr_strain_hi = np.array(strains) <= kwargs['strain_hi']\n",
    "            filtr = np.all([filtr,filtr_strain_hi],axis=0)\n",
    "        if 'timestep_lo' in kwargs:\n",
    "            times = self.GetTimeStep()\n",
    "            filtr_time_lo = np.array(times) >= kwargs['timestep_lo']\n",
    "            filtr = np.all([filtr,filtr_time_lo],axis=0)\n",
    "        if 'timestep_hi' in kwargs:\n",
    "            times = self.GetTimeStep()\n",
    "            filtr_time_hi = np.array(times) <= kwargs['timestep_hi']\n",
    "            filtr = np.all([filtr,filtr_time_hi],axis=0)\n",
    "        return filtr\n",
    "\n",
    "    def Integrate(self,filtr0):\n",
    "        return np.nan if not np.all(filtr0) else\\\n",
    "        np.sum(list(map(lambda x:self.ClusterAnalysis(x)['sum_size'],np.array(self.data)[filtr0])))\n",
    "        \n",
    "    def GetStrain(self):\n",
    "        return list(map(lambda x:x['strain'],self.data))\n",
    "\n",
    "    def GetTimeStep(self):\n",
    "        return list(map(lambda x:x['timestep'],self.data))\n",
    "\n",
    "    @staticmethod\n",
    "    def GetPolarAzimuthalAngles(r):\n",
    "        ez=np.array([0,0,1])\n",
    "        ex=np.array([1,0,0])\n",
    "        rz=np.dot(r,ez)*ez\n",
    "        rp=r-rz\n",
    "        rzz=np.dot(r,ez)/np.dot(r,r)**0.5\n",
    "        polar_angle = 180.0*np.arccos(rzz)/np.pi\n",
    "        azimuth_angle = 180.0*np.arctan2(rp[1],rp[0])/np.pi\n",
    "        return azimuth_angle + polar_angle *1j\n",
    "\n",
    "    @staticmethod\n",
    "    def Reshape(d):\n",
    "        nx = len(d['x'])\n",
    "        ny = len(d['y'])\n",
    "        nz = len(d['z'])\n",
    "        val = np.array(d['val']).reshape(ny,nx,nz)\n",
    "        return d['x'], d['y'], d['z'], val\n",
    "    \n",
    "    @staticmethod\n",
    "    def Get_Df(data_frame):\n",
    "        #--- fit\n",
    "\n",
    "        xdata = data_frame['rg_sq']**0.5\n",
    "        ydata = data_frame['size']\n",
    "        filtr = xdata > 0\n",
    "        popt, pcov = curve_fit(Fractal.func, xdata[filtr], ydata[filtr],\n",
    "                               bounds=((0,0),(np.inf,3))\n",
    "                              )\n",
    "        popt = np.polyfit(np.log10(xdata[filtr]), np.log10(ydata[filtr]),\n",
    "                               1\n",
    "                              )\n",
    "        return popt[0]\n",
    "    \n",
    "    @staticmethod\n",
    "    def func(x, a, b):\n",
    "        return b * x ** a\n",
    "    \n",
    "    @staticmethod\n",
    "    def Sort(x,y):\n",
    "        slist = list(zip(y, x))\n",
    "        slist.sort()\n",
    "        return np.array(slist)[:,1]\n",
    "    \n",
    "    @staticmethod\n",
    "    def PrintMultipleTimeSteps(fout,times,data, strain):\n",
    "        \n",
    "        for item0, item1, item2, indx in zip(times,data, strain, range(len(times))): \n",
    "#            print('strain=',item1)\n",
    "            if len(item1) == 0:\n",
    "                continue\n",
    "            with open('%s%s.json'%(fout,indx),'w') as fp:\n",
    "                #--- output as json\n",
    "                dictionary={'hist':list(item1[:,0]),'bin_edges':list(item1[:,1]),'error':list(item1[:,2]),\n",
    "                            'strain':item2,'timestep':item0}\n",
    "                json.dump(dictionary, fp)\n",
    "\n",
    "    @staticmethod\n",
    "    def ReadDislocationFile(myfile,verbose=False):\n",
    "        #--- read file\n",
    "#        pdb.set_trace()\n",
    "        strr=open(myfile).readlines() #--- read as string\n",
    "#        li = strr.index('CLUSTERS %s\\n'%ncluster) #--- 1st line to be read\n",
    "        li = 0\n",
    "        while strr[li][0:12] != 'DISLOCATIONS':\n",
    "            li +=1\n",
    "        if verbose:\n",
    "            print('read line %s '%li)\n",
    "            \n",
    "        ndislocations = int(strr[li].split()[1])\n",
    "        if verbose:\n",
    "            print('ndislocations= %s '%ndislocations)\n",
    "\n",
    "        li += 1\n",
    "\n",
    "        burgers = {}\n",
    "        corners = {}\n",
    "        crystalType = {}\n",
    "        for ii in range(ndislocations): #--- two dislocations\n",
    "            cluster_id = int(strr[li])\n",
    "            if verbose:\n",
    "                print('cluster_id=',cluster_id)\n",
    "            #\n",
    "            li += 1\n",
    "            #\n",
    "            burgers[cluster_id] = list(map(float,strr[li].split()))\n",
    "            if verbose:\n",
    "                print('burgers=',burgers[cluster_id])\n",
    "            #\n",
    "            li+=1\n",
    "            crystalType[cluster_id] = int(strr[li])\n",
    "            #\n",
    "            li+=1\n",
    "            nseg = int(strr[li])\n",
    "            li+=1\n",
    "#            pdb.set_trace()\n",
    "            corners[cluster_id] = np.c_[[list(map(float,strr[li+iseg].split())) for iseg in range(nseg)]]\n",
    "            li+=nseg\n",
    "        \n",
    "#        print(corners[cluster_id])\n",
    "        return {'burgers':burgers,'corners':corners,'crystalType':crystalType}\n",
    "                \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached end of file!\n",
      "AnalysisType= 10\n",
      "InputFile= ../lammpsRuns/nicocrNatom100KMultipleTempIrradiatedAnneal/dpa2/temp0/Run0/swapped.dump\n",
      "num_frames= 2\n",
      "frame=0\n",
      "frame=1\n",
      "AnalysisType= 4\n",
      "InputFile= junk.xyz\n",
      "num_frames= 1\n",
      "frame=0\n",
      "output neighbor list=2.0676968097686768 s\n",
      "reached end of file!\n",
      "load neighbor list=2.1204888820648193 s\n",
      "AnalysisType= 4\n",
      "InputFile= junk.xyz\n",
      "num_frames= 1\n",
      "frame=0\n",
      "output neighbor list=1.676743984222412 s\n",
      "reached end of file!\n",
      "load neighbor list=1.6989130973815918 s\n"
     ]
    }
   ],
   "source": [
    "def main():#stats):\n",
    "    if not eval(confParser['irradiation']['irradiation']):\n",
    "        return\n",
    "    \n",
    "    os.system('mkdir -p %s/dislocations/ps'%confParser['irradiation']['outputPath'])\n",
    "\n",
    "    #--- constructor call\n",
    "    fractal = Fractal(#verbose=True\n",
    "                     )\n",
    "    \n",
    "    #--- parse data\n",
    "    fractal.Parse('%s/dislocations/mydislocations/mydislocations.xyz'%\\\n",
    "                  confParser['irradiation']['outputPath'])\n",
    "\n",
    "    \n",
    "    #--- size distributions\n",
    "#    fractal.SizeDistribution(fout='./dislocations/ps/clusterSizePdf') #--- each timestep\n",
    "#    fractal.SizeDistributionTotal(fout='%s/dislocations/ps/clusterSizePdfTotal.txt'%\\\n",
    "#                                  parser['dislocation analysis']['outputPath']) #--- total\n",
    "    \n",
    "    #--- orientation\n",
    "    fractal.Clusters(\n",
    "                               fout='%s/dislocations/sro'%\\\n",
    "                               confParser['irradiation']['outputPath'])\n",
    "    \n",
    "    #--- fractal dimension\n",
    "#    fractal.FractalDimension(fout='%s/dislocations/ps/scatterRgSize.txt'%\\\n",
    "#                               parser['dislocation analysis']['outputPath'])\n",
    "    #-----------------------------------------\n",
    "    #--- cluster size vs. energy drops:\n",
    "    #--- please do the dislocation analysis \n",
    "    #--- with high frequency (i.e. nevery=2)\n",
    "    #-----------------------------------------\n",
    "#    fractal.GetAccumulatedSize(stats, \n",
    "#                               fout='%s/dislocations/ps/clusterSizeEnergyDrop.txt'%\\\n",
    "#                               parser['dislocation analysis']['outputPath'])\n",
    "    \n",
    "    #--- mydislocations is huge!!!\n",
    "#    os.system('rm -r %s/dislocations/mydislocations'%parser['dislocation analysis']['outputPath'])\n",
    "\n",
    "main() #stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot\n",
    "### Class Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Temperature:\n",
    "    \n",
    "    def __init__(self,temp_range,nrun,verbose=False):\n",
    "        self.temps =  temp_range\n",
    "        self.nrun = nrun\n",
    "        self.verbose = verbose\n",
    "#         pdb.set_trace()\n",
    "#        self.temps_runs = np.concatenate(list(map(lambda x:self.BuildTempRealizationPair([x[0]],np.arange(x[1])),\n",
    "#            zip(self.temps,self.nrun))))\n",
    "\n",
    "        self.temps_runs = np.concatenate(list(map(lambda x:self.BuildTempRealizationPair([x[0]],x[1]),\n",
    "             zip(self.temps,self.nrun))))\n",
    "        \n",
    "    \n",
    "    def BuildTempRealizationPair(self,temps,nrun):\n",
    "        t,r=np.meshgrid(temps,nrun,indexing='ij')\n",
    "        return np.array(list(zip(t.flatten(),r.flatten())))\n",
    "        \n",
    "    def ModifyNrun(self,fp,dirs):\n",
    "        #--- modify dirs\n",
    "        count = -1\n",
    "        dirs_copy = dirs[:]\n",
    "        for _, indx in zip(self.temps,range(len(self.temps))):\n",
    "            nrun_mod = self.nrun[indx][:]\n",
    "            for y in self.nrun[indx]:\n",
    "                count += 1\n",
    "                x = '%s/%s'%(dirs[count],fp)\n",
    "                if not os.path.isfile(x): #--- if false: remove file from \"dirs\"\n",
    "                    dirs_copy.remove(x)\n",
    "                    nrun_mod.remove(y)\n",
    "            self.nrun[indx] = nrun_mod[:]\n",
    "\n",
    "            assert len(self.nrun[indx]) > 0, 'temp = %s has no data!'%(self.temps[indx])\n",
    "                \n",
    "        self.temps_runs = np.concatenate(list(map(lambda x:self.BuildTempRealizationPair([x[0]],x[1]),\n",
    "             zip(self.temps,self.nrun))))\n",
    "        return dirs_copy\n",
    "        \n",
    "    def Parse(self,fp,dirs):\n",
    "            \n",
    "        dirs = self.ModifyNrun(fp,dirs)\n",
    "#         print('dirs:',dirs)\n",
    "        self.data=list(map(lambda x:np.loadtxt('%s/%s'%(x,fp),ndmin=2),dirs))\n",
    "        if self.verbose:\n",
    "            n = np.array(self.nrun).flatten()\n",
    "            list(map(lambda x:print('Parsing: %s data.shape is: %s'%(x[1],x[0].shape)),zip(self.data,n)))\n",
    "#        print('np.array(self.data):',np.array(self.data))\n",
    "\n",
    "        \n",
    "    def PlotScatter(self,shift = False, shift_factor=10,  \n",
    "                    rescale=False,alpha=1.0,\n",
    "                    mylegends='',\n",
    "                    powerlaw=False, prefact=1.0,\n",
    "                    markersizes=np.array([10,10,10,12,12,12,10])*8,\n",
    "                    transparency=0.1,\n",
    "                    addPoints = [],\n",
    "                    colorIndex = [],\n",
    "                    col_x=0,col_y=1,\n",
    "                    **kwargs):\n",
    "        self.ax = utl.PltErr(None,\n",
    "                        None,\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "\n",
    "        symbols=Symbols(markersizes=markersizes)\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs\n",
    "                    else (1.0,0.5,0.5,0.5)\n",
    "                   )\n",
    "        kounts = colorIndex if colorIndex else range(len(self.temps)) \n",
    "        for temp, count in zip(self.temps,kounts): \n",
    "            text = mylegends[count] if not mylegends == '' else ' '\n",
    "            #\n",
    "            data = self.data_reduced[temp]            \n",
    "            xdata = data[:,col_x]\n",
    "            ydata = data[:,col_y]\n",
    "            \n",
    "            if powerlaw and count == 0:\n",
    "                Xdata = xdata.copy()\n",
    "\n",
    "            if rescale:\n",
    "                ydata *= xdata ** alpha \n",
    "\n",
    "            ydata = ydata*shift_factor**count if shift else ydata\n",
    "\n",
    "            self.ax.scatter(xdata,ydata,\n",
    "                        **symbols.GetAttrsScatter(count=count%7,label='%s'%text,fmt='.',alpha=transparency),\n",
    "                       )\n",
    "        #--- add points\n",
    "        for points in addPoints:\n",
    "            utl.PltErr([points[0]],\n",
    "                       [points[1]],\n",
    "                       attrs={'fmt':'.','ms':10,'color':'red'},\n",
    "                       ax=self.ax,\n",
    "                       Plot=False,\n",
    "                      )\n",
    "            \n",
    "        #\n",
    "        attrs = {} if mylegends == '' else {'legend':legends.Get()}\n",
    "        if powerlaw:\n",
    "            Xdata.sort()\n",
    "        utl.PltErr(Xdata if powerlaw else None,\n",
    "                   prefact/Xdata**alpha if powerlaw else None,\n",
    "                   ax=self.ax,\n",
    "                   Plot=False,\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **attrs,\n",
    "                   **kwargs\n",
    "                  )\n",
    "    def PlotPdf(self,shift = False, shift_factor=10,\n",
    "                rescale=False,alpha=1.0,\n",
    "                powerlaw=False, prefact=1.0,\n",
    "                mylegends='', \n",
    "                **kwargs):\n",
    "        self.ax = utl.PltErr(None,\n",
    "                        None,\n",
    "                        attrs={'fmt':'-.r'},Plot=False)\n",
    "\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=kwargs['bbox_to_anchor'] if 'bbox_to_anchor' in kwargs\n",
    "                    else (1.0,0.5,0.5,0.5),\n",
    "                    labelspacing=kwargs['labelspacing'] if 'labelspacing' in kwargs\n",
    "                    else 0.0\n",
    "                   )\n",
    "        for temp, count in zip(self.temps,range(len(self.temps))): \n",
    "            text = mylegends[count] if not mylegends == '' else ' '\n",
    "            #\n",
    "            data = self.data_averaged[temp]\n",
    "            xdata = data[ :,0 ]\n",
    "            ydata = data[ :,1 ]\n",
    "            yerr  = data[:,2]\n",
    "            #\n",
    "            if powerlaw and count == 0:\n",
    "                Xdata = xdata.copy()\n",
    "            if rescale:\n",
    "                ydata *= xdata ** alpha \n",
    "                yerr *= xdata ** alpha \n",
    "                \n",
    "            ydata = ydata * shift_factor**count if shift else ydata\n",
    "            yerr  = yerr  * shift_factor**count if shift else yerr\n",
    "\n",
    "            try:\n",
    "                utl.PltErr(xdata,ydata,\n",
    "                        yerr=yerr,\n",
    "                       ax = self.ax,\n",
    "                       attrs=symbols.GetAttrs(count=count%7,label=r'$%s$'%text,**kwargs),\n",
    "                       Plot=False,\n",
    "                   \n",
    "                      )\n",
    "            except:\n",
    "                continue\n",
    "        #\n",
    "        attrs = {} if mylegends == '' else {'legend':legends.Get()}\n",
    "        attrs2 = {} if 'DrawFrame' in kwargs else {'DrawFrame':DRAW_FRAME}\n",
    "        utl.PltErr(Xdata if powerlaw else None,\n",
    "                   prefact/Xdata**alpha if powerlaw else None,\n",
    "                   ax=self.ax,\n",
    "                   Plot=False,\n",
    "                   #DrawFrame=DRAW_FRAME,\n",
    "                   **attrs2,\n",
    "                   **attrs,\n",
    "                   **kwargs\n",
    "                  )\n",
    "    def Concatenate(self):\n",
    "        '''\n",
    "        Concatenate scatter data corresponding to different realizations  \n",
    "        '''\n",
    "        kount = 0\n",
    "        self.data_reduced = {} \n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            #--- concat. data for each temp\n",
    "            nruns = len(self.nrun[indx])\n",
    "            data = self.data[kount:kount+nruns]\n",
    "            filtr = list(map(lambda x:x.shape[0] > 0,data)) #--- filter empty arrays\n",
    "            self.data_reduced[temp] = np.concatenate(np.array(data)[filtr]) #,axis=0)\n",
    "            if self.verbose:\n",
    "                print('temp:%s, data.shape:%s'%(temp,self.data_reduced[temp].shape)) \n",
    "            kount += nruns\n",
    "\n",
    "    def Transform(self,**kwargs):\n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            #--- concat. data for each temp\n",
    "            if 'multBy' in kwargs:\n",
    "                if 'col' in kwargs:\n",
    "                    if 'temp' in kwargs and temp != kwargs['temp']:\n",
    "                        continue\n",
    "                    self.data_reduced[temp][:,kwargs['col']] *=  kwargs['multBy']\n",
    "\n",
    "            if 'zscore' in kwargs and kwargs['zscore']:\n",
    "                if 'col' in kwargs:\n",
    "                    if 'temp' in kwargs and temp != kwargs['temp']:\n",
    "                        continue\n",
    "                    data = self.data_reduced[temp][:,kwargs['col']]\n",
    "                    data -= np.mean(data)\n",
    "                    data /= np.std(data)\n",
    "                    self.data_reduced[temp][:,kwargs['col']] = data\n",
    "                    \n",
    "    def EnsAverage(self):\n",
    "        kount = 0\n",
    "        self.data_averaged = {} \n",
    "        for temp, indx in zip(self.temps,range(len(self.temps))):\n",
    "            #--- concat. data for each temp\n",
    "            nruns = len(self.nrun[indx])\n",
    "            data = self.data[kount:kount+nruns]\n",
    "            if self.verbose:\n",
    "                print('data.shape:',np.array(data).shape) \n",
    "#            filtr = list(map(lambda x:x.shape[0] > 0,data)) #--- filter empty arrays\n",
    "#            data = np.concatenate(np.array(data)[filtr]) #,axis=0)\n",
    "            self.data_averaged[ temp ] = ftl.reduce(Temperature.myadd,data) / nruns\n",
    "        \n",
    "#            self.data_averaged[ temp ] = self.hist(data_reduced,nruns) #self.nrun[indx])\n",
    "            kount += nruns #self.nrun[indx]\n",
    "\n",
    "    def hist(self,data,nrun):\n",
    "        count, edge_left, edge_right, _ = data.T\n",
    "        \n",
    "        edge_left /= nrun\n",
    "        edge_right /= nrun\n",
    "        \n",
    "        ntot = np.sum(count)\n",
    "        \n",
    "        edges = np.sqrt( edge_left * edge_right )\n",
    "        \n",
    "        hist = count / ntot / (edge_right-edge_left)\n",
    "#        print(np.sum(hist*(edge_right-edge_left)))\n",
    "\n",
    "        err = hist / count ** 0.5\n",
    "        \n",
    "        filtr = count > 1\n",
    "        \n",
    "        return np.c_[hist[filtr], edges[filtr], err[filtr]]\n",
    "                    \n",
    "\n",
    "\n",
    "    def func2nd(self,x,k,x0,xc,beta,alpha):\n",
    "        return k*np.exp(-(x/xc)**beta)/(1+(x/x0)**alpha)\n",
    "\n",
    "    def func(self,x,k,xc,beta,alpha):\n",
    "        return k*np.exp(-(x/xc)**beta)/(x)**alpha\n",
    "\n",
    "    def Fit(self,Plot=None,\n",
    "            shift = False,\n",
    "            plotAttrs={},\n",
    "            bounds=(-np.inf, np.inf),\n",
    "            xlo=float('-inf'),xhi=float('inf'),\n",
    "            mylegends='',\n",
    "            **kwargs):\n",
    "        self.exponent = {}\n",
    "        pref=1e-10*1e-10 #--- ang^2 to m^2\n",
    "        symbols=utl.Symbols()\n",
    "        legends = Legends()\n",
    "        legends.Set(bbox_to_anchor=plotAttrs['bbox_to_anchor'] if 'bbox_to_anchor' in plotAttrs\n",
    "                    else (1.0,0.5,0.5,0.5))\n",
    "\n",
    "        if Plot:\n",
    "            ax = utl.PltErr(None,None,\n",
    "                            Plot=False)\n",
    "        #\n",
    "        for temp, count in zip(self.temps,range(len(self.temps))): \n",
    "            self.smat = smat = self.data_averaged[ temp ] #if len(self.nrun) > 1 else self.data[count]\n",
    "\n",
    "            xdata = smat[ :,1 ]\n",
    "            ydata = smat[ :,0 ]\n",
    "            yerr  = smat[:,2]\n",
    "\n",
    "        \n",
    "            #--- set limits:\n",
    "            if self.verbose:\n",
    "                print('limits:',xlo,xhi)\n",
    "\n",
    "            filtr = np.ones(xdata.shape[0],dtype=bool)\n",
    "            filtr = np.all([filtr,xdata > xlo],axis=0)\n",
    "            filtr = np.all([filtr,xdata <= xhi],axis=0)\n",
    "            assert np.any(filtr), 'empty arrays!'\n",
    "            if self.verbose:\n",
    "                print('filtr=',filtr)\n",
    "            \n",
    "            #--- error in y\n",
    "            if 'sigma' in kwargs:\n",
    "                kwargs['sigma'] = 2*yerr[filtr]\n",
    "\n",
    "            #--- fit\n",
    "#             print(kwargs)\n",
    "            popt, pcov = curve_fit(self.func, xdata[filtr], ydata[filtr],\n",
    "                                   bounds=bounds, \n",
    "                                    **kwargs\n",
    "                                    )\n",
    "            self.popt = popt\n",
    "            self.filtr = filtr\n",
    "            #--- uncertainties\n",
    "            if self.verbose:\n",
    "                print('Temp=%s,y0,c0,alpha'%temp,list(popt),pcov)\n",
    "            alpha=popt[-1]\n",
    "            err_alpha = pcov[-1,-1]**0.5\n",
    "            self.exponent[temp] = [alpha,alpha+err_alpha,alpha-err_alpha]\n",
    "            if Plot:\n",
    "                text = mylegends[count] if not mylegends == '' else ' '\n",
    "                #---fit\n",
    "                shift_factor = 100**count if shift else 1\n",
    "                utl.PltErr(xdata,\n",
    "                                (self.func(xdata,*popt))*shift_factor,#-y0)/xdata_shift,\n",
    "                                attrs={'fmt':'-.','color':symbols.colors[count%7]},\n",
    "                           Plot=False,ax=ax)\n",
    "                #--- points\n",
    "#                temp= [1000,1200,1400,1600,1800,2000][count]\n",
    "                utl.PltErr(xdata,\n",
    "                           ydata*shift_factor,#-y0)/xdata_shift,\n",
    "                           yerr=yerr*shift_factor,#-y0),#/xdata_shift,\n",
    "                           attrs=symbols.GetAttrs(count=count%7,label=r'$%s$'%text,fmt='.',**plotAttrs),\n",
    "                           ax=ax,\n",
    "                           Plot=False,\n",
    "                          )\n",
    "        if Plot:\n",
    "            attrs = {} if mylegends == '' else {'legend':legends.Get()}\n",
    "            utl.PltErr(None,\n",
    "                       None, \n",
    "                       ax=ax,\n",
    "                       Plot=False,\n",
    "                       DrawFrame=DRAW_FRAME,\n",
    "                       **plotAttrs,\n",
    "                       **attrs\n",
    "                      )\n",
    "\n",
    "    def PlotDiff(self,**kwargs):\n",
    "        symbols=utl.Symbols()\n",
    "        utl.PltErr(1.0/np.array(self.temps),\n",
    "                   list(map(lambda x:self.Diffusion[x][0],self.temps)),\n",
    "                   yerr=list(map(lambda x:(self.Diffusion[x][1]-self.Diffusion[x][2])/2,self.temps)),\n",
    "                   attrs=symbols.GetAttrs(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   **kwargs\n",
    "                  )\n",
    "\n",
    "    def PlotExponent(self,**kwargs):\n",
    "        symbols=utl.Symbols()\n",
    "        ax=utl.PltErr([0.5e-3,1e-3],[1,1],attrs={'fmt':'-.r'},Plot=False)\n",
    "        utl.PltErr(1.0/np.array(self.temps),\n",
    "                   list(map(lambda x:self.exponent[x][0],self.temps)),\n",
    "                   yerr=list(map(lambda x:1.0*(self.exponent[x][1]-self.exponent[x][2]),self.temps)),\n",
    "                   attrs=symbols.GetAttrs(),\n",
    "                   DrawFrame=DRAW_FRAME,\n",
    "                   ax=ax,\n",
    "                   **kwargs\n",
    "                  )\n",
    "\n",
    "    @staticmethod\n",
    "    def myadd(a,b):\n",
    "        return a+b\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class TimeAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeAverage(Temperature):\n",
    "    \n",
    "    def __init__(self,temp_range,nrun,skip_frame = 0, verbose=False):\n",
    "        \n",
    "        Temperature.__init__(self,temp_range,nrun,verbose)\n",
    "        self.skip_frame = skip_frame\n",
    "    \n",
    "    @staticmethod \n",
    "    def LoadJson(fp):\n",
    "        with open(fp,'r') as f:\n",
    "            data = [json.loads(line) for line in f]\n",
    "        return data\n",
    "    \n",
    "    def Parse(self, fp, dirs):\n",
    "#        pdb.set_trace()\n",
    "        self.dirs = dirs = self.ModifyNrun(fp,dirs)\n",
    "        if self.verbose:\n",
    "            print('dirs:',dirs)\n",
    "        self.data=list(map(lambda x:TimeAverage.LoadJson('%s/%s'%(x,fp)),dirs))\n",
    "        if self.verbose:\n",
    "            n = np.array(self.nrun).flatten()\n",
    "            list(map(lambda x:print('Parsing: %s data.shape is: %s'%(x[1],len(x[0]))),zip(self.data,n)))\n",
    "#        print('np.array(self.data):',np.array(self.data))\n",
    "\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def Mean(data,key,skip_row = 0):\n",
    "        assert type(data) == type([])\n",
    "        assert type(data[0]) == type({})\n",
    "        sarray = np.array(list(map(lambda x:x[key],data)))\n",
    "#        print(sarray[skip_row:].shape)\n",
    "#        pdb.set_trace()\n",
    "        return np.mean(sarray[skip_row:],axis=0)\n",
    "        \n",
    "\n",
    "        \n",
    "    def Print(self, fp, \n",
    "              keys='bin_edges value error'.split(),\n",
    "              header='bin_edges value error',\n",
    "             ):\n",
    "        for item, idir in zip(self.data, self.dirs):\n",
    "            sarray = np.array(list(map(lambda x:TimeAverage.Mean(item,x,skip_row=self.skip_frame),keys)))\n",
    "            #--- write\n",
    "#            pdb.set_trace()\n",
    "            np.savetxt('%s/%s'%(idir,fp),np.c_[sarray].T,header=header)\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dirs: ['dislocations/sro']\n",
      "Parsing: 0 data.shape is: 2\n",
      "Parsing: 0 data.shape is: (10, 3)\n",
      "data.shape: (1, 10, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    if not eval(confParser['irradiation']['irradiation']) or\\\n",
    "    eval(confParser['flags']['RemoteMachine']):\n",
    "        return\n",
    "    \n",
    "    #--- temporal average\n",
    "    tmean = TimeAverage(\n",
    "       [0],[list(range(1))],\n",
    "        skip_frame = 1,\n",
    "         verbose = True,\n",
    "                     )\n",
    "    #--- parse data\n",
    "    tmean.Parse( 'wc_pairi_1_pairj_1.txt',\n",
    "                ['dislocations/sro'],\n",
    "#                list(map(lambda x:'%sNatom10KTemp300KMultipleRates/Rate%s/Run%s/crltns'%(alloy,x[0],x[1]),\n",
    "#                         tmean.temps_runs ))\n",
    "              )\n",
    "    tmean.Print('wc_pairi_1_pairj_1_timeAveraged.txt')\n",
    "\n",
    "    #--- plot\n",
    "    temp = Temperature(\n",
    "       [0],[list(range(1))],\n",
    "         verbose = True,\n",
    "                     )\n",
    "    #--- parse data\n",
    "    temp.Parse( 'wc_pairi_1_pairj_1_timeAveraged.txt',\n",
    "                ['dislocations/sro'],\n",
    "#                list(map(lambda x:'%sNatom10KTemp300KMultipleRates/Rate%s/Run%s/crltns'%(alloy,x[0],x[1]),\n",
    "#                         temp.temps_runs ))\n",
    "              )\n",
    "\n",
    "    temp.EnsAverage()\n",
    "\n",
    "    \n",
    "    #    help(temp.Concatenate)\n",
    "#    temp.Transform(col=0,multBy=-1,temp=invert)\n",
    "#    temp.Transform(col=1,multBy=-1,temp=invert)\n",
    "\n",
    "    #--- plot\n",
    "     #--- plot\n",
    "    temp.PlotPdf(shift=False,shift_factor=0.1/2,\n",
    "                 rescale=False,alpha=1.5,\n",
    "                 powerlaw=False, prefact=1e0,\n",
    "#                  mylegends=[r'$1$',r'$10$',r'$10^2$',r'$10^3$'],\n",
    "                 **{\n",
    "                  'attrs':{'fmt':'-.r'},\n",
    "#                  'xscale':'log',\n",
    "#                  'yscale':'log',\n",
    "#                   'xlim':(1e-2,10),\n",
    "#                    'ylim':(1e-7,1e1),\n",
    "#                    'ylim':(1e-7,1e2),\n",
    "#                    'ndecade_y':1,'ndecade_x':1,\n",
    "                    'nevery':1,\n",
    "                   'title':'dislocations/sro/pdf_s_E1-4_cantor.png',\n",
    "        'bbox_to_anchor':(0.55,0.45,0.5,0.5),\n",
    "    \n",
    "    })\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(Temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnnEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "497.562px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
